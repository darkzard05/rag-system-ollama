import asyncio
import os
import sys
import pytest

# Add src directory to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "src"))

from core.rag_core import RAGSystem
from core.model_loader import load_llm, load_embedding_model
from core.graph_builder import build_graph
from common.config import OLLAMA_MODEL_NAME, AVAILABLE_EMBEDDING_MODELS
from common.utils import apply_tooltips_to_response


@pytest.mark.asyncio
async def test_pdf_qa_full_graph():
    """
    ì‹¤ì œ PDF íŒŒì¼ê³¼ ì „ì²´ LangGraph íŒŒì´í”„ë¼ì¸(build_graph)ì„ ì‚¬ìš©í•˜ì—¬
    ì—”ë“œíˆ¬ì—”ë“œ RAG íë¦„ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    pdf_path = "tests/2201.07520v1.pdf"
    assert os.path.exists(pdf_path), f"í…ŒìŠ¤íŠ¸ìš© PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_path}"

    session_id = "test_full_graph_session"
    embedding_model_name = AVAILABLE_EMBEDDING_MODELS[0]

    try:
        # 1. ëª¨ë¸ ë° ì‹œìŠ¤í…œ ì¤€ë¹„
        embedder = load_embedding_model(embedding_model_name)
        llm = load_llm(OLLAMA_MODEL_NAME)
        rag_system = RAGSystem(session_id=session_id)

        print("âš™ï¸ ë¬¸ì„œ ë¡œë“œ ë° ì¸ë±ì‹± ì¤‘...")
        await asyncio.to_thread(
            rag_system.load_document, pdf_path, "test.pdf", embedder
        )

        # 2. ì „ì²´ ê·¸ë˜í”„ êµ¬ì¶•
        qa_chain = build_graph(retriever=rag_system.ensemble_retriever)
        run_config = {"configurable": {"llm": llm}}

        # 3. ì§ˆë¬¸ ì‹¤í–‰
        question = "CM3ê°€ ë¬´ì—‡ì¸ê°€ìš”?"
        print(f"ğŸ¤” ì§ˆë¬¸: {question}")

        full_response = ""
        retrieved_docs = []

        # astream_eventsë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì•±ê³¼ ë™ì¼í•œ ìŠ¤íŠ¸ë¦¬ë° ë¡œì§ ê²€ì¦
        async for event in qa_chain.astream_events(
            {"input": question}, config=run_config, version="v2"
        ):
            kind = event["event"]
            name = event.get("name", "")

            # 1. ì»¤ìŠ¤í…€ í† í° ì´ë²¤íŠ¸ ì²˜ë¦¬ (adispatch_custom_event)
            if kind == "on_custom_event" and name == "response_chunk":
                chunk_text = event["data"].get("chunk", "")
                if chunk_text:
                    if not full_response:
                        print("ğŸš€ ì²« ë²ˆì§¸ í† í° ìˆ˜ì‹ !")
                    full_response += chunk_text
                    # ì‹¤ì œ ì•±ì²˜ëŸ¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ (ì„ íƒ ì‚¬í•­)
                    # print(chunk_text, end="", flush=True)

            # 2. ìƒíƒœ ì—…ë°ì´íŠ¸ ì´ë²¤íŠ¸ ì²˜ë¦¬
            elif kind == "on_custom_event" and name == "status_update":
                status_msg = event["data"].get("message", "")
                print(f"ğŸ“¡ [Status] {status_msg}")

            # 3. ëª¨ë¸ ìŠ¤íŠ¸ë¦¼ (í´ë°± ë˜ëŠ” ì§ì ‘ í˜¸ì¶œ ëŒ€ë¹„)
            elif kind == "on_chat_model_stream":
                content = event["data"]["chunk"].content
                if content and not full_response:  # ì»¤ìŠ¤í…€ ì´ë²¤íŠ¸ê°€ ì—†ì„ ë•Œë§Œ
                    full_response += content

            # 4. ë¬¸ì„œ ê²€ìƒ‰ ì™„ë£Œ ì´ë²¤íŠ¸
            elif kind == "on_chain_end" and name == "retrieve":
                retrieved_docs = event["data"]["output"]["documents"]
                print(f"ğŸ“š ë¬¸ì„œ {len(retrieved_docs)}ê°œ ê²€ìƒ‰ ì™„ë£Œ")

        # 4. ê²°ê³¼ ê²€ì¦
        if not full_response:
            print("âš ï¸ ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨, ainvoke í´ë°± ì‹œë„...")
            result = await qa_chain.ainvoke({"input": question}, config=run_config)
            full_response = result.get("response", "")
            retrieved_docs = result.get("documents", [])

        print(f"ğŸ¤– ìµœì¢… ë‹µë³€ ê¸¸ì´: {len(full_response)}ì")

        # 5. UI í¬ë§·íŒ… ì ìš©
        final_content = apply_tooltips_to_response(full_response, retrieved_docs)

        assert len(full_response) > 0, "ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        assert len(retrieved_docs) > 0, "ë¬¸ì„œê°€ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

        print("\n--- ìµœì¢… ë‹µë³€ ìƒ˜í”Œ ---")
        print(final_content[:500] + "...")

    except Exception as e:
        pytest.fail(f"ì „ì²´ ê·¸ë˜í”„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")


if __name__ == "__main__":
    asyncio.run(test_pdf_qa_full_graph())
