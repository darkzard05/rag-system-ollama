import os
import sys
import asyncio
import pytest

# src ë””ë ‰í† ë¦¬ë¥¼ ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.join(os.getcwd(), "src"))

from core.rag_core import RAGSystem
from core.model_loader import load_embedding_model, load_llm
from common.config import AVAILABLE_EMBEDDING_MODELS, OLLAMA_MODEL_NAME


@pytest.mark.asyncio
async def test_consecutive_queries():
    """
    ë™ì¼í•œ RAGSystem ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•´ ì—°ì†ì ìœ¼ë¡œ 2ê°œì˜ ì§ˆë¬¸ì„ ìˆ˜í–‰í•˜ì—¬
    ì‹œìŠ¤í…œ ì•ˆì •ì„±ê³¼ ë‹µë³€ì˜ ì •í™•ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    """
    print("\nğŸš€ ì—°ì† ì§ˆë¬¸ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘...")

    # 1. ëª¨ë¸ ë° ì‹œìŠ¤í…œ ì¤€ë¹„
    embedding_model = AVAILABLE_EMBEDDING_MODELS[0]
    llm_model = OLLAMA_MODEL_NAME

    print(f"ğŸ§¬ ëª¨ë¸ ë¡œë”©: {embedding_model}, {llm_model}")
    embedder = await asyncio.to_thread(load_embedding_model, embedding_model)
    llm = await asyncio.to_thread(load_llm, llm_model)

    rag = RAGSystem(session_id="consecutive_test_session")

    pdf_path = os.path.join("tests", "2201.07520v1.pdf")
    print(f"ğŸ“‚ ë¬¸ì„œ ì¸ë±ì‹±: {pdf_path}")
    await asyncio.to_thread(
        rag.load_document,
        file_path=pdf_path,
        file_name="2201.07520v1.pdf",
        embedder=embedder,
    )

    # 2. ì²« ë²ˆì§¸ ì§ˆë¬¸: ê°œìš” ìœ„ì£¼
    q1 = "What is the main objective of the CM3 model?"
    print(f"\nğŸ’¬ ì§ˆë¬¸ 1: {q1}")
    res1 = await rag.aquery(input_text=q1, llm=llm)
    ans1 = res1.get("response", "")

    print("-" * 30)
    print(f"ğŸ¤– ë‹µë³€ 1:\n{ans1}")
    print("-" * 30)

    assert len(ans1) > 50, "ì²« ë²ˆì§¸ ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
    assert "CM3" in ans1 or "causally masked" in ans1.lower(), (
        "ì§ˆë¬¸ 1ì— ëŒ€í•œ ë‹µë³€ì´ ë¶€ì ì ˆí•©ë‹ˆë‹¤."
    )

    # 3. ë‘ ë²ˆì§¸ ì§ˆë¬¸: ì„¸ë¶€ ì‚¬í•­ ìœ„ì£¼ (ë©”ëª¨ë¦¬ ë° ì»¨í…ìŠ¤íŠ¸ í™•ì¸)
    q2 = "What datasets were used to train the CM3 models?"
    print(f"\nğŸ’¬ ì§ˆë¬¸ 2: {q2}")
    res2 = await rag.aquery(input_text=q2, llm=llm)
    ans2 = res2.get("response", "")

    print("-" * 30)
    print(f"ğŸ¤– ë‹µë³€ 2:\n{ans2}")
    print("-" * 30)

    assert len(ans2) > 50, "ë‘ ë²ˆì§¸ ë‹µë³€ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
    # ë…¼ë¬¸ ë‚´ìš©ìƒ Wikipedia, Common Crawl ë“±ì´ ì–¸ê¸‰ë˜ëŠ”ì§€ í™•ì¸ (ì‹¤ì œ ë‹µë³€ì— ë”°ë¼ ìœ ì—°í•˜ê²Œ ê²€ì¦)
    assert any(
        word in ans2.lower()
        for word in ["data", "web", "wikipedia", "common", "dataset"]
    ), "ì§ˆë¬¸ 2ì— ëŒ€í•œ ë‹µë³€ì— ë°ì´í„° ê´€ë ¨ í‚¤ì›Œë“œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."

    print("\nâœ… ë‘ ì§ˆë¬¸ ëª¨ë‘ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ì§ˆë¬¸ 1 ì°¸ì¡° ë¬¸ì„œ ìˆ˜: {len(res1.get('documents', []))}")
    print(f"ì§ˆë¬¸ 2 ì°¸ì¡° ë¬¸ì„œ ìˆ˜: {len(res2.get('documents', []))}")
    print("\nâœ¨ ì—°ì† ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(test_consecutive_queries())
