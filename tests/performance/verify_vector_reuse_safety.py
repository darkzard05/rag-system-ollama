import asyncio
import os
import sys
import time

import torch
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë° src ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.join(os.getcwd(), "src"))

from common.config import AVAILABLE_EMBEDDING_MODELS
from core.model_loader import load_embedding_model
from core.semantic_chunker import EmbeddingBasedSemanticChunker


async def run_verification():
    print("ğŸ” [Safety Test] ë²¡í„° ì¬ì‚¬ìš© ë° í’€ë§ ì •í™•ë„ ê²€ì¦ ì‹œì‘")

    # 1. í™˜ê²½ ì¤€ë¹„
    "cuda" if torch.cuda.is_available() else "cpu"
    model_name = AVAILABLE_EMBEDDING_MODELS[0]
    embedder = load_embedding_model(model_name)

    # í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ìƒì„± (ê¸´ ë¬¸ì¥ë“¤)
    texts = [
        "ì¸ê³µì§€ëŠ¥ì€ í˜„ëŒ€ ì‚¬íšŒì˜ í•µì‹¬ ê¸°ìˆ ë¡œ ìë¦¬ì¡ê³  ìˆìŠµë‹ˆë‹¤. " * 5,
        "ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ëŠ” ëŒ€ê·œëª¨ ë¹„ì •í˜• ë°ì´í„°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤. " * 5,
        "RAG ì‹œìŠ¤í…œì€ ì™¸ë¶€ ì§€ì‹ì„ ê²°í•©í•˜ì—¬ LLMì˜ í™˜ê° í˜„ìƒì„ ì¤„ì…ë‹ˆë‹¤. " * 5,
    ]
    docs = [
        Document(page_content=t, metadata={"source": "test", "page": i})
        for i, t in enumerate(texts)
    ]

    # --- ì‹¤í—˜ 1: ê¸°ì¡´ ë°©ì‹ (ì¬ì„ë² ë”© ë°œìƒ) ---
    print("\n[Method 1] ê¸°ì¡´ ë°©ì‹ (ì¬ì„ë² ë”© ì‹œë®¬ë ˆì´ì…˜)")
    start_time = time.time()

    # ì²­í‚¹ (ë²¡í„° ê²°ê³¼ ë¬´ì‹œ)
    chunker = EmbeddingBasedSemanticChunker(
        embedder=embedder, min_chunk_size=100, max_chunk_size=500
    )
    split_docs, _ = chunker.split_documents(docs)

    # FAISS ìƒì„± (ë‚´ë¶€ì—ì„œ ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì„ë² ë”© ìˆ˜í–‰)
    vector_store_orig = FAISS.from_documents(split_docs, embedder)

    orig_time = time.time() - start_time
    print(f"âœ… ê¸°ì¡´ ë°©ì‹ ì†Œìš” ì‹œê°„: {orig_time:.4f}s")

    # --- ì‹¤í—˜ 2: ìµœì í™” ë°©ì‹ (ë²¡í„° ì¬ì‚¬ìš©) ---
    print("\n[Method 2] ìµœì í™” ë°©ì‹ (ë²¡í„° í’€ë§ ë° ì£¼ì…)")
    start_time = time.time()

    # ì²­í‚¹ (ì´ë¯¸ ê³„ì‚°ëœ ë²¡í„° í™•ë³´)
    split_docs_opt, precomputed_vectors = chunker.split_documents(docs)

    # FAISS ì§ì ‘ ì£¼ì… (ì¬ì„ë² ë”© 0íšŒ)
    text_embeddings = list(
        zip([d.page_content for d in split_docs_opt], precomputed_vectors, strict=False)
    )
    metadatas = [d.metadata for d in split_docs_opt]
    vector_store_opt = FAISS.from_embeddings(
        text_embeddings=text_embeddings, embedding=embedder, metadatas=metadatas
    )

    opt_time = time.time() - start_time
    print(f"âœ… ìµœì í™” ë°©ì‹ ì†Œìš” ì‹œê°„: {opt_time:.4f}s")

    # --- ì‹¤í—˜ 3: ê²€ìƒ‰ í’ˆì§ˆ ë¹„êµ (ê°€ì¥ ì¤‘ìš”) ---
    print("\n[Result] ê²€ìƒ‰ í’ˆì§ˆ ë¹„êµ ê²°ê³¼")
    query = "AIì™€ ë²¡í„° ê²€ìƒ‰ì˜ ê´€ê³„"

    # ê²€ìƒ‰ ìˆ˜í–‰
    res_orig = vector_store_orig.similarity_search(query, k=1)
    res_opt = vector_store_opt.similarity_search(query, k=1)

    # ê²°ê³¼ ê²€ì¦
    is_identical = res_orig[0].page_content == res_opt[0].page_content
    print(f"ğŸ”¹ ê²€ìƒ‰ ê²°ê³¼ ì¼ì¹˜ ì—¬ë¶€: {'â­• ì¼ì¹˜' if is_identical else 'âŒ ë¶ˆì¼ì¹˜'}")

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê²€ì¦
    embedder.embed_query(query)
    # FAISS ì¸ë±ìŠ¤ ë‚´ì˜ ì‹¤ì œ ë²¡í„°ë“¤ ê°„ì˜ ê±°ë¦¬ê°€ ë™ì¼í•œì§€ í™•ì¸
    # (FAISSëŠ” ì„ë² ë”© í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¿¼ë¦¬ë¥¼ ë³€í™˜í•˜ë¯€ë¡œ ê²°ê³¼ê°€ ê°™ì•„ì•¼ í•¨)

    improvement = (orig_time - opt_time) / orig_time * 100
    print(f"ğŸš€ ì„±ëŠ¥ ê°œì„ ìœ¨: {improvement:.2f}%")

    if is_identical:
        print(
            "\nâœ¨ ê²€ì¦ ì„±ê³µ: ë²¡í„° ì¬ì‚¬ìš©ì€ í’ˆì§ˆ ì €í•˜ ì—†ì´ ì„±ëŠ¥ë§Œ íšê¸°ì ìœ¼ë¡œ í–¥ìƒì‹œí‚µë‹ˆë‹¤."
        )
    else:
        print(
            "\nâš ï¸ ê²€ì¦ ì£¼ì˜: ê²€ìƒ‰ ê²°ê³¼ì— ë¯¸ì„¸í•œ ì°¨ì´ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤ (í’€ë§ ê°€ì¤‘ì¹˜ í™•ì¸ í•„ìš”)."
        )


if __name__ == "__main__":
    asyncio.run(run_verification())
