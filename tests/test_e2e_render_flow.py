import asyncio
import sys
import io
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent / "src"))

from common.config import OLLAMA_MODEL_NAME
from core.model_loader import load_llm
from core.graph_builder import build_graph
from common.utils import apply_tooltips_to_response
from langchain_core.documents import Document

# Windows ì¸ì½”ë”© ëŒ€ì‘
if sys.platform == "win32":
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")


async def test_e2e_generation_to_display_flow():
    print("ğŸš€ [E2E í†µí•© í…ŒìŠ¤íŠ¸] ìƒì„± -> í¬ë§·íŒ… -> UI í‘œì‹œ íë¦„ ê²€ì¦ ì‹œì‘")

    # 1. ì‹œìŠ¤í…œ ì¤€ë¹„ (LLM ë° RAG ê·¸ë˜í”„)
    try:
        llm = load_llm(OLLAMA_MODEL_NAME)
    except Exception as e:
        print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ (ì¸ìš©êµ¬ í…ŒìŠ¤íŠ¸ìš©)
    mock_docs = [
        Document(
            page_content="DeepSeek-R1 is a powerful reasoning model.",
            metadata={"page": 1, "source": "tech.pdf"},
        ),
        Document(
            page_content="It supports various local RAG implementations.",
            metadata={"page": 2, "source": "tech.pdf"},
        ),
    ]

    class MockRetriever:
        async def ainvoke(self, query):
            return mock_docs

        def invoke(self, query):
            return mock_docs

    app = build_graph(retriever=MockRetriever())
    config = {"configurable": {"llm": llm}}

    # 2. ì§ˆë¬¸ ì…ë ¥ ë° ë‹µë³€ ìƒì„± (Generation)
    question = "DeepSeek-R1ì˜ íŠ¹ì§•ê³¼ ì§€ì› ì‚¬í•­ì„ ìš”ì•½í•´ì¤˜."
    print(f"ì§ˆë¬¸: {question}")

    full_response = ""
    start_time = time.time()

    # ìŠ¤íŠ¸ë¦¬ë° ì‹œë®¬ë ˆì´ì…˜
    async for event in app.astream_events(
        {"input": question}, config=config, version="v2"
    ):
        if event["event"] == "on_chat_model_stream":
            content = event["data"]["chunk"].content
            if content:
                full_response += content
                if len(full_response) % 20 == 0:  # ì§„í–‰ í‘œì‹œ
                    print(".", end="", flush=True)

    print(f"\nâœ… ë‹µë³€ ìƒì„± ì™„ë£Œ (ì†Œìš”ì‹œê°„: {time.time() - start_time:.2f}s)")

    # 3. ì¸ìš©êµ¬ íˆ´íŒ í¬ë§·íŒ… (Formatting)
    # ì‹¤ì œ UIì—ì„œ _stream_chat_responseê°€ í˜¸ì¶œí•˜ëŠ” apply_tooltips_to_response ì‹¤í–‰
    formatted_response = apply_tooltips_to_response(full_response, mock_docs)

    # 4. ìµœì¢… ê²°ê³¼ ê²€ì¦ (Display Analysis)
    print("\n--- ìµœì¢… ë Œë”ë§ ê²°ê³¼ ë¶„ì„ ---")

    checks = {
        "êµ¬ì¡°í™”ëœ ë³´ê³ ì„œ í˜•ì‹ (í—¤ë” í™•ì¸)": "# " in formatted_response
        and "## " in formatted_response,
        "ì¸ìš©êµ¬ íˆ´íŒ ë³€í™˜ (HTML í™•ì¸)": 'class="tooltip"' in formatted_response,
        "í˜ì´ì§€ ì •ë³´ í¬í•¨ ([p.1] í™•ì¸)": "[p.1]" in formatted_response
        or "[p.2]" in formatted_response,
        "ë‚´ìš© ì •í™•ì„± (DeepSeek-R1 í¬í•¨)": "DeepSeek-R1" in formatted_response,
    }

    all_passed = True
    for label, passed in checks.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f" - {label}: {status}")
        if not passed:
            all_passed = False

    if all_passed:
        print("\nğŸ‰ ëª¨ë“  ìƒì„± ë° UI í‘œì‹œ íë¦„ í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í–ˆìŠµë‹ˆë‹¤!")
        print("-" * 50)
        print("ìµœì¢… ì¶œë ¥ë¬¼ ìƒ˜í”Œ (ìƒìœ„ 300ì):")
        print(formatted_response[:300] + "...")
        print("-" * 50)
    else:
        print("\nâš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²°ê³¼ë¬¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        print(formatted_response)


if __name__ == "__main__":
    asyncio.run(test_e2e_generation_to_display_flow())
