"""
ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª¨ë“  ì„¤ì •ì„ ë‹´ëŠ” íŒŒì¼ì…ë‹ˆë‹¤.
"""
import os
from typing import Dict, List
from dotenv import load_dotenv

load_dotenv() # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

# --- ëª¨ë¸ ë° ì„¤ì • ìƒìˆ˜ ---
OLLAMA_MODEL_NAME: str = "qwen3:4b"
GEMINI_MODEL_NAME: str = "gemini-1.5-flash"
OLLAMA_NUM_PREDICT: int = int(os.getenv("OLLAMA_NUM_PREDICT", "-1")) # -1 for unlimited, or set a specific token limit

# Gemini API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
# ì˜ˆ: export GEMINI_API_KEY="YOUR_API_KEY"
GEMINI_API_KEY: str = os.getenv("GEMINI_API_KEY", "") 

AVAILABLE_EMBEDDING_MODELS: List[str] = [
    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
    "intfloat/multilingual-e5-large-instruct",
    "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
    "sentence-transformers/all-MiniLM-L6-v2", # ì§„ë‹¨ì„ ìœ„í•´ ê¸°ë³¸ ëª¨ë¸ë¡œ ë³€ê²½
]
EMBEDDING_MODEL_NAME: str = AVAILABLE_EMBEDDING_MODELS[0]
CACHE_DIR: str = ".model_cache"

# --- ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • ìƒìˆ˜ ---
RETRIEVER_CONFIG: Dict = {
    'search_type': "similarity",
    'search_kwargs': {
        'k': 4,
    },
    'weights': [0.4, 0.6]
}

# --- í…ìŠ¤íŠ¸ ë¶„í•  ì„¤ì • ---
TEXT_SPLITTER_CONFIG: Dict = {
    'chunk_size': 1500,
    'chunk_overlap': 150,
}

# --- ì±„íŒ… UI ìƒìˆ˜ ---
THINK_START_TAG: str = "<think>"
THINK_END_TAG: str = "</think>"
MSG_PREPARING_ANSWER: str = "ë‹µë³€ ìƒì„± ì¤€ë¹„ ì¤‘..."
MSG_THINKING: str = "ğŸ¤” ìƒê°ì„ ì •ë¦¬í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."
MSG_WRITING_ANSWER: str = "ë‹µë³€ì„ ì‘ì„±í•˜ëŠ” ì¤‘..."
MSG_NO_THOUGHT_PROCESS: str = "ì•„ì§ ìƒê° ê³¼ì •ì´ ì—†ìŠµë‹ˆë‹¤."
MSG_NO_RELATED_INFO: str = "ì£„ì†¡í•©ë‹ˆë‹¤, ì œê³µëœ ë¬¸ì„œì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤."
