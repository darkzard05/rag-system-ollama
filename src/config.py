"""
config.yml íŒŒì¼ê³¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •ì„ ë¡œë“œí•©ë‹ˆë‹¤.
"""

import os
import yaml
from typing import Dict, List, Any
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


def _load_config() -> Dict[str, Any]:
    """YAML ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    config_path = os.path.join(os.path.dirname(__file__), "..", "config.yml")
    try:
        with open(config_path, "r", encoding="utf-8") as f:
            return yaml.safe_load(f)
    except FileNotFoundError:
        raise RuntimeError(
            "ì„¤ì • íŒŒì¼(config.yml)ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
        )
    except yaml.YAMLError as e:
        raise RuntimeError(
            f"ì„¤ì • íŒŒì¼(config.yml)ì„ íŒŒì‹±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        )


# ì„¤ì • ë¡œë“œ
_config = _load_config()

# --- ëª¨ë¸ ë° ì„¤ì • ìƒìˆ˜ ---
_models_config = _config.get("models", {})
OLLAMA_MODEL_NAME: str = _models_config.get("default_ollama", "gemma3:8b")
# ì˜ˆì¸¡ í† í° ìˆ˜
OLLAMA_NUM_PREDICT: int = int(
    os.getenv("OLLAMA_NUM_PREDICT", _models_config.get("ollama_num_predict", -1))
    )
# ì˜¨ë„ ì„¤ì •
OLLAMA_TEMPERATURE: float = float(
    os.getenv("OLLAMA_TEMPERATURE", _models_config.get("temperature", 0.5))
    )
# ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°
OLLAMA_NUM_CTX: int = int(
    os.getenv("OLLAMA_NUM_CTX", _models_config.get("num_ctx", 2048)) 
)
# Top P
OLLAMA_TOP_P: float = float(
    os.getenv("OLLAMA_TOP_P", _models_config.get("top_p", 0.9))
)
AVAILABLE_EMBEDDING_MODELS: List[str] = _models_config.get("available_embeddings", [])
CACHE_DIR: str = _models_config.get("cache_dir", ".model_cache")
EMBEDDING_BATCH_SIZE: Any = _models_config.get("embedding_batch_size", "auto")

# --- RAG íŒŒì´í”„ë¼ì¸ ì„¤ì • ---
_rag_config = _config.get("rag", {})
RETRIEVER_CONFIG: Dict = _rag_config.get("retriever", {})
TEXT_SPLITTER_CONFIG: Dict = _rag_config.get("text_splitter", {})
VECTOR_STORE_CACHE_DIR: str = _rag_config.get(
    "vector_store_cache_dir", ".model_cache/vector_store_cache"
)
_prompts_config = _rag_config.get("prompts") or {}
QA_SYSTEM_PROMPT: str = _prompts_config.get("qa_system_prompt", "")


# --- ì±„íŒ… UI ìƒìˆ˜ ---
_ui_config = _config.get("ui", {})
UI_CONTAINER_HEIGHT: int = _ui_config.get("container_height", 650)
_ui_messages = _ui_config.get("messages", {})
MSG_PREPARING_ANSWER: str = _ui_messages.get("preparing_answer", "ë‹µë³€ ìƒì„± ì¤€ë¹„ ì¤‘...")
MSG_NO_RELATED_INFO: str = _ui_messages.get(
    "no_related_info", "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
)
MSG_SIDEBAR_TITLE: str = _ui_messages.get("sidebar_title", "âš™ï¸ ì„¤ì •")
MSG_PDF_UPLOADER_LABEL: str = _ui_messages.get("pdf_uploader_label", "PDF íŒŒì¼ ì—…ë¡œë“œ")
MSG_MODEL_SELECTOR_LABEL: str = _ui_messages.get("model_selector_label", "LLM ëª¨ë¸ ì„ íƒ")
MSG_EMBEDDING_SELECTOR_LABEL: str = _ui_messages.get(
    "embedding_selector_label", "ì„ë² ë”© ëª¨ë¸ ì„ íƒ"
)
MSG_SYSTEM_STATUS_TITLE: str = _ui_messages.get("system_status_title", "ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
MSG_LOADING_MODELS: str = _ui_messages.get(
    "loading_models", "LLM ëª¨ë¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."
)
MSG_PDF_VIEWER_TITLE: str = _ui_messages.get("pdf_viewer_title", "ğŸ“„ PDF ë¯¸ë¦¬ë³´ê¸°")
MSG_PDF_VIEWER_NO_FILE: str = _ui_messages.get(
    "pdf_viewer_no_file", "ë¯¸ë¦¬ë³¼ PDFê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
)
MSG_PDF_VIEWER_PREV_BUTTON: str = _ui_messages.get("pdf_viewer_prev_button", "â† ì´ì „")
MSG_PDF_VIEWER_NEXT_BUTTON: str = _ui_messages.get("pdf_viewer_next_button", "ë‹¤ìŒ â†’")
MSG_PDF_VIEWER_PAGE_SLIDER: str = _ui_messages.get("pdf_viewer_page_slider", "í˜ì´ì§€ ì´ë™")
MSG_PDF_VIEWER_ERROR: str = _ui_messages.get(
    "pdf_viewer_error", "PDFë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
)
MSG_CHAT_TITLE: str = _ui_messages.get("chat_title", "ğŸ’¬ ì±„íŒ…")
MSG_CHAT_INPUT_PLACEHOLDER: str = _ui_messages.get(
    "chat_input_placeholder", "PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”."
)
MSG_CHAT_NO_QA_SYSTEM: str = _ui_messages.get(
    "chat_no_qa_system", "QA ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDFë¥¼ ë¨¼ì € ì²˜ë¦¬í•´ì£¼ì„¸ìš”."
)
MSG_CHAT_WELCOME: str = _ui_messages.get("chat_welcome", "í™˜ì˜í•©ë‹ˆë‹¤!")
MSG_CHAT_GUIDE: str = _ui_messages.get("chat_guide", "ì‚¬ìš© ê°€ì´ë“œ")
MSG_STREAMING_ERROR: str = _ui_messages.get(
    "streaming_error", "ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
)
MSG_GENERIC_ERROR: str = _ui_messages.get("generic_error", "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}")
MSG_RETRY_BUTTON: str = _ui_messages.get("retry_button", "ì¬ì‹œë„")
_ui_errors = _ui_messages.get("errors", {})
MSG_ERROR_OLLAMA_NOT_RUNNING: str = _ui_errors.get(
    "ollama_not_running",
    "Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.",
)
