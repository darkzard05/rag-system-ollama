"""
í”„ë¡œì íŠ¸ ì „ë°˜ì—ì„œ ì‚¬ìš©ë˜ëŠ” ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ íŒŒì¼.
Utils Rebuild: ë³µì¡í•œ ë°ì½”ë ˆì´í„° ì œê±° ë° ë¹„ë™ê¸° í—¬í¼ ë‹¨ìˆœí™”.
"""

import asyncio
import functools
import hashlib
import logging
import os
import re
import time

import streamlit as st

logger = logging.getLogger(__name__)

# --- ì‚¬ì „ ì»´íŒŒì¼ëœ ì •ê·œí‘œí˜„ì‹ (ì„±ëŠ¥ ìµœì í™”) ---
_RE_LATEX_BLOCK = re.compile(r"\\\[(.*?)\\\]", re.DOTALL)
_RE_LATEX_INLINE = re.compile(r"\\\((.*?)\\\)", re.DOTALL)

# [ìˆ˜ì •] ë³µí•© ì¸ìš© íŒ¨í„´ ì§€ì›: [p.1, p.2] ë˜ëŠ” [p.1, 2, 3] ë˜ëŠ” [page 5] ë“± ì§€ì›
_RE_CITATION_BLOCK = re.compile(
    r"([\[\(])((?:[Pp](?:age)?\.?\s*)?\d+(?:[\s,]*)(?:(?:[Pp](?:age)?\.?\s*)?\d+(?:[\s,]*))*)([\]\)])",
    re.IGNORECASE,
)
_RE_EXTRACT_PAGES = re.compile(r"(\d+)")
_RE_WHITESPACE = re.compile(r"\s+")
_RE_CLEAN_LIST_NUM = re.compile(r"^\d+[\.\)]\s*")
_RE_CLEAN_LIST_BULLET = re.compile(r"^[\-\*â€¢]\s*")

# [ìˆ˜ì •] ì •ê·œì‹ ì™„í™”:
# 1. ^\d+[\.\)\s]+ : ë¬¸ë‘ì˜ ìˆ«ìì™€ ì /ê´„í˜¸ (ì˜ˆ: "1. ", "1) ")
# 2. ^\s*[\-\*\u2022]\s* : ë¬¸ë‘ì˜ ë¶ˆë › í¬ì¸íŠ¸ (ì˜ˆ: "- ", "* ")
# 3. ^["']+|["']+$ : ë¬¸ë‘/ë¬¸ë¯¸ì˜ ë”°ì˜´í‘œ
# 4. (?:^Example:|^Query:)\s* : "Example:" ê°™ì€ ì ‘ë‘ì‚¬ ì œê±°
_RE_QUERY_CLEAN_PREFIX = re.compile(
    r"^(?:\d+[\.\)\s]+|\s*[\-\*\u2022]\s*|(?:Example|Query|Question):\s*)+",
    re.IGNORECASE,
)
_RE_QUERY_CLEAN_QUOTES = re.compile(r'^["\']+|["\']+$')


def normalize_latex_delimiters(text: str) -> str:
    r"""
    LLMì´ ì¶œë ¥í•˜ëŠ” ë‹¤ì–‘í•œ LaTeX ìˆ˜ì‹ êµ¬ë¶„ìë¥¼ Streamlit í‘œì¤€($ ë˜ëŠ” $$)ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    - \( ... \) -> $ ... $ (ì¸ë¼ì¸)
    - \[ ... \] -> $$ ... $$ (ë¸”ë¡)
    - ê¸°í˜¸ ì•ë’¤ì˜ ë¶ˆí•„ìš”í•œ ì´ìŠ¤ì¼€ì´í”„ ì œê±°
    """
    if not text:
        return text

    # 1. ë¸”ë¡ ìˆ˜ì‹ ë³€í™˜: \[ ... \] -> $$ ... $$
    text = _RE_LATEX_BLOCK.sub(r"$$\1$$", text)

    # 2. ì¸ë¼ì¸ ìˆ˜ì‹ ë³€í™˜: \( ... \) -> $ ... $
    text = _RE_LATEX_INLINE.sub(r"$\1$", text)

    # 3. ì˜ëª»ëœ ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì •ì œ (ì˜ˆ: \$ -> $)
    # ë‹¨, ì½”ë“œ ë¸”ë¡ ë‚´ì˜ ê¸°í˜¸ëŠ” ê±´ë“œë¦¬ì§€ ì•Šë„ë¡ ì£¼ì˜ê°€ í•„ìš”í•˜ë‚˜ ì¼ë°˜ ë‹µë³€ ê¸°ì¤€ ì²˜ë¦¬
    text = text.replace(r"\$", "$")

    return text


def apply_tooltips_to_response(response_text: str, documents: list) -> str:
    """
    [ìµœì í™”] LaTeX ì •ê·œí™”ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤. (íˆ´íŒ ë¡œì§ì€ UI ê³„ì¸µìœ¼ë¡œ ì´ë™ë¨)
    """
    if not response_text:
        return response_text

    return normalize_latex_delimiters(response_text)


# --- ì „ì²˜ë¦¬ìš© ê³ ì† í…Œì´ë¸” ---
# ë„ ë¬¸ì ë“± ì œì–´ ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜í•˜ëŠ” í…Œì´ë¸”
_CLEAN_TRANS_TABLE = str.maketrans({"\x00": " ", "\r": " ", "\n": " ", "\t": " "})


def preprocess_text(text: str) -> str:
    """
    í…ìŠ¤íŠ¸ ì •ì œ: ì œì–´ ë¬¸ìë¥¼ ê³µë°±ìœ¼ë¡œ ì¹˜í™˜í•˜ê³  ì—°ì† ê³µë°±ì„ ê³ ì† ì •ê·œí™”
    [ìµœì í™”] ì •ê·œì‹ ì—”ì§„ ëŒ€ì‹  ë„¤ì´í‹°ë¸Œ split/joinì„ ì‚¬ìš©í•˜ì—¬ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”
    """
    if not text:
        return ""

    # 1. str.translateë¥¼ ì´ìš©í•œ ê³ ì† ë¬¸ì ì¹˜í™˜
    text = text.translate(_CLEAN_TRANS_TABLE)

    # 2. ì—°ì†ëœ ê³µë°±ì„ ë‹¨ì¼ ê³µë°±ìœ¼ë¡œ í†µí•© (split/joinì´ re.subë³´ë‹¤ í›¨ì”¬ ë¹ ë¦„)
    return " ".join(text.split())


def clean_query_text(query: str) -> str:
    """ì¿¼ë¦¬ í…ìŠ¤íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ ê¸°í˜¸, ë²ˆí˜¸, ì ‘ë‘ì‚¬(Example:, Question: ë“±) ì œê±°"""
    if not query:
        return ""

    # 1. ë¬¸ë‘ì˜ ìˆ«ì, ë¶ˆë ›, ì ‘ë‘ì‚¬(Example:, Query: ë“±) ì¼ê´„ ì œê±°
    query = _RE_QUERY_CLEAN_PREFIX.sub("", query.strip())

    # 2. ë¬¸ë‘/ë¬¸ë¯¸ ë”°ì˜´í‘œ ì œê±°
    query = _RE_QUERY_CLEAN_QUOTES.sub("", query.strip())

    return query.strip()


@st.cache_data(ttl=5)  # 5ì´ˆ ë™ì•ˆ ë¦¬ì†ŒìŠ¤ ì •ë³´ ìºì‹±
def get_ollama_resource_usage(model_name: str) -> str:
    """
    Ollama APIë¥¼ í†µí•´ íŠ¹ì • ëª¨ë¸ì˜ ë¦¬ì†ŒìŠ¤ ì‚¬ìš© ìƒíƒœ(GPU/CPU)ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        import requests

        from common.config import OLLAMA_BASE_URL

        # Ollama ps API í˜¸ì¶œ
        response = requests.get(f"{OLLAMA_BASE_URL}/api/ps", timeout=2.0)
        if response.status_code == 200:
            data = response.json()
            models = data.get("models", [])

            for m in models:
                if model_name in m.get("name", ""):
                    size_vram = m.get("size_vram", 0)
                    size = m.get("size", 1)

                    # VRAM ì‚¬ìš© ë¹„ìœ¨ ê³„ì‚°
                    vram_ratio = (size_vram / size) * 100
                    if vram_ratio >= 90:
                        return f"GPU (VRAM {vram_ratio:.1f}%)"
                    elif vram_ratio > 0:
                        return f"Hybrid (VRAM {vram_ratio:.1f}%, CPU {100 - vram_ratio:.1f}%)"
                    else:
                        return "CPU (0% VRAM)"

            return "Unknown (Not running)"
        return "Unknown (API Error)"
    except Exception:
        return "Unknown (Connection Error)"


def format_error_message(e: Exception) -> str:
    """
    ë°œìƒí•œ ì˜ˆì™¸ ê°ì²´ë¥¼ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ì¹œì ˆí•œ ë©”ì‹œì§€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    from common.exceptions import (
        EmbeddingModelError,
        EmptyPDFError,
        InsufficientChunksError,
        LLMInferenceError,
    )

    err_type = type(e).__name__
    msg = str(e)

    # 1. ì»¤ìŠ¤í…€ ë„ë©”ì¸ ì˜ˆì™¸ ì²˜ë¦¬
    if isinstance(e, EmptyPDFError):
        return "ğŸ“„ PDF íŒŒì¼ì— í…ìŠ¤íŠ¸ê°€ ì—†ê±°ë‚˜ ì´ë¯¸ì§€ë¡œë§Œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì‹œë„í•´ ë³´ì„¸ìš”."
    elif isinstance(e, InsufficientChunksError):
        return "âš ï¸ ë¬¸ì„œì˜ ìœ íš¨í•œ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    elif isinstance(e, LLMInferenceError):
        return f"ğŸ¤– ì¶”ë¡  ëª¨ë¸ ì‘ë‹µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {msg}"
    elif isinstance(e, EmbeddingModelError):
        return "ğŸ§  ì„ë² ë”© ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ìì›(VRAM/RAM)ì´ ë¶€ì¡±í•œì§€ í™•ì¸í•´ ì£¼ì„¸ìš”."

    # 2. ì¼ë°˜ ì‹œìŠ¤í…œ ì˜ˆì™¸ ì²˜ë¦¬
    if "ConnectionError" in err_type or "11434" in msg:
        return (
            "ğŸ”Œ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”."
        )
    elif "timeout" in msg.lower():
        return (
            "âŒ› ì²˜ë¦¬ ì‹œê°„ì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë ¤ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        )
    elif "out of memory" in msg.lower() or "CUDA" in msg:
        return "ğŸš€ GPU ë©”ëª¨ë¦¬(VRAM)ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•˜ê±°ë‚˜ ëª¨ë¸ì„ ì‘ì€ ê²ƒìœ¼ë¡œ ë°”ê¿”ë³´ì„¸ìš”."

    # 3. ê¸°ë³¸ê°’
    return f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ ({err_type}): {msg}"


def fast_hash(text: str, length: int = 16) -> str:
    """
    ë³´ì•ˆì´ í•„ìš” ì—†ëŠ” ë‹¨ìˆœ ì‹ë³„ìš© ê³ ì† í•´ì‹œ í•¨ìˆ˜.
    SHA256ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥¸ MD5ë¥¼ ì‚¬ìš©í•˜ê³  ê²°ê³¼ ê¸¸ì´ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.
    """
    if not text:
        return "0" * length
    # usedforsecurity=False: ë³´ì•ˆ ì§„ë‹¨ ë„êµ¬(Bandit ë“±)ì— ì´ í•´ì‹œê°€
    # ì•”í˜¸í™”ë‚˜ ë³´ì•ˆ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë˜ì§€ ì•ŠìŒì„ ì•Œë¦½ë‹ˆë‹¤.
    return hashlib.md5(text.encode(errors="ignore"), usedforsecurity=False).hexdigest()[
        :length
    ]


def count_tokens_rough(text: str) -> int:
    """
    í…ìŠ¤íŠ¸ì˜ í† í° ìˆ˜ë¥¼ ëŒ€ëµì ìœ¼ë¡œ ê³„ì‚°í•©ë‹ˆë‹¤.
    - ì˜ì–´: ì•½ 4ê¸€ìë‹¹ 1í† í°
    - í•œê¸€/íŠ¹ìˆ˜ë¬¸ì: ì•½ 1~2ê¸€ìë‹¹ 1í† í°
    ë³´ìˆ˜ì ìœ¼ë¡œ ê³„ì‚°í•˜ê¸° ìœ„í•´ (ê¸€ì ìˆ˜ / 2.5)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    if not text:
        return 0
    return int(len(text) / 2.5) + 1


@functools.lru_cache(maxsize=4)
def _get_cached_pdf_bytes(pdf_path: str) -> bytes | None:
    """PDF íŒŒì¼ ë‚´ìš©ì„ ë©”ëª¨ë¦¬ì— ìºì‹±í•©ë‹ˆë‹¤. (I/O ì ˆê°)"""
    if os.path.exists(pdf_path):
        with open(pdf_path, "rb") as f:
            return f.read()
    return None


def _merge_rects(rects: list, threshold: float = 5.0) -> list:
    """
    ì¸ì ‘í•˜ê±°ë‚˜ ê²¹ì¹˜ëŠ” ì‚¬ê°í˜•ë“¤ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ë³‘í•©í•©ë‹ˆë‹¤.
    [ìµœì í™”] ë‹¤ë‹¨ ë ˆì´ì•„ì›ƒ ë° í–‰ ê°„ê²©ì„ ê³ ë ¤í•œ ì •ë°€ ë³‘í•©.
    """
    if not rects:
        return []

    # 1. Y ì¢Œí‘œ ë° X ì¢Œí‘œ ê¸°ì¤€ ì •ë ¬
    sorted_rects = sorted(rects, key=lambda r: (r.y0, r.x0))
    merged = []

    if not sorted_rects:
        return []

    current_group = [sorted_rects[0]]

    for next_rect in sorted_rects[1:]:
        last = current_group[-1]

        # ìˆ˜ì§ ê²¹ì¹¨ ì •ë„ í™•ì¸ (í–‰ íŒë‹¨)
        y_overlap = max(0, min(last.y1, next_rect.y1) - max(last.y0, next_rect.y0))
        is_same_line = y_overlap > min(last.height, next_rect.height) * 0.6

        # ìˆ˜í‰ ê±°ë¦¬ í™•ì¸ (ë‹¨ì–´ ê°„ê²© íŒë‹¨)
        x_gap = next_rect.x0 - last.x1

        if is_same_line and x_gap < threshold * 10:  # ê°™ì€ í–‰ & ì¸ì ‘
            current_group.append(next_rect)
        else:
            # ê·¸ë£¹ ë³‘í•© ë° ìƒˆ ê·¸ë£¹ ì‹œì‘
            union_rect = current_group[0]
            for r in current_group[1:]:
                union_rect = union_rect | r
            merged.append(union_rect)
            current_group = [next_rect]

    # ë§ˆì§€ë§‰ ê·¸ë£¹ ì²˜ë¦¬
    if current_group:
        union_rect = current_group[0]
        for r in current_group[1:]:
            union_rect = union_rect | r
        merged.append(union_rect)

    return merged


def get_pdf_annotations(
    pdf_path: str, documents: list, color: str = "rgba(255, 0, 0, 0.25)"
) -> list[dict]:
    """
    ê²€ìƒ‰ëœ ë¬¸ì„œ ì¡°ê°ë“¤ì˜ í…ìŠ¤íŠ¸ ì¢Œí‘œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    [ìµœì í™”] ë¬¸ì¥ ì „ì²´ë¥¼ í•œ ì¤„ í•œ ì¤„ ë…ë¦½ëœ ë°•ìŠ¤ë¡œ í‘œì‹œí•˜ì—¬ ì‹œê°ì  ì™„ì„±ë„ë¥¼ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.
    """
    import fitz

    annotations = []
    if not pdf_path or not documents:
        return []

    try:
        pdf_bytes = _get_cached_pdf_bytes(pdf_path)
        if not pdf_bytes:
            return []

        with fitz.open(stream=pdf_bytes, filetype="pdf") as doc:
            search_flags = (
                fitz.TEXT_DEHYPHENATE
                | fitz.TEXT_PRESERVE_LIGATURES
                | fitz.TEXT_PRESERVE_WHITESPACE
            )

            for idx, doc_obj in enumerate(documents):
                page_num = doc_obj.metadata.get("page", 1) - 1
                if page_num < 0 or page_num >= len(doc):
                    continue

                page = doc[page_num]
                query_content = doc_obj.page_content.strip()
                if len(query_content) < 5:
                    continue

                # --- [ê³ ì •ë°€ í–‰ ë‹¨ìœ„ ì¶”ì¶œ ì•Œê³ ë¦¬ì¦˜] ---
                p_words = page.get_text("words", flags=search_flags)
                if not p_words:
                    continue

                head_txt = query_content[:20].strip()
                tail_txt = query_content[-20:].strip()

                def clean(t):
                    return re.sub(r"[^\w]", "", t).lower()

                head_clean = clean(head_txt)
                tail_clean = clean(tail_txt)

                start_idx, end_idx = -1, -1
                for i, w in enumerate(p_words):
                    w_clean = clean(w[4])
                    if (
                        start_idx == -1
                        and head_clean.startswith(w_clean)
                        and len(w_clean) > 1
                    ):
                        start_idx = i
                    if tail_clean.endswith(w_clean) and len(w_clean) > 1:
                        end_idx = i

                target_rects = []
                if start_idx != -1 and end_idx != -1 and start_idx <= end_idx:
                    current_line_rects = [fitz.Rect(p_words[start_idx][:4])]
                    last_y = p_words[start_idx][1]

                    for i in range(start_idx + 1, end_idx + 1):
                        w_rect = fitz.Rect(p_words[i][:4])
                        curr_y = p_words[i][1]
                        if abs(curr_y - last_y) < 3:
                            current_line_rects.append(w_rect)
                        else:
                            line_union = current_line_rects[0]
                            for r in current_line_rects[1:]:
                                line_union |= r
                            target_rects.append(line_union)
                            current_line_rects = [w_rect]
                            last_y = curr_y

                    if current_line_rects:
                        line_union = current_line_rects[0]
                        for r in current_line_rects[1:]:
                            line_union |= r
                        target_rects.append(line_union)

                if not target_rects:
                    quads = page.search_for(
                        query_content[:100], quads=True, flags=search_flags
                    )
                    target_rects = [q.rect for q in quads]

                for i, rect in enumerate(target_rects):
                    if rect.width < 2 or rect.height < 2:
                        continue
                    annotations.append(
                        {
                            "page": int(page_num + 1),
                            "x": float(rect.x0),
                            "y": float(rect.y0),
                            "width": float(rect.width),
                            "height": float(rect.height),
                            "color": "rgba(255, 0, 0, 0.3)",
                            "border": "solid",
                            "id": f"ref_{idx}_{page_num}_{i}",
                        }
                    )

    except Exception as e:
        logger.error(f"[Utils] PDF í•˜ì´ë¼ì´íŠ¸ ì¢Œí‘œ ì¶”ì¶œ ì‹¤íŒ¨: {e}", exc_info=True)

    return annotations


def sync_run(coro):
    """
    Streamlit(ë™ê¸° í™˜ê²½)ì—ì„œ ë¹„ë™ê¸° ì½”ë£¨í‹´ì„ ì•ˆì „í•˜ê²Œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ í—¬í¼.
    ì „ì—­ì ìœ¼ë¡œ nest_asyncioê°€ ì ìš©ë˜ì–´ ìˆì–´ì•¼ ì‘ë™í•©ë‹ˆë‹¤.
    """
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        loop = None

    if loop and loop.is_running():
        return loop.run_until_complete(coro)

    return asyncio.run(coro)


def log_operation(operation_name):
    """
    ë‹¨ìˆœ ë™ê¸° í•¨ìˆ˜ìš© ë¡œê¹… ë°ì½”ë ˆì´í„°.
    GraphBuilderì˜ Node í•¨ìˆ˜ì—ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”! (config ì „ë‹¬ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥)
    """

    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            logger.info(f"[SYSTEM] [TASK] {operation_name} ì‹œì‘")
            start = time.time()
            try:
                res = func(*args, **kwargs)
                dur = time.time() - start
                logger.info(f"[SYSTEM] [TASK] {operation_name} ì™„ë£Œ | ì†Œìš”: {dur:.2f}s")
                return res
            except Exception as e:
                logger.info(f"[SYSTEM] [TASK] {operation_name} ì‹¤íŒ¨ | {e}")
                raise

        return wrapper

    return decorator
