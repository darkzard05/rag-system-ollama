"""
Streamlit UI ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ íŒŒì¼.
Clean & Minimal Version: ë¶€ê°€ ìš”ì†Œ ì œê±°, ì§ê´€ì ì¸ ë¡œë”© ë° ìŠ¤íŠ¸ë¦¬ë°.
"""

import asyncio
import time
import logging
import os
import re
from contextlib import aclosing
from typing import Callable, Optional

import streamlit as st
from streamlit_pdf_viewer import pdf_viewer
import fitz  # PyMuPDF

from common.exceptions import (
    PDFProcessingError,
    EmptyPDFError,
    InsufficientChunksError,
    VectorStoreError,
    LLMInferenceError,
    EmbeddingModelError,
)
from core.session import SessionManager
from core.model_loader import get_available_models
from common.utils import sync_run, apply_tooltips_to_response
from common.config import (
    AVAILABLE_EMBEDDING_MODELS,
    DEFAULT_OLLAMA_MODEL,
    UI_CONTAINER_HEIGHT,
    MSG_SIDEBAR_TITLE,
    MSG_PDF_UPLOADER_LABEL,
    MSG_MODEL_SELECTOR_LABEL,
    MSG_EMBEDDING_SELECTOR_LABEL,
    MSG_SYSTEM_STATUS_TITLE,
    MSG_PDF_VIEWER_TITLE,
    MSG_PDF_VIEWER_NO_FILE,
    MSG_PDF_VIEWER_PREV_BUTTON,
    MSG_PDF_VIEWER_NEXT_BUTTON,
    MSG_PDF_VIEWER_ERROR,
    MSG_CHAT_TITLE,
    MSG_CHAT_INPUT_PLACEHOLDER,
    MSG_CHAT_NO_QA_SYSTEM,
    MSG_CHAT_WELCOME,
    MSG_ERROR_OLLAMA_NOT_RUNNING,
    MSG_PREPARING_ANSWER,
)

logger = logging.getLogger(__name__)


def _render_status_box(container):
    """ì‹œìŠ¤í…œ ìƒíƒœ ë¡œê·¸ ë°•ìŠ¤ë¥¼ ìµœì‹ ìˆœ(ì—­ìˆœ)ìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤."""
    if container is None:
        return
        
    status_logs = SessionManager.get("status_logs", [])
    if not status_logs:
        return

    # [ìŠ¤íƒ€ì¼ë§: ìµœì‹ ìˆœ ì¶œë ¥ ì „ìš© í…Œë§ˆ]
    log_html = """
    <style>
    .status-outer-container {
        border: 1px solid rgba(49, 51, 63, 0.2);
        border-radius: 8px;
        padding: 8px;
        background-color: #1e1e1e;
        margin-bottom: 10px;
        width: 100%;
    }
    .status-container {
        font-family: 'Consolas', 'Monaco', 'Source Code Pro', monospace;
        height: 130px;
        overflow-y: auto;
        overflow-x: hidden;
        display: flex;
        flex-direction: column; /* ì—­ìˆœ ë°ì´í„°ì´ë¯€ë¡œ ìœ„ì—ì„œë¶€í„° ìˆœì°¨ ì¶œë ¥ */
        gap: 2px;
    }
    .status-line {
        flex-shrink: 0;
        line-height: 1.4;
        margin: 0px !important;
        padding: 2px 6px !important;
        font-size: 0.82rem;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
        color: #888; /* ê¸°ë³¸ì€ íë¦¬ê²Œ */
    }
    .status-newest { 
        color: #4fc3f7; /* ìµœì‹  ë¡œê·¸ë§Œ ë°ì€ ìƒ‰ */
        font-weight: bold;
        background-color: rgba(79, 195, 247, 0.08);
        border-radius: 4px;
    }
    
    .status-container::-webkit-scrollbar { width: 3px; }
    .status-container::-webkit-scrollbar-thumb { background: #333; }
    </style>
    """
    
    import re
    import html
    log_content = ""
    # [í•µì‹¬] ë¡œê·¸ë¥¼ ì—­ìˆœìœ¼ë¡œ ë’¤ì§‘ì–´ ìµœì‹  ë‚´ìš©ì´ 0ë²ˆ ì¸ë±ìŠ¤ì— ì˜¤ê²Œ í•¨
    reversed_logs = status_logs[::-1]
    
    for i, log in enumerate(reversed_logs):
        # HTML ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬ë¡œ ì•ˆì „ì„± í™•ë³´
        safe_log = html.escape(log)
        clean_log = re.sub(r'[^\x00-\x7Fê°€-í£\s\(\)\[\]\/\:\.\-\>]', '', safe_log).strip()
        if not clean_log and safe_log: clean_log = safe_log.strip()
        
        # ì²« ë²ˆì§¸(i=0)ê°€ ê°€ì¥ ìµœì‹  ë¡œê·¸
        is_newest = (i == 0)
        cls = "status-newest" if is_newest else ""
        prefix = "âš¡" if is_newest else " "
        
        log_content += f"<div class='status-line {cls}' title='{clean_log}'>{prefix} {clean_log}</div>"
    
    full_html = f"{log_html}<div class='status-outer-container'><div class='status-container'>{log_content}</div></div>"
    container.markdown(full_html, unsafe_allow_html=True)



async def _stream_chat_response(rag_engine, user_query: str, chat_container) -> str:
    """
    RAG ì—”ì§„ì˜ ì´ë²¤íŠ¸ë¥¼ ìˆ˜ì‹ í•˜ì—¬ ì‚¬ê³  ê³¼ì •ê³¼ ë‹µë³€ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    state = {
        "full_response": "",
        "full_thought": "",
        "retrieved_docs": [],
        "start_time": time.time(),
        "thinking_start_time": None,
        "thinking_end_time": None
    }
    
    current_llm = SessionManager.get("llm")
    if not current_llm:
        return "âŒ ì˜¤ë¥˜: LLM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
    status_placeholder = SessionManager.get("status_placeholder")
    run_config = {"configurable": {"llm": current_llm}}
    SessionManager.set("is_generating_answer", True)

    try:
        with chat_container:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                # UI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”: ì²˜ìŒì—ëŠ” ì ‘íŒ ìƒíƒœë¡œ ëŒ€ê¸°
                thought_container = st.empty()
                with thought_container:
                    st.expander("ğŸ§  ì‚¬ê³  ì¤€ë¹„ ì¤‘...", expanded=False)
                
                thought_display = None # ì‚¬ê³  ê³¼ì • í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì“¸ ê³µê°„
                
                answer_display = st.empty()
                answer_display.markdown(f"âŒ› {MSG_PREPARING_ANSWER}")
                
                # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ìˆ˜ì‹ 
                async with aclosing(rag_engine.astream_events(
                    {"input": user_query}, config=run_config, version="v2"
                )) as event_stream:
                    try:
                        async for event in event_stream:
                            kind, name, data = event["event"], event.get("name", "Unknown"), event.get("data", {})
                            
                            # ìƒíƒœ ë°•ìŠ¤ ë™ê¸°í™”
                            if kind in ["on_chain_start", "on_chain_end"]:
                                _render_status_box(status_placeholder)
                            
                            # ì»¤ìŠ¤í…€ ì‘ë‹µ ì´ë²¤íŠ¸ ì²˜ë¦¬ (Integrity Protocol)
                            if kind == "on_custom_event" and name == "response_chunk":
                                content = data.get("chunk")
                                thought = data.get("thought")

                                # 1. ì‚¬ê³  ê³¼ì • ì²˜ë¦¬
                                if thought:
                                    if not state["full_thought"]:
                                        state["thinking_start_time"] = time.time()
                                        # ì‚¬ê³  ì‹œì‘ ì‹œ íƒ€ì´í‹€ ì—…ë°ì´íŠ¸ (ì—¬ì „íˆ ì ‘íŒ ìƒíƒœ ìœ ì§€)
                                        with thought_container:
                                            thought_expander = st.expander("ğŸ§  ì‚¬ê³  ê³¼ì • ì‘ì„± ì¤‘...", expanded=False)
                                            thought_display = thought_expander.empty()
                                    
                                    state["full_thought"] += thought
                                    if thought_display:
                                        thought_display.markdown(state["full_thought"] + "â–Œ")
                                
                                # 2. ë‹µë³€ ë³¸ë¬¸ ì²˜ë¦¬
                                if content:
                                    if not state["full_response"]:
                                        # ì²« ë‹µë³€ í† í°ì´ ë“¤ì–´ì˜¤ë©´ ì‚¬ê³  ê³¼ì • ì¢…ë£Œë¡œ ê°„ì£¼
                                        state["thinking_end_time"] = time.time()
                                        if state["full_thought"]:
                                            thinking_dur = state["thinking_end_time"] - state["thinking_start_time"]
                                            with thought_container:
                                                label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({thinking_dur:.1f}ì´ˆ)"
                                                with st.expander(label, expanded=False):
                                                    st.markdown(state["full_thought"])
                                    
                                    state["full_response"] += content
                                    answer_display.markdown(state["full_response"] + "â–Œ", unsafe_allow_html=True)
                                
                            # ì—”ì§„ ë‚´ë¶€ ë°ì´í„° ìº¡ì²˜
                            elif kind == "on_chain_end":
                                if name == "retrieve":
                                    output = data.get("output", {})
                                    if "documents" in output: state["retrieved_docs"] = output["documents"]
                                
                                elif name == "generate_response":
                                    output = data.get("output", {})
                                    if isinstance(output, dict):
                                        if "documents" in output and not state["retrieved_docs"]:
                                            state["retrieved_docs"] = output["documents"]
                                        if "response" in output and len(output["response"]) > len(state["full_response"]):
                                            state["full_response"] = output["response"]
                    except asyncio.CancelledError:
                        logger.info("[UI] ìŠ¤íŠ¸ë¦¬ë°ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        raise
                
                # ìµœì¢… ë Œë”ë§ ë° ì •ë¦¬
                _finalize_ui_rendering(thought_container, answer_display, state)
                
        return {
            "response": state["full_response"], 
            "thought": state["full_thought"],
            "documents": state["retrieved_docs"]
        }

    except Exception as e:
        logger.error(f"UI ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}", exc_info=True)
        from common.utils import format_error_message
        friendly_msg = format_error_message(e)
        
        # [ìµœì í™”] ìƒíƒœì°½ì— ì—ëŸ¬ ë©”ì‹œì§€ ì¦‰ì‹œ ë°˜ì˜
        SessionManager.add_status_log(friendly_msg)
        return {"response": friendly_msg, "thought": "", "documents": []}
    finally:
        SessionManager.set("is_generating_answer", False)
        _render_status_box(status_placeholder)

def _finalize_ui_rendering(thought_container, answer_display, state):
    """ë‹µë³€ ìƒì„±ì´ ëë‚œ í›„ UIë¥¼ ìµœì¢… ìƒíƒœë¡œ ì •ë¦¬í•©ë‹ˆë‹¤."""
    # 1. ì‚¬ê³  ê³¼ì • ì •ë¦¬
    if state["full_thought"]:
        with thought_container:
            # íƒ€ì´ë° ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í† í° ìˆ˜ ì‚¬ìš©
            if state.get("thinking_start_time") and state.get("thinking_end_time"):
                dur = state["thinking_end_time"] - state["thinking_start_time"]
                label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({dur:.1f}ì´ˆ)"
            else:
                label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({len(state['full_thought'].split())} tokens)"
            
            with st.expander(label, expanded=False):
                st.markdown(state["full_thought"])
    else:
        thought_container.empty()

    # 2. ë‹µë³€ ë³¸ë¬¸ ìµœì¢… ë Œë”ë§ (íˆ´íŒ ë° í•˜ì´ë¼ì´íŠ¸ ì ìš©)
    if state["full_response"]:
        if state["retrieved_docs"]:
            final_html = apply_tooltips_to_response(state["full_response"], state["retrieved_docs"])
            answer_display.markdown(final_html, unsafe_allow_html=True)
        else:
            answer_display.markdown(state["full_response"], unsafe_allow_html=True)
    else:
        answer_display.error("âš ï¸ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def render_sidebar(
    file_uploader_callback: Callable,
    model_selector_callback: Callable,
    embedding_selector_callback: Callable
):
    with st.sidebar:
        st.header(MSG_SIDEBAR_TITLE)
        is_generating = SessionManager.get("is_generating_answer")
        
        # --- 1. ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸° ---
        with st.expander("ğŸ“„ ë¬¸ì„œ ë¶ˆëŸ¬ì˜¤ê¸°", expanded=True):
            st.file_uploader(
                "PDF íŒŒì¼ ì„ íƒ", 
                type="pdf", 
                key="pdf_uploader", 
                on_change=file_uploader_callback,
                disabled=is_generating,
                label_visibility="collapsed" # ì¤‘ë³µ ë¼ë²¨ ì œê±°
            )

        # --- 2. ëª¨ë¸ ì„¤ì • ---
        with st.expander("âš™ï¸ ëª¨ë¸ ì„¤ì •", expanded=True):
            available_models = get_available_models()
            is_ollama_error = bool(available_models) and available_models[0] == MSG_ERROR_OLLAMA_NOT_RUNNING
            actual_models = [] if is_ollama_error else [m for m in available_models if "---" not in m]
            
            last_model = SessionManager.get("last_selected_model")
            
            # [ìˆ˜ì •] ì €ì¥ëœ ì„¸ì…˜ ëª¨ë¸ì´ ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°ì˜ ì´ˆê¸°ê°’ ê²°ì • ë¡œì§
            if not last_model or (actual_models and last_model not in actual_models):
                # 1. ì„¤ì •íŒŒì¼ì˜ ê¸°ë³¸ ëª¨ë¸(DEFAULT_OLLAMA_MODEL)ì´ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
                if DEFAULT_OLLAMA_MODEL in actual_models:
                    last_model = DEFAULT_OLLAMA_MODEL
                # 2. ì—†ë‹¤ë©´ ëª©ë¡ì˜ ì²« ë²ˆì§¸ ëª¨ë¸ ì„ íƒ
                elif actual_models:
                    last_model = actual_models[0]
                # 3. ëª©ë¡ë„ ì—†ë‹¤ë©´ ìƒìˆ˜ì˜ ê¸°ë³¸ê°’ ì‚¬ìš©
                else:
                    last_model = DEFAULT_OLLAMA_MODEL
                
                SessionManager.set("last_selected_model", last_model)

            try: idx = available_models.index(last_model)
            except ValueError: idx = 0

            st.selectbox(MSG_MODEL_SELECTOR_LABEL, available_models, index=idx, key="model_selector", on_change=model_selector_callback, disabled=(is_ollama_error or is_generating))

            last_emb = SessionManager.get("last_selected_embedding_model") or AVAILABLE_EMBEDDING_MODELS[0]
            try: emb_idx = AVAILABLE_EMBEDDING_MODELS.index(last_emb)
            except ValueError: emb_idx = 0
                
            st.selectbox(MSG_EMBEDDING_SELECTOR_LABEL, AVAILABLE_EMBEDDING_MODELS, index=emb_idx, key="embedding_model_selector", on_change=embedding_selector_callback, disabled=is_generating)
        
        # --- 3. ì‹œìŠ¤í…œ ìƒíƒœ ì¹´ë“œ ---
        with st.expander("ğŸ“Š " + MSG_SYSTEM_STATUS_TITLE, expanded=True):
            status_placeholder = st.empty()
            SessionManager.set("status_placeholder", status_placeholder)
            _render_status_box(status_placeholder)

        return st.container()


def render_pdf_viewer():
    _pdf_viewer_fragment()


@st.fragment
def _pdf_viewer_fragment():
    st.subheader(MSG_PDF_VIEWER_TITLE)
    pdf_path = SessionManager.get("pdf_file_path")
    if not pdf_path:
        st.info(MSG_PDF_VIEWER_NO_FILE)
        return
    if not os.path.exists(pdf_path):
        st.error("âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    try:
        with fitz.open(pdf_path) as doc:
            total_pages = len(doc)
            if "current_page" not in st.session_state: st.session_state.current_page = 1
            is_generating = SessionManager.get("is_generating_answer")
            pdf_viewer(input=pdf_path, height=UI_CONTAINER_HEIGHT, pages_to_render=[st.session_state.current_page])
            def go_prev():
                if st.session_state.current_page > 1: st.session_state.current_page -= 1
            def go_next():
                if st.session_state.current_page < total_pages: st.session_state.current_page += 1
            c1, c2, c3 = st.columns([1, 1, 1])
            with c1: st.button(MSG_PDF_VIEWER_PREV_BUTTON, key="btn_pdf_prev", use_container_width=True, disabled=(st.session_state.current_page <= 1 or is_generating), on_click=go_prev)
            with c2:
                p1, p2 = st.columns([1, 1])
                with p1: st.number_input("í˜ì´ì§€ ì´ë™", min_value=1, max_value=total_pages, value=st.session_state.current_page, label_visibility="collapsed", key="num_input_page", disabled=is_generating, on_change=lambda: setattr(st.session_state, 'current_page', int(st.session_state.num_input_page)))
                with p2: st.markdown(f"<div style='line-height: 2.3em; font-size: 1.0em;'>&nbsp;/ {total_pages} pages</div>", unsafe_allow_html=True)
            with c3: st.button(MSG_PDF_VIEWER_NEXT_BUTTON, key="btn_pdf_next", use_container_width=True, disabled=(st.session_state.current_page >= total_pages or is_generating), on_click=go_next)
    except Exception as e:
        st.error(f"PDF ì˜¤ë¥˜: {e}")


def render_left_column():
    st.markdown("""
    <style>
    .tooltip { position: relative; display: inline-block; border-bottom: 1px dotted #888; cursor: help; color: #0068c9; font-weight: bold; }
    .tooltip .tooltip-text { visibility: hidden; width: 350px; background-color: #333; color: #fff; text-align: left; border-radius: 6px; padding: 10px; font-size: 0.9em; font-weight: normal; line-height: 1.5; position: absolute; z-index: 1000; bottom: 125%; left: 50%; margin-left: -175px; opacity: 0; transition: opacity 0.3s; max-height: 200px; overflow-y: auto; box-shadow: 0px 4px 8px rgba(0,0,0,0.3); }
    .tooltip .tooltip-text::after { content: ""; position: absolute; top: 100%; left: 50%; margin-left: -5px; border-width: 5px; border-style: solid; border-color: #333 transparent transparent transparent; }
    .tooltip:hover .tooltip-text { visibility: visible; opacity: 1; }
    @media (prefers-color-scheme: dark) { .tooltip { color: #4fa8ff; } }
    </style>
    """, unsafe_allow_html=True)
    _chat_fragment()


def render_message(role: str, content: str, thought: str = None, doc_ids: list = None):
    avatar_icon = "ğŸ¤–" if role == "assistant" else "ğŸ‘¤"
    with st.chat_message(role, avatar=avatar_icon):
        if thought:
            with st.expander("ğŸ§  ì‚¬ê³  ì™„ë£Œ", expanded=False):
                st.markdown(thought)
        
        # [ìµœì í™”] ID ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ë¬¸ì„œ í’€ì—ì„œ ì›ë³¸ ë¬¸ì„œ ë³µì›
        documents = []
        if role == "assistant" and doc_ids:
            doc_pool = SessionManager.get("doc_pool", {})
            documents = [doc_pool[d_id] for d in doc_ids if (d_id := d) in doc_pool]
        
        # Assistant ë©”ì‹œì§€ì´ë©´ì„œ ì°¸ê³  ë¬¸ì„œê°€ ìˆë‹¤ë©´ íˆ´íŒ ì ìš©
        if role == "assistant" and documents:
            from common.utils import apply_tooltips_to_response
            content = apply_tooltips_to_response(content, documents)
            
        st.markdown(content, unsafe_allow_html=True)


@st.fragment
def _chat_fragment():
    st.subheader(MSG_CHAT_TITLE)
    chat_container = st.container(height=UI_CONTAINER_HEIGHT, border=True)
    messages = SessionManager.get_messages()
    
    # 1. ì±„íŒ… ì´ë ¥ ë Œë”ë§
    for msg in messages:
        with chat_container: 
            render_message(
                msg["role"], 
                msg["content"], 
                thought=msg.get("thought"),
                doc_ids=msg.get("doc_ids") # documents ëŒ€ì‹  doc_ids ì „ë‹¬
            )
            
    if not messages:
        with chat_container: 
            st.info(MSG_CHAT_WELCOME)
            
    # 2. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    is_generating = SessionManager.get("is_generating_answer")
    if user_query := st.chat_input(MSG_CHAT_INPUT_PLACEHOLDER, disabled=is_generating, key="chat_input_clean"):
        SessionManager.add_message("user", user_query)
        SessionManager.add_status_log("ì§ˆë¬¸ ë¶„ì„ ì¤‘")
        
        # UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸
        status_placeholder = SessionManager.get("status_placeholder")
        _render_status_box(status_placeholder)
        with chat_container: 
            render_message("user", user_query)
            
        # RAG ì—”ì§„ í˜¸ì¶œ
        rag_engine = SessionManager.get("rag_engine")
        if rag_engine:
            from common.utils import sync_run
            result = sync_run(_stream_chat_response(rag_engine, user_query, chat_container))
            
            final_answer = result.get("response", "")
            final_thought = result.get("thought", "")
            final_docs = result.get("documents", [])
            
            if final_answer and not final_answer.startswith("âŒ"):
                SessionManager.add_message(
                    "assistant", 
                    final_answer, 
                    thought=final_thought,
                    documents=final_docs # SessionManager.add_message ë‚´ë¶€ì—ì„œ doc_idsë¡œ ë³€í™˜ë¨
                )
                SessionManager.replace_last_status_log("ë‹µë³€ ì‘ì„± ì™„ë£Œ")
                SessionManager.add_status_log("ì§ˆë¬¸ ê°€ëŠ¥")
                st.rerun()
        else: 
            st.toast(MSG_CHAT_NO_QA_SYSTEM, icon="âš ï¸")
