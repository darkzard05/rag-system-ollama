"""
Streamlit UI ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ íŒŒì¼.
Clean & Minimal Version: ë¶€ê°€ ìš”ì†Œ ì œê±°, ì§ê´€ì ì¸ ë¡œë”© ë° ìŠ¤íŠ¸ë¦¬ë°.
"""

from __future__ import annotations
import asyncio
import time
import logging
import os
import re
from contextlib import aclosing
from typing import Callable, Optional

import streamlit as st

from core.session import SessionManager
from common.utils import apply_tooltips_to_response
from common.config import (
    AVAILABLE_EMBEDDING_MODELS,
    UI_CONTAINER_HEIGHT,
    MSG_SYSTEM_STATUS_TITLE,
    MSG_PDF_VIEWER_NO_FILE,
    MSG_CHAT_INPUT_PLACEHOLDER,
    MSG_CHAT_NO_QA_SYSTEM,
    MSG_CHAT_WELCOME,
    MSG_PREPARING_ANSWER,
)

logger = logging.getLogger(__name__)


def _render_status_box(container):
    """ì‹œìŠ¤í…œ ìƒíƒœ ë¡œê·¸ ë°•ìŠ¤ë¥¼ ìµœì‹ ìˆœ(ì—­ìˆœ)ìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤."""
    if container is None:
        return

    # [ìµœì í™”] ì„¸ì…˜ì´ ì—†ì–´ë„ ì—ëŸ¬ ì—†ì´ ë¹ˆ ëª©ë¡ ë°˜í™˜
    try:
        status_logs = SessionManager.get("status_logs", [])
    except:
        status_logs = []

    if not status_logs:
        container.info("ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘...")
        return

    # [ìŠ¤íƒ€ì¼ë§: ìµœì‹ ìˆœ ì¶œë ¥ ì „ìš© í…Œë§ˆ]
    log_html = """
    <style>
    .status-outer-container {
        border: 1px solid rgba(49, 51, 63, 0.2);
        border-radius: 12px;
        padding: 10px;
        background-color: rgba(128, 128, 128, 0.05);
        margin-bottom: 15px;
        width: 100%;
        box-shadow: inset 0 1px 3px rgba(0,0,0,0.1);
    }
    .status-container {
        font-family: 'Source Code Pro', 'Consolas', monospace;
        height: 140px;
        overflow-y: auto;
        overflow-x: hidden;
        display: flex;
        flex-direction: column;
        gap: 4px;
    }
    .status-line {
        flex-shrink: 0;
        line-height: 1.5;
        margin: 0px !important;
        padding: 4px 8px !important;
        font-size: 0.8rem;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
        color: #666;
        border-left: 2px solid transparent;
        transition: all 0.2s;
    }
    .status-newest { 
        color: #0068c9;
        font-weight: 600;
        background-color: rgba(0, 104, 201, 0.1);
        border-radius: 6px;
        border-left: 3px solid #0068c9;
    }
    
    @media (prefers-color-scheme: dark) {
        .status-outer-container { background-color: rgba(255, 255, 255, 0.05); }
        .status-line { color: #aaa; }
        .status-newest { color: #4fa8ff; background-color: rgba(79, 168, 255, 0.15); border-left-color: #4fa8ff; }
    }
    
    .status-container::-webkit-scrollbar { width: 4px; }
    .status-container::-webkit-scrollbar-thumb { background: rgba(128, 128, 128, 0.3); border-radius: 10px; }
    </style>
    """

    import html

    log_content = ""
    reversed_logs = status_logs[::-1]

    for i, log in enumerate(reversed_logs):
        safe_log = html.escape(log)
        clean_log = re.sub(
            r"[^\x00-\x7Fê°€-í£\s\(\)\[\]\/\:\.\-\>]", "", safe_log
        ).strip()
        if not clean_log and safe_log:
            clean_log = safe_log.strip()

        is_newest = i == 0
        cls = "status-newest" if is_newest else ""
        icon = "â—" if is_newest else "â—‹"

        log_content += f"<div class='status-line {cls}' title='{clean_log}'>{icon} {clean_log}</div>"

    full_html = f"{log_html}<div class='status-outer-container'><div class='status-container'>{log_content}</div></div>"
    container.markdown(full_html, unsafe_allow_html=True)


async def _stream_chat_response(rag_engine, user_query: str, chat_container) -> str:
    """
    RAG ì—”ì§„ì˜ ì´ë²¤íŠ¸ë¥¼ ìˆ˜ì‹ í•˜ì—¬ ì‚¬ê³  ê³¼ì •ê³¼ ë‹µë³€ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    from common.utils import normalize_latex_delimiters  # ë£¨í”„ ë°–ìœ¼ë¡œ ì´ë™

    state = {
        "full_response": "",
        "full_thought": "",
        "retrieved_docs": [],
        "start_time": time.time(),
        "thinking_start_time": None,
        "thinking_end_time": None,
    }

    current_llm = SessionManager.get("llm")
    if not current_llm:
        return "âŒ ì˜¤ë¥˜: LLM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    status_placeholder = SessionManager.get("status_placeholder")
    run_config = {"configurable": {"llm": current_llm}}
    SessionManager.set("is_generating_answer", True)

    try:
        with chat_container:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                # UI ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”: ê³µê°„ë§Œ í™•ë³´í•˜ê³  ì•„ë¬´ê²ƒë„ í‘œì‹œí•˜ì§€ ì•ŠìŒ
                thought_container = st.empty()
                thought_display = None  # ì‚¬ê³  ê³¼ì • í…ìŠ¤íŠ¸ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì“¸ ê³µê°„

                answer_display = st.empty()
                answer_display.markdown(f"âŒ› {MSG_PREPARING_ANSWER}")

                # ìŠ¤íŠ¸ë¦¬ë° ì´ë²¤íŠ¸ ìˆ˜ì‹ 
                async with aclosing(
                    rag_engine.astream_events(
                        {"input": user_query}, config=run_config, version="v2"
                    )
                ) as event_stream:
                    try:
                        async for event in event_stream:
                            kind, name, data = (
                                event["event"],
                                event.get("name", "Unknown"),
                                event.get("data", {}),
                            )

                            # ìƒíƒœ ë°•ìŠ¤ ë™ê¸°í™”
                            if kind in ["on_chain_start", "on_chain_end"]:
                                _render_status_box(status_placeholder)

                            # ì»¤ìŠ¤í…€ ì‘ë‹µ ì´ë²¤íŠ¸ ì²˜ë¦¬ (Integrity Protocol)
                            if kind == "on_custom_event" and name == "response_chunk":
                                content = data.get("chunk")
                                thought = data.get("thought")

                                # 1. ì‚¬ê³  ê³¼ì • ì²˜ë¦¬
                                if thought:
                                    if not state["full_thought"]:
                                        state["thinking_start_time"] = time.time()
                                        # [ê°œì„ ] ì‹¤ì œ ì‚¬ê³  í† í°ì´ ë“¤ì–´ì˜¬ ë•Œë§Œ ìµìŠ¤íŒ¬ë” ìƒì„±
                                        with thought_container:
                                            thought_expander = st.expander(
                                                "ğŸ§  ì‚¬ê³  ê³¼ì • ì‘ì„± ì¤‘...",
                                                expanded=False,
                                            )
                                            thought_display = thought_expander.empty()

                                    state["full_thought"] += thought
                                    if thought_display:
                                        thought_display.markdown(
                                            state["full_thought"] + "â–Œ"
                                        )

                                # 2. ë‹µë³€ ë³¸ë¬¸ ì²˜ë¦¬
                                if content:
                                    if not state["full_response"]:
                                        # ì²« ë‹µë³€ í† í°ì´ ë“¤ì–´ì˜¤ë©´ ì‚¬ê³  ê³¼ì • ì¢…ë£Œë¡œ ê°„ì£¼
                                        state["thinking_end_time"] = time.time()
                                        if state["full_thought"]:
                                            thinking_dur = (
                                                state["thinking_end_time"]
                                                - state["thinking_start_time"]
                                            )
                                            with thought_container:
                                                label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({thinking_dur:.1f}ì´ˆ)"
                                                with st.expander(label, expanded=False):
                                                    st.markdown(state["full_thought"])

                                    state["full_response"] += content

                                    # [ìˆ˜ì •] ìˆ˜ì‹ êµ¬ë¶„ì ì‹¤ì‹œê°„ ì •ê·œí™” ì ìš©
                                    display_text = normalize_latex_delimiters(
                                        state["full_response"]
                                    )
                                    answer_display.markdown(
                                        display_text + "â–Œ", unsafe_allow_html=True
                                    )

                            # ì—”ì§„ ë‚´ë¶€ ë°ì´í„° ìº¡ì²˜
                            elif kind == "on_chain_end":
                                if name == "retrieve":
                                    output = data.get("output", {})
                                    if "documents" in output:
                                        state["retrieved_docs"] = output["documents"]

                                elif name == "generate_response":
                                    output = data.get("output", {})
                                    if isinstance(output, dict):
                                        if (
                                            "documents" in output
                                            and not state["retrieved_docs"]
                                        ):
                                            state["retrieved_docs"] = output[
                                                "documents"
                                            ]
                                        if "response" in output and len(
                                            output["response"]
                                        ) > len(state["full_response"]):
                                            state["full_response"] = output["response"]
                    except asyncio.CancelledError:
                        logger.info("[UI] ìŠ¤íŠ¸ë¦¬ë°ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        raise

                # ìµœì¢… ë Œë”ë§ ë° ì •ë¦¬
                _finalize_ui_rendering(thought_container, answer_display, state)

        return {
            "response": state["full_response"],
            "thought": state["full_thought"],
            "documents": state["retrieved_docs"],
        }

    except Exception as e:
        logger.error(f"UI ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}", exc_info=True)
        from common.utils import format_error_message

        friendly_msg = format_error_message(e)

        # [ìµœì í™”] ìƒíƒœì°½ì— ì—ëŸ¬ ë©”ì‹œì§€ ì¦‰ì‹œ ë°˜ì˜
        SessionManager.add_status_log(friendly_msg)
        return {"response": friendly_msg, "thought": "", "documents": []}
    finally:
        SessionManager.set("is_generating_answer", False)
        _render_status_box(status_placeholder)


def _finalize_ui_rendering(thought_container, answer_display, state):
    """ë‹µë³€ ìƒì„±ì´ ëë‚œ í›„ UIë¥¼ ìµœì¢… ìƒíƒœë¡œ ì •ë¦¬í•©ë‹ˆë‹¤."""
    # 1. ì‚¬ê³  ê³¼ì • ì •ë¦¬
    if state["full_thought"]:
        with thought_container:
            # íƒ€ì´ë° ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í† í° ìˆ˜ ì‚¬ìš©
            if state.get("thinking_start_time") and state.get("thinking_end_time"):
                dur = state["thinking_end_time"] - state["thinking_start_time"]
                label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({dur:.1f}ì´ˆ)"
            else:
                label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({len(state['full_thought'].split())} tokens)"

            with st.expander(label, expanded=False):
                st.markdown(state["full_thought"])
    else:
        thought_container.empty()

    # 2. ë‹µë³€ ë³¸ë¬¸ ìµœì¢… ë Œë”ë§ (íˆ´íŒ ë° í•˜ì´ë¼ì´íŠ¸ ì ìš©)
    if state["full_response"]:
        if state["retrieved_docs"]:
            final_html = apply_tooltips_to_response(
                state["full_response"], state["retrieved_docs"]
            )
            answer_display.markdown(final_html, unsafe_allow_html=True)
        else:
            answer_display.markdown(state["full_response"], unsafe_allow_html=True)
    else:
        answer_display.error("âš ï¸ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def render_sidebar(
    file_uploader_callback: Callable,
    model_selector_callback: Callable,
    embedding_selector_callback: Callable,
    is_generating: bool = False,
    current_file_name: Optional[str] = None,
    current_embedding_model: Optional[str] = None,
):
    # ì»¤ìŠ¤í…€ ì–‡ì€ êµ¬ë¶„ì„  ì»´í¬ë„ŒíŠ¸
    thin_divider = "<hr style='margin: 12px 0; border: none; border-top: 1px solid rgba(49, 51, 63, 0.1);'>"

    with st.sidebar:
        # --- 1. ë¸Œëœë”© ì„¹ì…˜ (ì¦‰ì‹œ ì¶œë ¥) ---
        st.markdown(
            """
            <div style='display: flex; align-items: center; gap: 10px; margin-bottom: 5px;'>
                <span style='font-size: 2.2rem;'>ğŸ¤–</span>
                <div>
                    <div style='font-size: 1.1rem; font-weight: bold; line-height: 1.2;'>GraphRAG-Ollama</div>
                    <div style='font-size: 0.75rem; color: #888;'>Local Intelligence RAG System</div>
                </div>
            </div>
        """,
            unsafe_allow_html=True,
        )

        st.markdown(thin_divider, unsafe_allow_html=True)

        # --- 2. ë¬¸ì„œ ì œì–´ ì„¹ì…˜ ---
        st.markdown("**ğŸ“„ ë¬¸ì„œ ë¶„ì„**")
        st.file_uploader(
            "PDF íŒŒì¼ ì—…ë¡œë“œ",
            type="pdf",
            key="pdf_uploader",
            on_change=file_uploader_callback,
            disabled=is_generating,
            label_visibility="collapsed",
        )

        if current_file_name:
            st.caption(f"í˜„ì¬: **{current_file_name}**")
        else:
            st.caption("ë¶„ì„í•  PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")

        st.markdown(thin_divider, unsafe_allow_html=True)

        # --- 3. ëª¨ë¸ ì„¤ì • ì„¹ì…˜ (í”Œë ˆì´ìŠ¤í™€ë”) ---
        st.markdown("**âš™ï¸ ëª¨ë¸ ì„¤ì •**")
        model_selector_placeholder = st.empty()

        with st.popover("ğŸ”§ ê³ ê¸‰ ì„¤ì •", use_container_width=True):
            st.markdown("#### ì„ë² ë”© ì„¤ì •")
            last_emb = current_embedding_model or AVAILABLE_EMBEDDING_MODELS[0]
            try:
                emb_idx = AVAILABLE_EMBEDDING_MODELS.index(last_emb)
            except ValueError:
                emb_idx = 0

            st.selectbox(
                "ì„ë² ë”© ëª¨ë¸",
                AVAILABLE_EMBEDDING_MODELS,
                index=emb_idx,
                key="embedding_model_selector",
                on_change=embedding_selector_callback,
                disabled=is_generating,
            )
            st.info("ğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í™œì„± ì¤‘")

        st.markdown(thin_divider, unsafe_allow_html=True)

        # --- 4. ì‹œìŠ¤í…œ ìƒíƒœ ì„¹ì…˜ ---
        st.markdown(f"**ğŸ“Š {MSG_SYSTEM_STATUS_TITLE}**")
        status_placeholder = st.empty()

        # ìƒíƒœ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ ë Œë”ë§ (ì´ˆê¸° ë Œë”ë§ ì‹œì—ëŠ” ê±´ë„ˆëœ€)
        if "_initialized" in st.session_state:
            _render_status_box(status_placeholder)

        return {
            "model_selector": model_selector_placeholder,
            "status_container": status_placeholder,
        }


def render_pdf_viewer():
    _pdf_viewer_fragment()


@st.fragment
def _pdf_viewer_fragment():
    import fitz  # PyMuPDF
    from streamlit_pdf_viewer import pdf_viewer

    # [UI ëŒ€ì¹­ì„±] ì±„íŒ…ì°½ê³¼ ë™ì¼í•˜ê²Œ í…Œë‘ë¦¬ê°€ ìˆëŠ” ì»¨í…Œì´ë„ˆ ìƒì„±
    viewer_container = st.container(height=UI_CONTAINER_HEIGHT, border=True)

    # [ìˆ˜ì •] ì„¸ì…˜ ì´ˆê¸°í™” ì „ì—ë„ ì•ˆì „í•˜ë„ë¡ ê¸°ë³¸ê°’ None ì œê³µ ë° ëª…ì‹œì  ì²´í¬
    pdf_path_raw = SessionManager.get("pdf_file_path", None)

    if not pdf_path_raw:
        with viewer_container:
            st.info(MSG_PDF_VIEWER_NO_FILE)
        return

    # [ìˆ˜ì •] ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ì—¬ ì •í™•í•œ íŒŒì¼ ì°¸ì¡° ë³´ì¥
    pdf_path = os.path.abspath(pdf_path_raw)

    if not os.path.exists(pdf_path):
        with viewer_container:
            st.error(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    try:
        with fitz.open(pdf_path) as doc:
            total_pages = len(doc)
            if "current_page" not in st.session_state:
                st.session_state.current_page = 1

            # [ìˆ˜ì •] ì„¸ì…˜ ì´ˆê¸°í™” ì „ì—ë„ ì•ˆì „í•˜ë„ë¡ ê¸°ë³¸ê°’ False ì œê³µ
            is_generating = SessionManager.get("is_generating_answer", False) or False

            # 1. PDF ë·°ì–´ ë©”ì¸ ì˜ì—­
            with viewer_container:
                pdf_viewer(
                    input=pdf_path,
                    height=UI_CONTAINER_HEIGHT,
                    pages_to_render=[st.session_state.current_page],
                )

            # 2. ì„¸ë ¨ëœ ë²„íŠ¼ ê·¸ë£¹í˜• íƒìƒ‰ íˆ´ë°”
            # ë¹„ìœ¨ ì¡°ì •: [ì´ì „|ë‹¤ìŒ | í˜ì´ì§€ì •ë³´ | ìŠ¬ë¼ì´ë”]
            c1, c2, c3, c4 = st.columns([4.0, 1.2, 0.4, 0.4])

            with c1:
                # ìš°ì¸¡ì˜ ë„“ì€ ê³µê°„ì„ ì°¨ì§€í•˜ëŠ” ìŠ¬ë¼ì´ë”
                new_page = st.slider(
                    "page_nav_wide",
                    min_value=1,
                    max_value=total_pages,
                    value=st.session_state.current_page,
                    key="pdf_nav_slider_wide",
                    disabled=is_generating,
                    label_visibility="collapsed",
                )
                if new_page != st.session_state.current_page:
                    st.session_state.current_page = new_page
                    st.rerun()

            with c2:
                # í˜ì´ì§€ ì •ë³´ë¥¼ ë²„íŠ¼ ë°”ë¡œ ì˜†ì— ë°°ì¹˜
                st.markdown(
                    f"<div style='text-align: center; line-height: 2.3rem; font-family: monospace; font-size: 0.95rem; color: #888;'>"
                    f"<span style='color: #0068c9; font-weight: bold;'>{st.session_state.current_page}</span> / {total_pages}"
                    f"</div>",
                    unsafe_allow_html=True,
                )

            with c3:
                if st.button(
                    "â€¹",
                    use_container_width=True,
                    disabled=(st.session_state.current_page <= 1 or is_generating),
                    key="btn_pdf_prev_grp",
                    help="ì´ì „ í˜ì´ì§€",
                ):
                    st.session_state.current_page -= 1
                    st.rerun()

            with c4:
                if st.button(
                    "â€º",
                    use_container_width=True,
                    disabled=(
                        st.session_state.current_page >= total_pages or is_generating
                    ),
                    key="btn_pdf_next_grp",
                    help="ë‹¤ìŒ í˜ì´ì§€",
                ):
                    st.session_state.current_page += 1
                    st.rerun()

    except Exception as e:
        with viewer_container:
            st.error(f"PDF ì˜¤ë¥˜: {e}")


def inject_custom_css():
    """ì•± ì „ë°˜ì— ê±¸ì¹œ ì»¤ìŠ¤í…€ CSSë¥¼ ì£¼ì…í•©ë‹ˆë‹¤."""
    # Streamlit 1.34+ ì—ì„œ ì§€ì›í•˜ëŠ” st.html ì‚¬ìš© (ì•ˆì „ì„± í–¥ìƒ)
    st.html("""
    <style>
    /* Streamlit ê¸°ë³¸ ìƒíƒœ í‘œì‹œê¸°(Running...) ìˆ¨ê¸°ê¸° */
    [data-testid="stStatusWidget"] {
        visibility: hidden;
        display: none;
    }
    
    /* íˆ´íŒ ê¸°ë³¸ ìŠ¤íƒ€ì¼ */
    .tooltip { 
        position: relative; 
        display: inline-block; 
        border-bottom: 1px dotted #888; 
        cursor: help; 
        color: #0068c9; 
        font-weight: bold; 
    }
    .tooltip .tooltip-text { 
        visibility: hidden; 
        width: 350px; 
        background-color: #333; 
        color: #fff; 
        text-align: left; 
        border-radius: 8px; 
        padding: 12px; 
        font-size: 0.85rem; 
        font-weight: normal; 
        line-height: 1.5; 
        position: absolute; 
        z-index: 1000; 
        bottom: 125%; 
        left: 50%; 
        margin-left: -175px; 
        opacity: 0; 
        transition: opacity 0.3s, transform 0.3s; 
        transform: translateY(10px);
        max-height: 250px; 
        overflow-y: auto; 
        box-shadow: 0px 8px 16px rgba(0,0,0,0.4); 
        border: 1px solid #444;
    }
    .tooltip .tooltip-text::after { 
        content: ""; 
        position: absolute; 
        top: 100%; 
        left: 50%; 
        margin-left: -5px; 
        border-width: 5px; 
        border-style: solid; 
        border-color: #333 transparent transparent transparent; 
    }
    .tooltip:hover .tooltip-text { 
        visibility: visible; 
        opacity: 1; 
        transform: translateY(0);
    }
    
    /* ë‹¤í¬ ëª¨ë“œ ëŒ€ì‘ */
    @media (prefers-color-scheme: dark) { 
        .tooltip { color: #4fa8ff; } 
        .tooltip .tooltip-text { background-color: #262730; border-color: #444; }
        .tooltip .tooltip-text::after { border-color: #262730 transparent transparent transparent; }
    }
    
    /* ì±„íŒ… ë©”ì‹œì§€ ë‚´ ì½”ë“œ ë¸”ë¡ ìŠ¤íƒ€ì¼ ê°œì„  */
    code {
        background-color: rgba(128, 128, 128, 0.15);
        padding: 0.2rem 0.4rem;
        border-radius: 4px;
        font-family: 'Source Code Pro', monospace;
    }
    
    /* PDF ì»¨íŠ¸ë¡¤ëŸ¬ íˆ´ë°” ìŠ¤íƒ€ì¼ (ë” ì„¸ë ¨ëœ ë²„ì „) */
    .pdf-nav-container {
        background-color: rgba(128, 128, 128, 0.08);
        border-radius: 12px;
        padding: 4px 12px;
        margin-top: -8px;
        border: 1px solid rgba(49, 51, 63, 0.1);
        display: flex;
        align-items: center;
    }
    /* ìŠ¬ë¼ì´ë” ë†’ì´ ë° ì—¬ë°± ì¡°ì • */
    div[data-testid="stSlider"] {
        padding-top: 10px;
        padding-bottom: 0px;
    }
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ë¯¸ì„¸ ì¡°ì • */
    .stButton > button {
        border-radius: 8px !important;
        border: 1px solid rgba(49, 51, 63, 0.1) !important;
        background-color: transparent !important;
        transition: all 0.2s ease;
    }
    .stButton > button:hover {
        background-color: rgba(0, 104, 201, 0.1) !important;
        border-color: #0068c9 !important;
    }
    </style>
    """)


def render_left_column():
    _chat_fragment()


def render_message(role: str, content: str, thought: str = None, doc_ids: list = None):
    avatar_icon = "ğŸ¤–" if role == "assistant" else "ğŸ‘¤"
    with st.chat_message(role, avatar=avatar_icon):
        if thought and thought.strip():
            with st.expander("ğŸ§  ì‚¬ê³  ì™„ë£Œ", expanded=False):
                st.markdown(thought)

        # [ìµœì í™”] ID ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ë¬¸ì„œ í’€ì—ì„œ ì›ë³¸ ë¬¸ì„œ ë³µì›
        documents = []
        if role == "assistant" and doc_ids:
            # [ìˆ˜ì •] ì„¸ì…˜ ì´ˆê¸°í™” ì „ì—ë„ ì•ˆì „í•˜ë„ë¡ ê¸°ë³¸ê°’ {} ì œê³µ
            doc_pool = SessionManager.get("doc_pool", {}) or {}
            documents = [doc_pool[d_id] for d in doc_ids if (d_id := d) in doc_pool]

        # Assistant ë©”ì‹œì§€ì´ë©´ì„œ ì°¸ê³  ë¬¸ì„œê°€ ìˆë‹¤ë©´ íˆ´íŒ ì ìš©
        if role == "assistant":
            from common.utils import (
                apply_tooltips_to_response,
                normalize_latex_delimiters,
            )

            # 1. ìˆ˜ì‹ ì •ê·œí™”
            content = normalize_latex_delimiters(content)

            # 2. íˆ´íŒ ì ìš©
            if documents:
                content = apply_tooltips_to_response(content, documents)

        st.markdown(content, unsafe_allow_html=True)


def _chat_fragment():
    chat_container = st.container(height=UI_CONTAINER_HEIGHT, border=True)
    # [ìˆ˜ì •] ì„¸ì…˜ ì´ˆê¸°í™” ì „ì—ë„ ì•ˆì „í•˜ë„ë¡ ê¸°ë³¸ê°’ [] ì œê³µ
    messages = SessionManager.get_messages() or []
    pdf_path = SessionManager.get("pdf_file_path")
    pdf_processed = SessionManager.get("pdf_processed", False)
    is_generating = bool(st.session_state.get("is_generating_answer", False))

    # ë¬¸ì„œ ë¶„ì„ ì¤‘ì¸ì§€ íŒë³„ (íŒŒì¼ì€ ì—…ë¡œë“œëëŠ”ë° ì•„ì§ ì²˜ë¦¬ê°€ ì•ˆ ëœ ìƒíƒœ)
    is_processing_pdf = bool(pdf_path and not pdf_processed)

    # 1. ì±„íŒ… ì´ë ¥ ë Œë”ë§
    with chat_container:
        for msg in messages:
            render_message(
                msg["role"],
                msg["content"],
                thought=msg.get("thought"),
                doc_ids=msg.get("doc_ids"),
            )

        if not messages:
            if is_processing_pdf:
                st.info(
                    "ğŸ“„ **ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤.**\n\në‚´ìš©ì´ ë§ì„ ê²½ìš° ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì±„íŒ…ì´ í™œì„±í™”ë©ë‹ˆë‹¤."
                )
            else:
                st.info(MSG_CHAT_WELCOME)

    # 2. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    # ì…ë ¥ì°½ ìƒíƒœ ê²°ì •
    input_disabled = is_generating or is_processing_pdf
    input_placeholder = (
        "ë¬¸ì„œ ë¶„ì„ ì¤‘ì—ëŠ” ì§ˆë¬¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤..."
        if is_processing_pdf
        else (
            "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."
            if is_generating
            else MSG_CHAT_INPUT_PLACEHOLDER
        )
    )

    if user_query := st.chat_input(
        input_placeholder, disabled=input_disabled, key="chat_input_clean"
    ):
        SessionManager.add_message("user", user_query)
        SessionManager.add_status_log("ì§ˆë¬¸ ë¶„ì„ ì¤‘")

        # UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸
        status_placeholder = SessionManager.get("status_placeholder")
        _render_status_box(status_placeholder)
        with chat_container:
            render_message("user", user_query)

        # RAG ì—”ì§„ í˜¸ì¶œ
        rag_engine = SessionManager.get("rag_engine")
        if rag_engine:
            from common.utils import sync_run

            result = sync_run(
                _stream_chat_response(rag_engine, user_query, chat_container)
            )

            final_answer = result.get("response", "")
            final_thought = result.get("thought", "")
            final_docs = result.get("documents", [])

            if final_answer and not final_answer.startswith("âŒ"):
                SessionManager.add_message(
                    "assistant",
                    final_answer,
                    thought=final_thought,
                    documents=final_docs,  # SessionManager.add_message ë‚´ë¶€ì—ì„œ doc_idsë¡œ ë³€í™˜ë¨
                )
                SessionManager.replace_last_status_log("ë‹µë³€ ì‘ì„± ì™„ë£Œ")
                SessionManager.add_status_log("ì§ˆë¬¸ ê°€ëŠ¥")
                st.rerun()
        else:
            st.toast(MSG_CHAT_NO_QA_SYSTEM, icon="âš ï¸")
