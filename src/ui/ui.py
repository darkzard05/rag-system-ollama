"""
Streamlit UI ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ íŒŒì¼.
Clean & Minimal Version: ë¶€ê°€ ìš”ì†Œ ì œê±°, ì§ê´€ì ì¸ ë¡œë”© ë° ìŠ¤íŠ¸ë¦¬ë°.
"""

from __future__ import annotations

import logging
import os
import time
from collections.abc import Callable
from contextlib import aclosing

import streamlit as st

from api.streaming_handler import get_adaptive_controller, get_streaming_handler
from common.config import (
    AVAILABLE_EMBEDDING_MODELS,
    MSG_CHAT_INPUT_PLACEHOLDER,
    MSG_CHAT_NO_QA_SYSTEM,
    MSG_CHAT_WELCOME,
    MSG_PDF_VIEWER_NO_FILE,
    MSG_PREPARING_ANSWER,
    MSG_SYSTEM_STATUS_TITLE,
    UI_CONTAINER_HEIGHT,
)
from common.utils import apply_tooltips_to_response
from core.session import SessionManager
from ui.components.status_box import render_status_box as _render_status_box

logger = logging.getLogger(__name__)


async def _stream_chat_response(rag_engine, user_query: str, chat_container) -> str:
    """
    ì ì‘í˜• ìŠ¤íŠ¸ë¦¬ë° í•¸ë“¤ëŸ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ê³  ê³¼ì •ê³¼ ë‹µë³€ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ë Œë”ë§í•©ë‹ˆë‹¤.
    """

    state = {
        "full_response": "",
        "full_thought": "",
        "retrieved_docs": [],
        "start_time": time.time(),
        "thinking_start_time": None,
        "thinking_end_time": None,
    }

    current_llm = SessionManager.get("llm")
    if not current_llm:
        return "âŒ ì˜¤ë¥˜: LLM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

    status_placeholder = SessionManager.get("status_placeholder")
    run_config = {"configurable": {"llm": current_llm}}
    SessionManager.set("is_generating_answer", True)

    # í•¸ë“¤ëŸ¬ ë° ì œì–´ê¸° íšë“
    handler = get_streaming_handler()
    controller = get_adaptive_controller()

    # UI ë””ë°”ìš´ì‹± ì„¤ì • (ë£¨í”„ ì™¸ë¶€ì—ì„œ ì •ì˜í•˜ì—¬ UnboundLocalError ë°©ì§€)
    last_render_time = 0.0
    render_interval = 0.05  # ì•½ 20fpsë¡œ UI ì—…ë°ì´íŠ¸ ì œí•œ

    try:
        with chat_container:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                thought_container = st.empty()
                thought_display = None
                answer_display = st.empty()
                answer_display.markdown(f"âŒ› {MSG_PREPARING_ANSWER}")

                # ì ì‘í˜• ìŠ¤íŠ¸ë¦¬ë° ì ìš© ë° ë¦¬ì†ŒìŠ¤ ì•ˆì „ ê´€ë¦¬
                event_generator = rag_engine.astream_events(
                    {"input": user_query}, config=run_config, version="v2"
                )

                async with aclosing(
                    handler.stream_graph_events(
                        event_generator, adaptive_controller=controller
                    )
                ) as stream:
                    async for chunk in stream:
                        # ìƒíƒœ ë°•ìŠ¤ ë™ê¸°í™” (ì£¼ê¸°ì : ì˜¤ë²„í—¤ë“œ ê°ì†Œë¥¼ ìœ„í•´ ë¹ˆë„ ë‚®ì¶¤)
                        if chunk.chunk_index % 20 == 0:
                            _render_status_box(status_placeholder)

                        # 1. ë©”íƒ€ë°ì´í„°(ë¬¸ì„œ) ì²˜ë¦¬
                        if chunk.metadata and "documents" in chunk.metadata:
                            state["retrieved_docs"] = chunk.metadata["documents"]

                        # 2. ì‚¬ê³  ê³¼ì • ì²˜ë¦¬
                        if chunk.thought:
                            if not state["full_thought"]:
                                state["thinking_start_time"] = time.time()
                                with thought_container:
                                    thought_expander = st.expander(
                                        "ğŸ§  ì‚¬ê³  ê³¼ì • ì‘ì„± ì¤‘...", expanded=False
                                    )
                                    thought_display = thought_expander.empty()

                            state["full_thought"] += chunk.thought

                            # ì‚¬ê³  ê³¼ì • ë””ë°”ìš´ì‹±
                            current_time = time.time()
                            if current_time - last_render_time > render_interval:
                                if thought_display:
                                    thought_display.markdown(
                                        state["full_thought"] + "â–Œ"
                                    )
                                last_render_time = current_time

                        # 3. ë‹µë³€ ë³¸ë¬¸ ì²˜ë¦¬
                        if chunk.content:
                            if not state["full_response"]:
                                state["thinking_end_time"] = time.time()
                                if state["full_thought"]:
                                    thinking_dur = (
                                        state["thinking_end_time"]
                                        - state["thinking_start_time"]
                                    )
                                    with thought_container:
                                        label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({thinking_dur:.1f}ì´ˆ)"
                                        with st.expander(label, expanded=False):
                                            st.markdown(state["full_thought"])

                            state["full_response"] += chunk.content

                            # UI ë Œë”ë§ ì‹œê°„ ì¸¡ì • ë° ë””ë°”ìš´ì‹± ì ìš©
                            current_time = time.time()
                            if (
                                current_time - last_render_time > render_interval
                                or chunk.is_final
                            ):
                                render_start = current_time

                                # ì„±ëŠ¥ ìµœì í™”: ìŠ¤íŠ¸ë¦¬ë° ì¤‘ì—ëŠ” ë¬´ê±°ìš´ ìˆ˜ì‹ ì •ê·œí™”ë¥¼ ê±´ë„ˆë›°ê³  ìµœì¢… ê²°ê³¼ì—ì„œë§Œ ìˆ˜í–‰
                                answer_display.markdown(
                                    state["full_response"] + "â–Œ", unsafe_allow_html=True
                                )

                                # UI ë Œë”ë§ ì‹œê°„ ê¸°ë¡ (ì ì‘í˜• ì œì–´ìš©)
                                render_latency = (time.time() - render_start) * 1000
                                controller.record_latency(render_latency)
                                last_render_time = time.time()

                # ìµœì¢… ë Œë”ë§ ë° ì •ë¦¬
                _finalize_ui_rendering(thought_container, answer_display, state)

        return {
            "response": state["full_response"],
            "thought": state["full_thought"],
            "documents": state["retrieved_docs"],
        }

    except Exception as e:
        logger.error(f"UI ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}", exc_info=True)
        from common.utils import format_error_message

        friendly_msg = format_error_message(e)

        # [ìµœì í™”] ìƒíƒœì°½ì— ì—ëŸ¬ ë©”ì‹œì§€ ì¦‰ì‹œ ë°˜ì˜
        SessionManager.add_status_log(friendly_msg)
        return {"response": friendly_msg, "thought": "", "documents": []}
    finally:
        SessionManager.set("is_generating_answer", False)
        _render_status_box(status_placeholder)


def _finalize_ui_rendering(thought_container, answer_display, state):
    """ë‹µë³€ ìƒì„±ì´ ëë‚œ í›„ UIë¥¼ ìµœì¢… ìƒíƒœë¡œ ì •ë¦¬í•©ë‹ˆë‹¤."""
    # 1. ì‚¬ê³  ê³¼ì • ì •ë¦¬
    if state["full_thought"]:
        with thought_container:
            # íƒ€ì´ë° ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ í† í° ìˆ˜ ì‚¬ìš©
            if state.get("thinking_start_time") and state.get("thinking_end_time"):
                dur = state["thinking_end_time"] - state["thinking_start_time"]
                label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({dur:.1f}ì´ˆ)"
            else:
                label = f"ğŸ§  ì‚¬ê³  ì™„ë£Œ ({len(state['full_thought'].split())} tokens)"

            with st.expander(label, expanded=False):
                st.markdown(state["full_thought"])
    else:
        thought_container.empty()

    # 2. ë‹µë³€ ë³¸ë¬¸ ìµœì¢… ë Œë”ë§ (íˆ´íŒ ë° í•˜ì´ë¼ì´íŠ¸ ì ìš©)
    if state["full_response"]:
        if state["retrieved_docs"]:
            final_html = apply_tooltips_to_response(
                state["full_response"], state["retrieved_docs"]
            )
            answer_display.markdown(final_html, unsafe_allow_html=True)
        else:
            answer_display.markdown(state["full_response"], unsafe_allow_html=True)
    else:
        answer_display.error("âš ï¸ ë‹µë³€ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def render_sidebar(
    file_uploader_callback: Callable,
    model_selector_callback: Callable,
    embedding_selector_callback: Callable,
    is_generating: bool = False,
    current_file_name: str | None = None,
    current_embedding_model: str | None = None,
    available_models: list[str] | None = None,
):
    # ì»¤ìŠ¤í…€ ì–‡ì€ êµ¬ë¶„ì„  ì»´í¬ë„ŒíŠ¸
    thin_divider = "<hr style='margin: 12px 0; border: none; border-top: 1px solid rgba(49, 51, 63, 0.1);'>"

    with st.sidebar:
        # --- 1. ë¸Œëœë”© ì„¹ì…˜ (ì¦‰ì‹œ ì¶œë ¥) ---
        st.markdown(
            """
            <div style='display: flex; align-items: center; gap: 10px; margin-bottom: 5px;'>
                <span style='font-size: 2.2rem;'>ğŸ¤–</span>
                <div>
                    <div style='font-size: 1.1rem; font-weight: bold; line-height: 1.2;'>GraphRAG-Ollama</div>
                    <div style='font-size: 0.75rem; color: #888;'>Local Intelligence RAG System</div>
                </div>
            </div>
        """,
            unsafe_allow_html=True,
        )

        st.markdown(thin_divider, unsafe_allow_html=True)

        # --- 2. ë¬¸ì„œ ì œì–´ ì„¹ì…˜ ---
        st.markdown("**ğŸ“„ ë¬¸ì„œ ë¶„ì„**")
        st.file_uploader(
            "PDF íŒŒì¼ ì—…ë¡œë“œ",
            type="pdf",
            key="pdf_uploader",
            on_change=file_uploader_callback,
            disabled=is_generating,
            label_visibility="collapsed",
        )

        if current_file_name:
            st.caption(f"í˜„ì¬: **{current_file_name}**")
        else:
            st.caption("ë¶„ì„í•  PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")

        st.markdown(thin_divider, unsafe_allow_html=True)

        # --- 3. ëª¨ë¸ ì„¤ì • ì„¹ì…˜ ---
        st.markdown("**âš™ï¸ ëª¨ë¸ ì„¤ì •**")

        # ëª¨ë¸ ëª©ë¡ ìƒíƒœì— ë”°ë¥¸ ì„ íƒì°½ ë Œë”ë§ (ì‚¬ë¼ì§ ë°©ì§€)
        from common.config import DEFAULT_OLLAMA_MODEL

        if available_models is None:
            # ë¡œë”© ì¤‘ ìƒíƒœ (ê³ ì •ëœ ìœ„ì¹˜)
            st.selectbox(
                "ë©”ì¸ LLM",
                ["ëª¨ë¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."],
                index=0,
                disabled=True,
                key="model_selector_loading",
                label_visibility="collapsed",
            )
        else:
            # ë¡œë”© ì™„ë£Œ ìƒíƒœ
            is_ollama_error = (
                available_models[0] == "Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì§€ ì•ŠìŠµë‹ˆë‹¤."
                if available_models
                else False
            )
            actual_models = (
                []
                if is_ollama_error
                else [m for m in available_models if "---" not in m]
            )

            # í˜„ì¬ ì„ íƒëœ ëª¨ë¸ ì¸ë±ìŠ¤ ê³„ì‚°
            last_model = SessionManager.get("last_selected_model")
            if not last_model or (actual_models and last_model not in actual_models):
                last_model = (
                    DEFAULT_OLLAMA_MODEL
                    if DEFAULT_OLLAMA_MODEL in actual_models
                    else (actual_models[0] if actual_models else available_models[0])
                )
                SessionManager.set("last_selected_model", last_model)

            try:
                model_idx = available_models.index(last_model)
            except ValueError:
                model_idx = 0

            st.selectbox(
                "ë©”ì¸ LLM",
                available_models,
                index=model_idx,
                key="model_selector",
                on_change=model_selector_callback,
                disabled=is_ollama_error or is_generating,
                label_visibility="collapsed",
            )

        with st.popover("ğŸ”§ ê³ ê¸‰ ì„¤ì •", use_container_width=True):
            st.markdown("#### ì„ë² ë”© ì„¤ì •")
            last_emb = current_embedding_model or AVAILABLE_EMBEDDING_MODELS[0]
            try:
                emb_idx = AVAILABLE_EMBEDDING_MODELS.index(last_emb)
            except ValueError:
                emb_idx = 0

            st.selectbox(
                "ì„ë² ë”© ëª¨ë¸",
                AVAILABLE_EMBEDDING_MODELS,
                index=emb_idx,
                key="embedding_model_selector",
                on_change=embedding_selector_callback,
                disabled=is_generating or (available_models is None),
            )
            st.info("ğŸ’¡ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í™œì„± ì¤‘")

        st.markdown(thin_divider, unsafe_allow_html=True)

        # --- 4. ì‹œìŠ¤í…œ ìƒíƒœ ì„¹ì…˜ ---
        st.markdown(f"**ğŸ“Š {MSG_SYSTEM_STATUS_TITLE}**")
        status_placeholder = st.empty()

        # ìƒíƒœ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ ë Œë”ë§ (ì´ˆê¸° ë Œë”ë§ ì‹œì—ëŠ” ê±´ë„ˆëœ€)
        if "_initialized" in st.session_state:
            _render_status_box(status_placeholder)

        return {
            "status_container": status_placeholder,
        }


def render_pdf_viewer():
    _pdf_viewer_fragment()


@st.fragment
def _pdf_viewer_fragment():
    import fitz  # PyMuPDF
    from streamlit_pdf_viewer import pdf_viewer

    # [UI ëŒ€ì¹­ì„±] ì±„íŒ…ì°½ê³¼ ë™ì¼í•˜ê²Œ í…Œë‘ë¦¬ê°€ ìˆëŠ” ì»¨í…Œì´ë„ˆ ìƒì„±
    viewer_container = st.container(height=UI_CONTAINER_HEIGHT, border=True)

    # [ìˆ˜ì •] ì„¸ì…˜ ì´ˆê¸°í™” ì „ì—ë„ ì•ˆì „í•˜ë„ë¡ ê¸°ë³¸ê°’ None ì œê³µ ë° ëª…ì‹œì  ì²´í¬
    pdf_path_raw = SessionManager.get("pdf_file_path", None)

    if not pdf_path_raw:
        with viewer_container:
            st.info(MSG_PDF_VIEWER_NO_FILE)
        return

    # [ìˆ˜ì •] ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ì—¬ ì •í™•í•œ íŒŒì¼ ì°¸ì¡° ë³´ì¥
    pdf_path = os.path.abspath(pdf_path_raw)

    if not os.path.exists(pdf_path):
        with viewer_container:
            st.error(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    try:
        with fitz.open(pdf_path) as doc:
            total_pages = len(doc)

            # [ì¶”ê°€] ë”¥ ë§í¬ ìš”ì²­ ì²˜ë¦¬
            page_to_move = SessionManager.get("pdf_page_to_move")
            if page_to_move is not None:
                # ìœ íš¨í•œ ë²”ìœ„ ë‚´ì—ì„œë§Œ ì´ë™
                target = max(1, min(int(page_to_move), total_pages))
                st.session_state.current_page = target
                # ì´ë™ í›„ ìš”ì²­ ì´ˆê¸°í™”
                SessionManager.set("pdf_page_to_move", None)

            if "current_page" not in st.session_state:
                st.session_state.current_page = 1

            # [ìˆ˜ì •] ì„¸ì…˜ ì´ˆê¸°í™” ì „ì—ë„ ì•ˆì „í•˜ë„ë¡ ê¸°ë³¸ê°’ False ì œê³µ
            is_generating = SessionManager.get("is_generating_answer", False) or False

            # 1. PDF ë·°ì–´ ë©”ì¸ ì˜ì—­
            with viewer_container:
                pdf_viewer(
                    input=pdf_path,
                    height=UI_CONTAINER_HEIGHT,
                    pages_to_render=[st.session_state.current_page],
                )

            # 2. ì„¸ë ¨ëœ ë²„íŠ¼ ê·¸ë£¹í˜• íƒìƒ‰ íˆ´ë°”
            # ë¹„ìœ¨ ì¡°ì •: [ì´ì „|ë‹¤ìŒ | í˜ì´ì§€ì •ë³´ | ìŠ¬ë¼ì´ë”]
            c1, c2, c3, c4 = st.columns([4.0, 1.2, 0.4, 0.4])

            with c1:
                # ìš°ì¸¡ì˜ ë„“ì€ ê³µê°„ì„ ì°¨ì§€í•˜ëŠ” ìŠ¬ë¼ì´ë”
                new_page = st.slider(
                    "page_nav_wide",
                    min_value=1,
                    max_value=total_pages,
                    value=st.session_state.current_page,
                    key="pdf_nav_slider_wide",
                    disabled=is_generating,
                    label_visibility="collapsed",
                )
                if new_page != st.session_state.current_page:
                    st.session_state.current_page = new_page
                    st.rerun()

            with c2:
                # í˜ì´ì§€ ì •ë³´ë¥¼ ë²„íŠ¼ ë°”ë¡œ ì˜†ì— ë°°ì¹˜
                st.markdown(
                    f"<div style='text-align: center; line-height: 2.3rem; font-family: monospace; font-size: 0.95rem; color: #888;'>"
                    f"<span style='color: #0068c9; font-weight: bold;'>{st.session_state.current_page}</span> / {total_pages}"
                    f"</div>",
                    unsafe_allow_html=True,
                )

            with c3:
                if st.button(
                    "â€¹",
                    use_container_width=True,
                    disabled=(st.session_state.current_page <= 1 or is_generating),
                    key="btn_pdf_prev_grp",
                    help="ì´ì „ í˜ì´ì§€",
                ):
                    st.session_state.current_page -= 1
                    st.rerun()

            with c4:
                if st.button(
                    "â€º",
                    use_container_width=True,
                    disabled=(
                        st.session_state.current_page >= total_pages or is_generating
                    ),
                    key="btn_pdf_next_grp",
                    help="ë‹¤ìŒ í˜ì´ì§€",
                ):
                    st.session_state.current_page += 1
                    st.rerun()

    except Exception as e:
        with viewer_container:
            st.error(f"PDF ì˜¤ë¥˜: {e}")


def inject_custom_css():
    """ì•± ì „ë°˜ì— ê±¸ì¹œ ì»¤ìŠ¤í…€ CSSë¥¼ ì£¼ì…í•©ë‹ˆë‹¤."""
    # Streamlit 1.34+ ì—ì„œ ì§€ì›í•˜ëŠ” st.html ì‚¬ìš© (ì•ˆì „ì„± í–¥ìƒ)
    st.html("""
    <style>
    /* Streamlit ê¸°ë³¸ ìƒíƒœ í‘œì‹œê¸°(Running...) ìˆ¨ê¸°ê¸° */
    [data-testid="stStatusWidget"] {
        visibility: hidden;
        display: none;
    }
    
    /* íˆ´íŒ ê¸°ë³¸ ìŠ¤íƒ€ì¼ */
    .tooltip { 
        position: relative; 
        display: inline-block; 
        border-bottom: 1px dotted #888; 
        cursor: pointer; 
        color: #0068c9; 
        font-weight: bold; 
        transition: all 0.2s;
        padding: 0 2px;
        border-radius: 4px;
    }
    .tooltip:hover {
        background-color: rgba(0, 104, 201, 0.1);
        color: #004a8b;
    }
    
    /* ì¸ìš© ë§í¬ ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì œê±° */
    .citation-link {
        text-decoration: none !important;
        color: inherit !important;
    }
    
    .tooltip .tooltip-text { 
        visibility: hidden; 
        width: 350px; 
        background-color: #333; 
        color: #fff; 
        text-align: left; 
        border-radius: 8px; 
        padding: 12px; 
        font-size: 0.85rem; 
        font-weight: normal; 
        line-height: 1.5; 
        position: absolute; 
        z-index: 1000; 
        bottom: 125%; 
        left: 50%; 
        margin-left: -175px; 
        opacity: 0; 
        transition: opacity 0.3s, transform 0.3s; 
        transform: translateY(10px);
        max-height: 250px; 
        overflow-y: auto; 
        box-shadow: 0px 8px 16px rgba(0,0,0,0.4); 
        border: 1px solid #444;
    }
    .tooltip .tooltip-text::after { 
        content: ""; 
        position: absolute; 
        top: 100%; 
        left: 50%; 
        margin-left: -5px; 
        border-width: 5px; 
        border-style: solid; 
        border-color: #333 transparent transparent transparent; 
    }
    .tooltip:hover .tooltip-text { 
        visibility: visible; 
        opacity: 1; 
        transform: translateY(0);
    }
    
    /* ë‹¤í¬ ëª¨ë“œ ëŒ€ì‘ */
    @media (prefers-color-scheme: dark) { 
        .tooltip { color: #4fa8ff; } 
        .tooltip .tooltip-text { background-color: #262730; border-color: #444; }
        .tooltip .tooltip-text::after { border-color: #262730 transparent transparent transparent; }
    }
    
    /* ì±„íŒ… ë©”ì‹œì§€ ë‚´ ì½”ë“œ ë¸”ë¡ ìŠ¤íƒ€ì¼ ê°œì„  */
    code {
        background-color: rgba(128, 128, 128, 0.15);
        padding: 0.2rem 0.4rem;
        border-radius: 4px;
        font-family: 'Source Code Pro', monospace;
    }
    
    /* PDF ì»¨íŠ¸ë¡¤ëŸ¬ íˆ´ë°” ìŠ¤íƒ€ì¼ (ë” ì„¸ë ¨ëœ ë²„ì „) */
    .pdf-nav-container {
        background-color: rgba(128, 128, 128, 0.08);
        border-radius: 12px;
        padding: 4px 12px;
        margin-top: -8px;
        border: 1px solid rgba(49, 51, 63, 0.1);
        display: flex;
        align-items: center;
    }
    /* ìŠ¬ë¼ì´ë” ë†’ì´ ë° ì—¬ë°± ì¡°ì • */
    div[data-testid="stSlider"] {
        padding-top: 10px;
        padding-bottom: 0px;
    }
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ ë¯¸ì„¸ ì¡°ì • */
    .stButton > button {
        border-radius: 8px !important;
        border: 1px solid rgba(49, 51, 63, 0.1) !important;
        background-color: transparent !important;
        transition: all 0.2s ease;
    }
    .stButton > button:hover {
        background-color: rgba(0, 104, 201, 0.1) !important;
        border-color: #0068c9 !important;
    }
    </style>
    """)


def render_left_column():
    _chat_fragment()


def render_message(role: str, content: str, thought: str = None, doc_ids: list = None):
    avatar_icon = "ğŸ¤–" if role == "assistant" else "ğŸ‘¤"
    with st.chat_message(role, avatar=avatar_icon):
        if thought and thought.strip():
            with st.expander("ğŸ§  ì‚¬ê³  ì™„ë£Œ", expanded=False):
                st.markdown(thought)

        # [ìµœì í™”] ID ë¦¬ìŠ¤íŠ¸ë¡œë¶€í„° ë¬¸ì„œ í’€ì—ì„œ ì›ë³¸ ë¬¸ì„œ ë³µì›
        documents = []
        if role == "assistant" and doc_ids:
            # [ìˆ˜ì •] ì„¸ì…˜ ì´ˆê¸°í™” ì „ì—ë„ ì•ˆì „í•˜ë„ë¡ ê¸°ë³¸ê°’ {} ì œê³µ
            doc_pool = SessionManager.get("doc_pool", {}) or {}
            documents = [doc_pool[d_id] for d_id in doc_ids if d_id in doc_pool]

        # Assistant ë©”ì‹œì§€ì´ë©´ì„œ ì°¸ê³  ë¬¸ì„œê°€ ìˆë‹¤ë©´ íˆ´íŒ ì ìš©
        if role == "assistant":
            from common.utils import (
                apply_tooltips_to_response,
                normalize_latex_delimiters,
            )

            # 1. ìˆ˜ì‹ ì •ê·œí™”
            content = normalize_latex_delimiters(content)

            # 2. íˆ´íŒ ì ìš©
            if documents:
                content = apply_tooltips_to_response(content, documents)

        st.markdown(content, unsafe_allow_html=True)


def _chat_fragment():
    chat_container = st.container(height=UI_CONTAINER_HEIGHT, border=True)
    # [ìˆ˜ì •] ì„¸ì…˜ ì´ˆê¸°í™” ì „ì—ë„ ì•ˆì „í•˜ë„ë¡ ê¸°ë³¸ê°’ [] ì œê³µ
    messages = SessionManager.get_messages() or []
    pdf_path = SessionManager.get("pdf_file_path")
    pdf_processed = SessionManager.get("pdf_processed", False)
    is_generating = bool(st.session_state.get("is_generating_answer", False))

    # ë¬¸ì„œ ë¶„ì„ ì¤‘ì¸ì§€ íŒë³„ (íŒŒì¼ì€ ì—…ë¡œë“œëëŠ”ë° ì•„ì§ ì²˜ë¦¬ê°€ ì•ˆ ëœ ìƒíƒœ)
    is_processing_pdf = bool(pdf_path and not pdf_processed)

    # 1. ì±„íŒ… ì´ë ¥ ë Œë”ë§
    with chat_container:
        for msg in messages:
            render_message(
                msg["role"],
                msg["content"],
                thought=msg.get("thought"),
                doc_ids=msg.get("doc_ids"),
            )

        if not messages:
            if is_processing_pdf:
                st.info(
                    "ğŸ“„ **ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤.**\n\në‚´ìš©ì´ ë§ì„ ê²½ìš° ì‹œê°„ì´ ë‹¤ì†Œ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì±„íŒ…ì´ í™œì„±í™”ë©ë‹ˆë‹¤."
                )
            else:
                st.info(MSG_CHAT_WELCOME)

    # 2. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    # ì…ë ¥ì°½ ìƒíƒœ ê²°ì •
    input_disabled = is_generating or is_processing_pdf
    input_placeholder = (
        "ë¬¸ì„œ ë¶„ì„ ì¤‘ì—ëŠ” ì§ˆë¬¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤..."
        if is_processing_pdf
        else (
            "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤..."
            if is_generating
            else MSG_CHAT_INPUT_PLACEHOLDER
        )
    )

    if user_query := st.chat_input(
        input_placeholder, disabled=input_disabled, key="chat_input_clean"
    ):
        SessionManager.add_message("user", user_query)
        SessionManager.add_status_log("ì§ˆë¬¸ ë¶„ì„ ì¤‘")

        # UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸
        status_placeholder = SessionManager.get("status_placeholder")
        _render_status_box(status_placeholder)
        with chat_container:
            render_message("user", user_query)

        # RAG ì—”ì§„ í˜¸ì¶œ
        rag_engine = SessionManager.get("rag_engine")
        if rag_engine:
            from common.utils import sync_run

            result = sync_run(
                _stream_chat_response(rag_engine, user_query, chat_container)
            )

            final_answer = result.get("response", "")
            final_thought = result.get("thought", "")
            final_docs = result.get("documents", [])

            if final_answer and not final_answer.startswith("âŒ"):
                SessionManager.add_message(
                    "assistant",
                    final_answer,
                    thought=final_thought,
                    documents=final_docs,  # SessionManager.add_message ë‚´ë¶€ì—ì„œ doc_idsë¡œ ë³€í™˜ë¨
                )
                SessionManager.replace_last_status_log("ë‹µë³€ ì‘ì„± ì™„ë£Œ")
                SessionManager.add_status_log("ì§ˆë¬¸ ê°€ëŠ¥")
                st.rerun()
        else:
            st.toast(MSG_CHAT_NO_QA_SYSTEM, icon="âš ï¸")
