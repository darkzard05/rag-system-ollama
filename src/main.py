"""
RAG Chatbot ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë©”ì¸ ì§„ì…ì  íŒŒì¼ì…ë‹ˆë‹¤.
"""
import logging
import tempfile
import time
import streamlit as st
import os

from session import SessionManager
from ui import render_sidebar, render_chat_column, render_pdf_viewer
from rag_core import (
    process_pdf_and_build_chain, 
    create_qa_chain, 
    create_vector_store,
    is_embedding_model_cached,
    load_llm,
    load_embedding_model
)
from config import AVAILABLE_EMBEDDING_MODELS

# --- ë¡œê¹… ì„¤ì • ---
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="RAG Chatbot",
    layout="wide"
)

# --- í•¸ë“¤ëŸ¬ ë° í—¬í¼ í•¨ìˆ˜ ---
def _ensure_models_are_loaded(status_container):
    """LLMê³¼ ì„ë² ë”© ëª¨ë¸ì´ ì„¸ì…˜ì— ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ê³ , ì—†ìœ¼ë©´ ë¡œë“œí•©ë‹ˆë‹¤."""
    selected_model = SessionManager.get("last_selected_model")
    selected_embedding_model = SessionManager.get("last_selected_embedding_model") or AVAILABLE_EMBEDDING_MODELS[0]

    if not SessionManager.get("llm"):
        status_container.update(label=f"'{selected_model}' LLM ëª¨ë¸ ë¡œë”© ì¤‘...")
        llm = load_llm(selected_model)
        SessionManager.set("llm", llm)
        status_container.update(label=f"'{selected_model}' LLM ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    if not SessionManager.get("embedder"):
        if not is_embedding_model_cached(selected_embedding_model):
            status_container.update(label=f"'{selected_embedding_model}' ëª¨ë¸ì„ ì²˜ìŒ ë¡œë“œí•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•˜ë©° ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            status_container.update(label=f"'{selected_embedding_model}' ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
        embedder = load_embedding_model(selected_embedding_model)
        SessionManager.set("embedder", embedder)
        status_container.update(label=f"'{selected_embedding_model}' ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

def update_qa_system():
    """QA ì‹œìŠ¤í…œì„ í˜„ì¬ ì„¸ì…˜ ìƒíƒœì— ë§ì¶° ì—…ë°ì´íŠ¸í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    try:
        llm = SessionManager.get("llm")
        vector_store = SessionManager.get("vector_store")
        doc_splits = SessionManager.get("processed_document_splits")

        if not all([llm, vector_store, doc_splits]):
            st.warning("QA ì‹œìŠ¤í…œì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•œ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return

        with st.status("QA ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì¤‘...", expanded=False) as status:
            status.update(label="ìƒˆë¡œìš´ LLMìœ¼ë¡œ QA ì²´ì¸ì„ ì¬êµ¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            qa_chain = create_qa_chain(llm, vector_store, doc_splits)
            SessionManager.set("qa_chain", qa_chain)
            status.update(label="QA ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì™„ë£Œ!", state="complete", expanded=False)
        
        # ì ì‹œ ë”œë ˆì´ë¥¼ ì£¼ì–´ ì‚¬ìš©ìê°€ ì™„ë£Œ ë©”ì‹œì§€ë¥¼ ì¸ì§€í•  ì‹œê°„ì„ ì¤ë‹ˆë‹¤.
        time.sleep(1)
        st.rerun()

    except Exception as e:
        st.error(f"QA ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        logging.error("QA ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜", exc_info=True)

def handle_model_change(selected_model: str):
    """ëª¨ë¸ ë³€ê²½ì„ ì²˜ë¦¬í•˜ëŠ” í•¸ë“¤ëŸ¬"""
    last_model = SessionManager.get("last_selected_model")
    if "---" in selected_model or not selected_model or selected_model == last_model:
        return

    if last_model is not None:
        SessionManager.add_message("assistant", f"ğŸ”„ LLMì„ '{selected_model}'(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.")
    SessionManager.set("last_selected_model", selected_model)
    
    if SessionManager.get("pdf_processed"):
        with st.status(f"'{selected_model}' ëª¨ë¸ ë¡œë“œ ë° ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì¤‘...", expanded=True) as status:
            status.update(label=f"'{selected_model}' ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
            llm = load_llm(selected_model)
            SessionManager.set("llm", llm)
            status.update(label="ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
            
            # update_qa_system() í˜¸ì¶œ ëŒ€ì‹  ì§ì ‘ ë¡œì§ ìˆ˜í–‰
            status.update(label="ìƒˆë¡œìš´ LLMìœ¼ë¡œ QA ì²´ì¸ì„ ì¬êµ¬ì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            vector_store = SessionManager.get("vector_store")
            doc_splits = SessionManager.get("processed_document_splits")
            qa_chain = create_qa_chain(llm, vector_store, doc_splits)
            SessionManager.set("qa_chain", qa_chain)
            status.update(label="QA ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸ ì™„ë£Œ!", state="complete", expanded=False)

        time.sleep(1)
        st.rerun()

def handle_embedding_model_change(selected_embedding_model: str):
    """ì„ë² ë”© ëª¨ë¸ ë³€ê²½ì„ ì²˜ë¦¬í•˜ëŠ” í•¸ë“¤ëŸ¬."""
    last_embedding_model = SessionManager.get("last_selected_embedding_model")
    if not selected_embedding_model or selected_embedding_model == last_embedding_model:
        return

    if last_embedding_model is not None:
        SessionManager.add_message("assistant", f"ğŸ”„ ì„ë² ë”© ëª¨ë¸ì„ '{selected_embedding_model}'(ìœ¼)ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.")
    
    SessionManager.set("last_selected_embedding_model", selected_embedding_model)

    if SessionManager.get("pdf_processed"):
        st.info("ì„ë² ë”© ëª¨ë¸ì´ ë³€ê²½ë˜ì–´ ë¬¸ì„œë¥¼ ë‹¤ì‹œ ì²˜ë¦¬í•©ë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        
        file_name = SessionManager.get("last_uploaded_file_name")
        file_bytes = SessionManager.get("pdf_file_bytes")
        llm = SessionManager.get("llm")

        if not all([file_name, file_bytes, llm]):
            st.warning("ë¬¸ì„œë¥¼ ë‹¤ì‹œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return

        temp_path = ""
        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(file_bytes)
                temp_path = tmp_file.name

            with st.status(f"ìƒˆ ì„ë² ë”© ëª¨ë¸ë¡œ RAG ì‹œìŠ¤í…œ ì¬êµ¬ì¶• ì¤‘...", expanded=True) as status:
                
                def progress_callback(message):
                    status.update(label=message)

                if not is_embedding_model_cached(selected_embedding_model):
                    status.update(label=f"'{selected_embedding_model}' ëª¨ë¸ì„ ì²˜ìŒ ë¡œë“œí•©ë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œê°€ í•„ìš”í•˜ë©° ëª‡ ë¶„ ì •ë„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                
                embedder = load_embedding_model(selected_embedding_model)
                SessionManager.set("embedder", embedder)
                status.update(label=f"'{selected_embedding_model}' ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

                success_message, cache_used = process_pdf_and_build_chain(
                    uploaded_file_name=file_name,
                    file_bytes=file_bytes,
                    temp_pdf_path=temp_path,
                    llm=llm,
                    embedder=embedder,
                    progress_callback=progress_callback
                )
                if cache_used:
                    st.info(success_message)
                
                SessionManager.add_message("assistant", "âœ… ìƒˆ ì„ë² ë”© ëª¨ë¸ë¡œ ì‹œìŠ¤í…œì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
                status.update(label="ì‹œìŠ¤í…œ ì¬êµ¬ì¶• ì™„ë£Œ!", state="complete", expanded=False)

            time.sleep(1)
            st.rerun()

        except Exception as e:
            error_msg = f"ì„ë² ë”© ëª¨ë¸ ë³€ê²½ í›„ ì¬ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
            logging.error(error_msg, exc_info=True)
            SessionManager.add_message("assistant", f"âŒ {error_msg}")
            st.rerun()
        finally:
            if temp_path and os.path.exists(temp_path):
                os.remove(temp_path)
                logging.info(f"ì„ì‹œ íŒŒì¼ '{temp_path}' ì‚­ì œ ì™„ë£Œ.")

def handle_file_upload(uploaded_file):
    """íŒŒì¼ ì—…ë¡œë“œë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¸ë“¤ëŸ¬"""
    if uploaded_file.name == SessionManager.get("last_uploaded_file_name"):
        return

    # ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì‹œ ì„¸ì…˜ ìƒíƒœ ë¦¬ì…‹ (ëª¨ë¸ ê´€ë ¨ ìƒíƒœëŠ” ë³´ì¡´)
    preserved_model = SessionManager.get("last_selected_model")
    preserved_embedding_model = SessionManager.get("last_selected_embedding_model")
    preserved_llm = SessionManager.get("llm")
    preserved_embedder = SessionManager.get("embedder")
    
    SessionManager.reset_all_state()
    
    SessionManager.set("last_selected_model", preserved_model)
    SessionManager.set("last_selected_embedding_model", preserved_embedding_model)
    SessionManager.set("llm", preserved_llm)
    SessionManager.set("embedder", preserved_embedder)
    
    # ìƒˆ íŒŒì¼ ì •ë³´ ì„¤ì •
    file_bytes = uploaded_file.getvalue()
    SessionManager.set("last_uploaded_file_name", uploaded_file.name)
    SessionManager.set("pdf_file_bytes", file_bytes)
    
    temp_path = ""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(file_bytes)
            temp_path = tmp_file.name

        SessionManager.add_message("assistant", f"ğŸ“‚ '{uploaded_file.name}' íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ.")
        
        if not SessionManager.get("last_selected_model"):
            st.warning("LLM ëª¨ë¸ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
            return

        with st.status(f"'{uploaded_file.name}' ë¬¸ì„œ ì²˜ë¦¬ ë° RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì¤‘...", expanded=True) as status:
            
            def progress_callback(message):
                status.update(label=message)

            _ensure_models_are_loaded(status)

            success_message, cache_used = process_pdf_and_build_chain(
                uploaded_file_name=uploaded_file.name,
                file_bytes=file_bytes,
                temp_pdf_path=temp_path,
                llm=SessionManager.get("llm"),
                embedder=SessionManager.get("embedder"),
                progress_callback=progress_callback
            )
            if cache_used:
                st.info(success_message)
            
            SessionManager.add_message("assistant", success_message)
            status.update(label="RAG ì‹œìŠ¤í…œ êµ¬ì¶• ì™„ë£Œ!", state="complete", expanded=False)
        
        time.sleep(1)
        st.rerun()

    except Exception as e:
        error_msg = f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        logging.error(error_msg, exc_info=True)
        SessionManager.set("pdf_processing_error", error_msg)
        SessionManager.add_message("assistant", f"âŒ {error_msg}")
        st.rerun()
    finally:
        if temp_path and os.path.exists(temp_path):
            os.remove(temp_path)
            logging.info(f"ì„ì‹œ íŒŒì¼ '{temp_path}' ì‚­ì œ ì™„ë£Œ.")

# --- ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ---
def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ í•¨ìˆ˜"""
    SessionManager.init_session()
    
    render_sidebar(
        uploaded_file_handler=handle_file_upload,
        model_change_handler=handle_model_change,
        embedding_model_change_handler=handle_embedding_model_change
    )

    col_left, col_right = st.columns([1, 1])

    with col_left:
        render_chat_column()

    with col_right:
        render_pdf_viewer()

if __name__ == "__main__":
    main()