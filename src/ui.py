"""
Streamlit UI ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ íŒŒì¼.
"""

import logging
import streamlit as st
from streamlit_pdf_viewer import pdf_viewer
import fitz  # PyMuPDF

from session import SessionManager
from model_loader import get_available_models
from config import (
    AVAILABLE_EMBEDDING_MODELS,
    OLLAMA_MODEL_NAME,
    MSG_PREPARING_ANSWER,
    MSG_THINKING,
    MSG_NO_THOUGHT_PROCESS,
    UI_CONTAINER_HEIGHT,
)


def _process_chat_response(qa_chain, user_input, chat_container):
    """
    LangGraph RAG ì²´ì¸ì—ì„œ ìŠ¤íŠ¸ë¦¬ë°ëœ ì‘ë‹µì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  UIì— í‘œì‹œí•©ë‹ˆë‹¤.
    """
    with chat_container, st.chat_message("assistant"):
        message_placeholder = st.empty()
        message_placeholder.markdown(MSG_PREPARING_ANSWER)

        final_generation = ""
        try:
            # LangGraphëŠ” ê° ë…¸ë“œê°€ ëë‚  ë•Œë§ˆë‹¤ ìƒíƒœë¥¼ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
            stream = qa_chain.stream({"input": user_input})

            for chunk in stream:
                # ìŠ¤íŠ¸ë¦¼ì˜ ê° ì²­í¬ëŠ” {'ë…¸ë“œì´ë¦„': {'ìƒíƒœí‚¤': ê°’}} í˜•íƒœì…ë‹ˆë‹¤.
                # ë§ˆì§€ë§‰ 'generate' ë…¸ë“œì˜ ì¶œë ¥ì„ ì°¾ìŠµë‹ˆë‹¤.
                if "generate" in chunk:
                    generation_output = chunk["generate"].get("generation", "")
                    if generation_output:
                        final_generation = generation_output
                        message_placeholder.markdown(final_generation + "â–Œ")
            
            # ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… UI ì—…ë°ì´íŠ¸
            message_placeholder.markdown(final_generation)
            SessionManager.add_message("assistant", final_generation)
            logging.info(f"LangGraph ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ. (ì‘ë‹µ ê¸¸ì´: {len(final_generation)}ì)")

        except Exception as e:
            error_msg = f"ë‹µë³€ ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            logging.error(error_msg, exc_info=True)
            message_placeholder.error(error_msg)
            SessionManager.add_message("assistant", f"âŒ {error_msg}")


def render_sidebar(
    file_uploader_callback, model_selector_callback, embedding_selector_callback
):
    """ì‚¬ì´ë“œë°” UIë¥¼ ë Œë”ë§í•˜ê³  ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # --- íŒŒì¼ ì—…ë¡œë” ---
        st.file_uploader(
            "PDF íŒŒì¼ ì—…ë¡œë“œ",
            type="pdf",
            key="pdf_uploader",
            on_change=file_uploader_callback,
        )

        # --- LLM ëª¨ë¸ ì„ íƒ (ë™ì  ëª©ë¡) ---
        with st.spinner("LLM ëª¨ë¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            available_models = get_available_models()

            # ì‚¬ìš© ê°€ëŠ¥í•œ ì‹¤ì œ ëª¨ë¸ ëª©ë¡ (êµ¬ë¶„ì„  ì œì™¸)
            actual_models = [m for m in available_models if "---" not in m]

            last_model = SessionManager.get("last_selected_model")

            # ì„¸ì…˜ì— ëª¨ë¸ì´ ì—†ê±°ë‚˜, ìˆë”ë¼ë„ í˜„ì¬ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ëª¨ë¸ì¼ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
            if not last_model or last_model not in actual_models:
                if actual_models:
                    last_model = actual_models[0]
                    SessionManager.set("last_selected_model", last_model)
                else:  # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì „í˜€ ì—†ì„ ê²½ìš°
                    last_model = OLLAMA_MODEL_NAME

            current_model_index = (
                available_models.index(last_model)
                if last_model in available_models
                else 0
            )

            st.selectbox(
                "LLM ëª¨ë¸ ì„ íƒ",
                available_models,
                index=current_model_index,
                key="model_selector",
                on_change=model_selector_callback,
            )

        # --- ì„ë² ë”© ëª¨ë¸ ì„ íƒ ---
        last_embedding_model = (
            SessionManager.get("last_selected_embedding_model")
            or AVAILABLE_EMBEDDING_MODELS[0]
        )
        current_embedding_model_index = (
            AVAILABLE_EMBEDDING_MODELS.index(last_embedding_model)
            if last_embedding_model in AVAILABLE_EMBEDDING_MODELS
            else 0
        )

        st.selectbox(
            "ì„ë² ë”© ëª¨ë¸ ì„ íƒ",
            AVAILABLE_EMBEDDING_MODELS,
            index=current_embedding_model_index,
            key="embedding_model_selector",
            on_change=embedding_selector_callback,
        )

        # --- ìƒíƒœ ë©”ì‹œì§€ í‘œì‹œ ì˜ì—­ ---
        st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        status_container = st.container()
        return status_container


def render_pdf_viewer():
    """PDF ë·°ì–´ ì»¬ëŸ¼ì„ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.subheader("ğŸ“„ PDF ë¯¸ë¦¬ë³´ê¸°")

    pdf_bytes = SessionManager.get("pdf_file_bytes")
    if not pdf_bytes:
        st.info("ë¯¸ë¦¬ë³¼ PDFê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return

    try:
        pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
        total_pages = len(pdf_document)

        current_file_name = SessionManager.get("last_uploaded_file_name")

        if "current_page" not in st.session_state:
            st.session_state.current_page = 1
        if st.session_state.get("last_pdf_name") != current_file_name:
            st.session_state.current_page = 1
            st.session_state.last_pdf_name = current_file_name
        if st.session_state.current_page > total_pages:
            st.session_state.current_page = 1

        def go_to_previous_page():
            if st.session_state.current_page > 1:
                st.session_state.current_page -= 1

        def go_to_next_page():
            if st.session_state.current_page < total_pages:
                st.session_state.current_page += 1

        # 1. PDF ë·°ì–´ ë¨¼ì € í‘œì‹œ
        pdf_viewer(
            input=pdf_bytes,
            height=UI_CONTAINER_HEIGHT,
            pages_to_render=[st.session_state.current_page],
        )

        # 2. ë‚´ë¹„ê²Œì´ì…˜ UI ê°œì„ 
        # ì»¬ëŸ¼ ë¹„ìœ¨ì„ ì¡°ì •í•˜ì—¬ í˜ì´ì§€ ì…ë ¥ê³¼ í…ìŠ¤íŠ¸ë¥¼ ë¶„ë¦¬
        nav_cols = st.columns([1, 2, 1])

        with nav_cols[0]:
            st.button(
                "â† ì´ì „",
                on_click=go_to_previous_page,
                use_container_width=True,
                disabled=(st.session_state.current_page <= 1),
            )

        with nav_cols[1]:
            # ìŠ¬ë¼ì´ë”ì™€ number_input ë™ê¸°í™”ë¥¼ ìœ„í•œ ì½œë°± í•¨ìˆ˜
            def sync_slider_and_input():
                st.session_state.current_page = st.session_state.current_page_slider

            st.slider(
                "í˜ì´ì§€ ì´ë™",
                min_value=1,
                max_value=total_pages,
                key="current_page_slider",
                label_visibility="collapsed",
                value=st.session_state.current_page,
                on_change=sync_slider_and_input,  # on_change ì½œë°± ì‚¬ìš©
            )

        with nav_cols[2]:
            st.button(
                "ë‹¤ìŒ â†’",
                on_click=go_to_next_page,
                use_container_width=True,
                disabled=(st.session_state.current_page >= total_pages),
            )

    except Exception as e:
        st.error(f"PDFë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        logging.error("PDF ë·°ì–´ ì˜¤ë¥˜", exc_info=True)


def render_chat_column():
    """ì±„íŒ… ì»¬ëŸ¼ì„ ë Œë”ë§í•˜ê³  ì±„íŒ… ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    st.subheader("ğŸ’¬ ì±„íŒ…")

    chat_container = st.container(height=UI_CONTAINER_HEIGHT, border=True)

    # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
    for message in SessionManager.get_messages():
        with chat_container, st.chat_message(message["role"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_input := st.chat_input(
        "PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.", disabled=not SessionManager.is_ready_for_chat()
    ):
        SessionManager.add_message("user", user_input)
        with chat_container, st.chat_message("user"):
            st.markdown(user_input)

        qa_chain = SessionManager.get("qa_chain")
        if qa_chain:
            _process_chat_response(qa_chain, user_input, chat_container)
        else:
            st.error("QA ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDFë¥¼ ë¨¼ì € ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")

    # ì´ˆê¸° ì•ˆë‚´ ë©”ì‹œì§€
    if not SessionManager.get_messages():
        with chat_container:
            st.info(
                "**RAG-Chatì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!**\n\n"
                "ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•œ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”."
            )

            st.markdown(
                """
                **ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ**
                - **PDF ì—…ë¡œë“œ:** ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•˜ê³  ì‹¶ì€ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.
                - **ëª¨ë¸ ì„ íƒ:** ë¡œì»¬ `Ollama` ëª¨ë¸ ë˜ëŠ” `Gemini` API ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - **ì§ˆë¬¸í•˜ê¸°:** ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ë©´, ë‚´ìš©ì— ëŒ€í•´ ììœ ë¡­ê²Œ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - **PDF ë·°ì–´:** ìš°ì¸¡ì—ì„œ ì›ë³¸ ë¬¸ì„œë¥¼ í•¨ê»˜ ë³´ë©° ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                **âš ï¸ ì•Œì•„ë‘ì‹¤ ì **
                - **ë‹µë³€ì˜ ì •í™•ì„±:** ë‹µë³€ì€ ì—…ë¡œë“œëœ PDF ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë˜ë©°, ì‚¬ì‹¤ì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - **ê°œì¸ì •ë³´:** Gemini ëª¨ë¸ ì‚¬ìš© ì‹œ, ì§ˆë¬¸ ë‚´ìš©ì´ Google ì„œë²„ë¡œ ì „ì†¡ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - **ì´ˆê¸° ë¡œë”©:** ì„ë² ë”© ëª¨ë¸ì„ ì²˜ìŒ ì‚¬ìš©í•˜ë©´ ë‹¤ìš´ë¡œë“œì— ëª‡ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """
            )

    # ì—ëŸ¬ ë©”ì‹œì§€ í‘œì‹œ
    if error_msg := SessionManager.get("pdf_processing_error"):
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}")
        if st.button("ì¬ì‹œë„"):
            SessionManager.reset_all_state()
            st.rerun()
