"Streamlit UI ì»´í¬ë„ŒíŠ¸ ë Œë”ë§ í•¨ìˆ˜ë“¤ì„ ëª¨ì•„ë†“ì€ íŒŒì¼."

import time
import logging
import asyncio
import streamlit as st
from streamlit_pdf_viewer import pdf_viewer
from streamlit_mermaid import st_mermaid
import fitz  # PyMuPDF

from session import SessionManager
from model_loader import get_available_models
from config import (
    AVAILABLE_EMBEDDING_MODELS,
    OLLAMA_MODEL_NAME,
    MSG_PREPARING_ANSWER,
    UI_CONTAINER_HEIGHT,
)


async def _stream_chat_response(qa_chain, user_input, chat_container) -> str:
    """
    LLMì˜ ë‹µë³€ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ UIì— ìŠ¤íŠ¸ë¦¬ë°í•˜ê³  ìµœì¢… ë‹µë³€ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    full_response = ""
    start_time = time.time()
    
    with chat_container, st.chat_message("assistant"):
        answer_container = st.empty()
        answer_container.markdown(MSG_PREPARING_ANSWER)

        try:
            async for event in qa_chain.astream_events(
                {"input": user_input}, version="v1"
            ):
                kind = event["event"]
                name = event.get("name", "")
                
                if kind == "on_chain_stream" and name == "generate_response":
                    chunk_data = event["data"].get("chunk")
                    
                    if isinstance(chunk_data, dict) and "response" in chunk_data:
                        full_response += chunk_data["response"]
                        answer_container.markdown(full_response + "â–Œ")

        except Exception as e:
            error_msg = f"ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
            logging.error(error_msg, exc_info=True)
            answer_container.error(error_msg)
            return f"âŒ {error_msg}"

    # --- ìŠ¤íŠ¸ë¦¬ë° ì™„ë£Œ í›„ ìµœì¢… ë‚´ìš© ì •ë¦¬ ë° ë¡œê·¸ ì¶œë ¥ ---
    end_time = time.time()
    answer_container.markdown(full_response)
    
    total_duration = end_time - start_time
    perf_details = f"ë‹µë³€: {total_duration:.2f}ì´ˆ ({len(full_response)}ì)"
    logging.info(f"  [ì„±ëŠ¥ ìƒì„¸] {perf_details}")
    
    return full_response


def render_sidebar(
    file_uploader_callback,
    model_selector_callback,
    embedding_selector_callback
):
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        st.file_uploader(
            "PDF íŒŒì¼ ì—…ë¡œë“œ",
            type="pdf",
            key="pdf_uploader",
            on_change=file_uploader_callback,
        )
        with st.spinner("LLM ëª¨ë¸ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            available_models = get_available_models()
            actual_models = [m for m in available_models if "---" not in m]
            last_model = SessionManager.get("last_selected_model")
            if not last_model or last_model not in actual_models:
                if actual_models:
                    last_model = actual_models[0]
                    SessionManager.set("last_selected_model", last_model)
                else:
                    last_model = OLLAMA_MODEL_NAME
            current_model_index = (
                available_models.index(last_model)
                if last_model in available_models
                else 0
            )
            st.selectbox(
                "LLM ëª¨ë¸ ì„ íƒ",
                available_models,
                index=current_model_index,
                key="model_selector",
                on_change=model_selector_callback,
            )
        last_embedding_model = (
            SessionManager.get("last_selected_embedding_model")
            or AVAILABLE_EMBEDDING_MODELS[0]
        )
        current_embedding_model_index = (
            AVAILABLE_EMBEDDING_MODELS.index(last_embedding_model)
            if last_embedding_model in AVAILABLE_EMBEDDING_MODELS
            else 0
        )
        st.selectbox(
            "ì„ë² ë”© ëª¨ë¸ ì„ íƒ",
            AVAILABLE_EMBEDDING_MODELS,
            index=current_embedding_model_index,
            key="embedding_model_selector",
            on_change=embedding_selector_callback,
        )
        st.divider()
        st.header("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")
        status_container = st.container()
        return status_container


def render_pdf_viewer():
    st.subheader("ğŸ“„ PDF ë¯¸ë¦¬ë³´ê¸°")
    pdf_bytes = SessionManager.get("pdf_file_bytes")
    if not pdf_bytes:
        st.info("ë¯¸ë¦¬ë³¼ PDFê°€ ì—†ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        return
    try:
        pdf_document = fitz.open(stream=pdf_bytes, filetype="pdf")
        total_pages = len(pdf_document)
        current_file_name = SessionManager.get("last_uploaded_file_name")
        if "current_page" not in st.session_state:
            st.session_state.current_page = 1
        if st.session_state.get("last_pdf_name") != current_file_name:
            st.session_state.current_page = 1
            st.session_state.last_pdf_name = current_file_name
        if st.session_state.current_page > total_pages:
            st.session_state.current_page = 1
        def go_to_previous_page():
            if st.session_state.current_page > 1:
                st.session_state.current_page -= 1
        def go_to_next_page():
            if st.session_state.current_page < total_pages:
                st.session_state.current_page += 1
        pdf_viewer(
            input=pdf_bytes,
            height=UI_CONTAINER_HEIGHT,
            pages_to_render=[st.session_state.current_page],
        )
        nav_cols = st.columns([1, 2, 1])
        with nav_cols[0]:
            st.button(
                "â† ì´ì „",
                on_click=go_to_previous_page,
                use_container_width=True,
                disabled=(st.session_state.current_page <= 1),
            )
        with nav_cols[1]:
            def sync_slider_and_input():
                st.session_state.current_page = st.session_state.current_page_slider
            st.slider(
                "í˜ì´ì§€ ì´ë™",
                min_value=1,
                max_value=total_pages,
                key="current_page_slider",
                label_visibility="collapsed",
                value=st.session_state.current_page,
                on_change=sync_slider_and_input,
            )
        with nav_cols[2]:
            st.button(
                "ë‹¤ìŒ â†’",
                on_click=go_to_next_page,
                use_container_width=True,
                disabled=(st.session_state.current_page >= total_pages),
            )
    except Exception as e:
        st.error(f"PDFë¥¼ í‘œì‹œí•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        logging.error("PDF ë·°ì–´ ì˜¤ë¥˜", exc_info=True)


def render_chat_column():
    """ì±„íŒ… ì»¬ëŸ¼ì„ ë Œë”ë§í•˜ê³  ì±„íŒ… ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    chat_container = st.container(height=UI_CONTAINER_HEIGHT, border=True)

    messages = SessionManager.get_messages()
    for message in messages:
        with chat_container, st.chat_message(message["role"]):
            st.markdown(message["content"], unsafe_allow_html=True)

    if user_input := st.chat_input(
        "PDF ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”.", disabled=not SessionManager.is_ready_for_chat()
    ):
        SessionManager.add_message("user", user_input)
        st.rerun()

    if messages and messages[-1]["role"] == "user":
        last_user_input = messages[-1]["content"]
        qa_chain = SessionManager.get("qa_chain")
        
        if qa_chain:
            try:
                loop = asyncio.get_running_loop()
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            final_answer = loop.run_until_complete(
                _stream_chat_response(qa_chain, last_user_input, chat_container)
            )
            
            if final_answer:
                SessionManager.add_message("assistant", content=final_answer)
                st.rerun()
        else:
            st.error("QA ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. PDFë¥¼ ë¨¼ì € ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")

    if not SessionManager.get_messages():
        with chat_container:
            st.info(
                "**RAG-Chatì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤!**\n\n"
                "ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•œ ëŒ€í™”ë¥¼ ì‹œì‘í•´ë³´ì„¸ìš”."
            )
            st.markdown(
                """
                **ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ**
                - **PDF ì—…ë¡œë“œ:** ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•˜ê³  ì‹¶ì€ PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.
                - **ëª¨ë¸ ì„ íƒ:** ë¡œì»¬ `Ollama` ëª¨ë¸ ë˜ëŠ” `Gemini` API ëª¨ë¸ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - **ì§ˆë¬¸í•˜ê¸°:** ë¬¸ì„œ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ë©´, ë‚´ìš©ì— ëŒ€í•´ ììœ ë¡­ê²Œ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - **PDF ë·°ì–´:** ìš°ì¸¡ì—ì„œ ì›ë³¸ ë¬¸ì„œë¥¼ í•¨ê»˜ ë³´ë©° ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                
                **âš ï¸ ì•Œì•„ë‘ì‹¤ ì **
                - **ë‹µë³€ì˜ ì •í™•ì„±:** ë‹µë³€ì€ ì—…ë¡œë“œëœ PDF ë‚´ìš©ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë˜ë©°, ì‚¬ì‹¤ì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - **ê°œì¸ì •ë³´:** Gemini ëª¨ë¸ ì‚¬ìš© ì‹œ, ì§ˆë¬¸ ë‚´ìš©ì´ Google ì„œë²„ë¡œ ì „ì†¡ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                - **ì´ˆê¸° ë¡œë”©:** ì„ë² ë”© ëª¨ë¸ì„ ì²˜ìŒ ì‚¬ìš©í•˜ë©´ ë‹¤ìš´ë¡œë“œì— ëª‡ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                """
            )

    if error_msg := SessionManager.get("pdf_processing_error"):
        st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {error_msg}")
        if st.button("ì¬ì‹œë„"):
            SessionManager.reset_all_state()
            st.rerun()

def render_workflow_tab_content():
    """ì›Œí¬í”Œë¡œìš° íƒ­ì— ë“¤ì–´ê°ˆ ì½˜í…ì¸ ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    qa_chain = SessionManager.get("qa_chain")
    
    if not qa_chain:
        st.info("ì›Œí¬í”Œë¡œìš°ë¥¼ ë³´ë ¤ë©´ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ PDFë¥¼ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.")
        return

    # 1. LangGraphì—ì„œ Mermaid êµ¬ë¬¸ ì¶”ì¶œ
    try:
        mermaid_syntax = qa_chain.get_graph().draw_mermaid()
    except Exception as e:
        st.error(f"ê·¸ë˜í”„ë¥¼ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        return

    # 2. Mermaid ê·¸ë˜í”„ ë Œë”ë§
    st.subheader("ì›Œí¬í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨")
    st_mermaid(mermaid_syntax, height="350px") # ì»¬ëŸ¼ì— ë§ê²Œ ë†’ì´ ì‚´ì§ ì¡°ì ˆ

    # 3. ê° ë…¸ë“œì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ì¶”ê°€
    st.subheader("ê° ë‹¨ê³„ ì„¤ëª…")
    
    node_descriptions = {
        "retrieve": "**1. ë¬¸ì„œ ê²€ìƒ‰ (Retrieve):** ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ ë¬¸ì„œ ì¡°ê°ë“¤ì„ ì°¾ì•„ëƒ…ë‹ˆë‹¤.",
        "format_context": "**2. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (Format Context):** ê²€ìƒ‰ëœ ë¬¸ì„œ ì¡°ê°ë“¤ì„ LLMì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.",
        "generate_response": "**3. ë‹µë³€ ìƒì„± (Generate Response):** ì •ë¦¬ëœ ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."
    }

    graph_nodes = qa_chain.get_graph().nodes
    for node_name in graph_nodes:
        if node_name in node_descriptions:
            st.markdown(node_descriptions[node_name])
        elif node_name != "__end__":
            st.markdown(f"- **{node_name}**: ì»¤ìŠ¤í…€ ë…¸ë“œ")

def render_left_column_with_tabs():
    """
    ì™¼ìª½ ì»¬ëŸ¼ì— 'ì±„íŒ…'ê³¼ 'ì›Œí¬í”Œë¡œìš°' íƒ­ì„ ìƒì„±í•˜ê³ ,
    ê° íƒ­ì— ë§ëŠ” ì½˜í…ì¸ ë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
    """
    # 1. íƒ­ ìƒì„±
    tab_chat, tab_workflow = st.tabs(["ğŸ’¬ ì±„íŒ…", "ğŸ“Š ì›Œí¬í”Œë¡œìš°"])

    # 2. 'ì±„íŒ…' íƒ­ ì½˜í…ì¸  êµ¬ì„±
    with tab_chat:
        # ê¸°ì¡´ ì±„íŒ… ë Œë”ë§ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        # (ì´í›„ ë‹¨ê³„ì—ì„œ ì´ í•¨ìˆ˜ë¥¼ ì•½ê°„ ìˆ˜ì •í•  ê²ƒì…ë‹ˆë‹¤.)
        render_chat_column()

    # 3. 'ì›Œí¬í”Œë¡œìš°' íƒ­ ì½˜í…ì¸  êµ¬ì„±
    with tab_workflow:
        # ê·¸ë˜í”„ ë·° ë Œë”ë§ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
        # (ì´í›„ ë‹¨ê³„ì—ì„œ ì´ í•¨ìˆ˜ë¥¼ ì•½ê°„ ìˆ˜ì •í•  ê²ƒì…ë‹ˆë‹¤.)
        render_workflow_tab_content() # ìƒˆ ì´ë¦„ìœ¼ë¡œ ë³€ê²½