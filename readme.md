[Read in English](#english) | [í•œêµ­ì–´ë¡œ ë³´ê¸°](#korean)

---
<a name="english"></a>
# RAG Chatbot with Ollama & Gemini (English)

**An advanced PDF-based Chatbot powered by an Ensemble Retriever (BM25 & FAISS), Ollama, Gemini, and Streamlit.**

![RAG Chatbot Preview](image/image1.png)

## ğŸ”‘ Key Features

- **PDF-based Q&A**: Upload your PDF documents and get answers to your questions based on their content.
- **Advanced Hybrid Search**: Utilizes an **Ensemble Retriever** that combines keyword-based search (BM25) and semantic search (FAISS) to deliver more accurate and contextually relevant results.
- **Flexible LLM Selection (Ollama & Gemini)**: Choose between running large language models locally with Ollama for privacy, or using powerful Gemini models via API for high performance.
- **Flexible Embedding Model Selection**: Choose from a variety of open-source embedding models to suit your needs for performance and language support.
- **Streamlit-based Web Interface**: A user-friendly and interactive web interface for easy document upload, model selection, chatting, and PDF viewing.
- **View LLM's Thinking Process**: Option to see the thought process of the LLM before it generates an answer, providing transparency into its reasoning.

---

## âš¡ Quick Start

### ğŸ“‹ Prerequisites
- **Python**: 3.10 or higher
- **Ollama (Optional)**: If using local models, Ollama must be installed and the server running.
  - Refer to the [Ollama Official Website](https://ollama.com) for installation.
- **Gemini API Key (Optional)**: If using Gemini models, you need to set up your API key.
  - Create a `.env` file in the project's root directory.
  - Add your API key to the file: `GEMINI_API_KEY="YOUR_API_KEY"`
  - You can get your key from [Google AI Studio](https://aistudio.google.com/app/apikey).
- **System Resources**: For local models, sufficient RAM (e.g., 16GB+ for 7B models) is recommended.

---

### ğŸ’» Installation & Run

1.  **Clone the repository**
    ```bash
    git clone https://github.com/darkzard05/rag-system-ollama.git
    cd rag-system-ollama
    ```

2.  **(Recommended) Create and activate a virtual environment**
    ```bash
    python -m venv venv
    
    # On Windows
    venv\Scripts\activate
    
    # On macOS/Linux
    source venv/bin/activate
    ```

3.  **Install required Python packages**
    ```bash
    pip install -r requirements.txt
    ```

4.  **(For Ollama Users) Pull a model**
    We recommend a general-purpose model to start. You can find more models at the [Ollama Library](https://ollama.com/library).
    ```bash
    ollama pull llama3:8b
    ```
    - Ensure the Ollama server is running before this step.
    - Make sure the `default_ollama` model name in your `config.yml` matches a model you have pulled.

5.  **Run the Streamlit application**
    ```bash
    streamlit run src/main.py
    ```

6.  Open your web browser and go to `http://localhost:8501` to use the application.

## ğŸ“ Project Structure
```
.
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ readme.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ image/
â”‚   â””â”€â”€ image1.png
â””â”€â”€ src/
    â”œâ”€â”€ main.py
    â”œâ”€â”€ ui.py
    â”œâ”€â”€ session.py
    â”œâ”€â”€ rag_core.py
    â”œâ”€â”€ config.py
    â””â”€â”€ config.yml
```
- **`main.py`**: Entry point of the Streamlit application.
- **`ui.py`**: Contains all functions for rendering the Streamlit user interface.
- **`session.py`**: Manages the application's session state.
- **`rag_core.py`**: The core of the RAG system (data processing, embedding, retrieval, QA chain).
- **`config.py`**: Loads and provides configuration constants for the application.
- **`config.yml`**: YAML file for storing configurations like model lists and retriever settings.
- **`.env.example`**: An example file for environment variables. Copy it to `.env` to set your API keys.

## âœ¨ Key Components

- **PDF Loader (PyMuPDF)**: Loads and extracts text content from uploaded PDF files.
- **Text Splitter (Langchain)**: Divides the extracted text into smaller, manageable chunks.
- **Embedding Model (Sentence Transformers)**: Converts text chunks into numerical vector embeddings.
- **Vector Store (FAISS)**: Stores vector embeddings for efficient similarity search.
- **Retriever (Ensemble)**: Combines keyword-based search (**BM25**) and semantic search (**FAISS**) to fetch the most relevant text chunks for a given query.
- **LLM (Ollama & Gemini)**: The selected language model generates an answer using the user's query and the retrieved context.
- **Streamlit UI**: Provides the interactive web interface for all user interactions.

## âš™ï¸ Configuration

- **API Keys**: Set your `GEMINI_API_KEY` in a `.env` file in the project root.
- **Models and Parameters**: You can adjust the models, retriever weights, and text splitter settings in `config.yml`.

## ğŸš‘ Troubleshooting

- **Ollama Connection Issues**: Ensure the Ollama application/server is running (`ollama list`).
- **Gemini API Key Issues**: Ensure the key is correct and set in your `.env` file. A `429` error might indicate you have exceeded your API rate limits.
- **Slow Performance**: Processing large PDFs or using large local models can be resource-intensive. Ensure your system meets the recommended specifications.

## ğŸ“„ License
This project is distributed under the MIT License. See the `LICENSE` file for more details.

---
<a name="korean"></a>
# RAG Chatbot with Ollama & Gemini (í•œêµ­ì–´)

**ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„(BM25 & FAISS), Ollama, Gemini, Streamlit ê¸°ë°˜ì˜ ê³ ë„í™”ëœ PDF ì±—ë´‡**

![RAG Chatbot Preview](image/image1.png)

## ğŸ”‘ ì£¼ìš” ê¸°ëŠ¥

- **PDF ê¸°ë°˜ Q&A**: PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ê³  í•´ë‹¹ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ê³ ë„í™”ëœ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰**: í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰(BM25)ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰(FAISS)ì„ ê²°í•©í•œ **ì•™ìƒë¸” ë¦¬íŠ¸ë¦¬ë²„**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì •í™•í•˜ê³  ë¬¸ë§¥ì— ë§ëŠ” ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
- **ìœ ì—°í•œ LLM ì„ íƒ (Ollama & Gemini)**: ê°œì¸ ì •ë³´ ë³´í˜¸ë¥¼ ìœ„í•´ Ollamaë¡œ ë¡œì»¬ì—ì„œ LLMì„ ì‹¤í–‰í•˜ê±°ë‚˜, ê³ ì„±ëŠ¥ì„ ìœ„í•´ APIë¥¼ í†µí•´ ê°•ë ¥í•œ Gemini ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒ ì¤‘ì—ì„œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ìœ ì—°í•œ ì„ë² ë”© ëª¨ë¸ ì„ íƒ**: ì„±ëŠ¥ ë° ì–¸ì–´ ì§€ì› ìš”êµ¬ì— ë§ëŠ” ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ ì„ë² ë”© ëª¨ë¸ ì¤‘ì—ì„œ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **Streamlit ê¸°ë°˜ ì›¹ ì¸í„°í˜ì´ìŠ¤**: ì†ì‰¬ìš´ ë¬¸ì„œ ì—…ë¡œë“œ, ëª¨ë¸ ì„ íƒ, ì±„íŒ…, PDF ë·°ì‰ì„ ìœ„í•œ ì‚¬ìš©ì ì¹œí™”ì ì¸ ëŒ€í™”í˜• ì›¹ ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
- **LLMì˜ ì‚¬ê³  ê³¼ì • í™•ì¸**: LLMì´ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ì „ì˜ ì‚¬ê³  ê³¼ì •ì„ í™•ì¸í•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì„ ì œê³µí•˜ì—¬ ì¶”ë¡  ê³¼ì •ì˜ íˆ¬ëª…ì„±ì„ ë†’ì…ë‹ˆë‹¤.

---

## âš¡ ë¹ ë¥¸ ì‹œì‘

### ğŸ“‹ ì‚¬ì „ ì¤€ë¹„ ì‚¬í•­
- **Python**: 3.10 ì´ìƒ
- **Ollama (ì„ íƒ ì‚¬í•­)**: ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© ì‹œ, Ollamaê°€ ì„¤ì¹˜ë˜ì–´ ìˆê³  ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•©ë‹ˆë‹¤.
  - ì„¤ì¹˜ëŠ” [Ollama ê³µì‹ ì›¹ì‚¬ì´íŠ¸](https://ollama.com)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
- **Gemini API í‚¤ (ì„ íƒ ì‚¬í•­)**: Gemini ëª¨ë¸ ì‚¬ìš© ì‹œ, API í‚¤ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.
  - í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í„°ë¦¬ì— `.env` íŒŒì¼ì„ ìƒì„±í•˜ì„¸ìš”.
  - íŒŒì¼ì— `GEMINI_API_KEY="YOUR_API_KEY"` í˜•ì‹ìœ¼ë¡œ API í‚¤ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
  - [Google AI Studio](https://aistudio.google.com/app/apikey)ì—ì„œ í‚¤ë¥¼ ë°œê¸‰ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤**: ë¡œì»¬ ëª¨ë¸ì˜ ê²½ìš°, ì¶©ë¶„í•œ RAM(ì˜ˆ: 7B ëª¨ë¸ì˜ ê²½ìš° 16GB ì´ìƒ)ì´ ê¶Œì¥ë©ë‹ˆë‹¤.

---

### ğŸ’» ì„¤ì¹˜ ë° ì‹¤í–‰

1.  **ì €ì¥ì†Œ í´ë¡ **
    ```bash
    git clone https://github.com/darkzard05/rag-system-ollama.git
    cd rag-system-ollama
    ```

2.  **(ê¶Œì¥) ê°€ìƒ í™˜ê²½ ìƒì„± ë° í™œì„±í™”**
    ```bash
    python -m venv venv
    
    # Windows
    venv\Scripts\activate
    
    # macOS/Linux
    source venv/bin/activate
    ```

3.  **í•„ìš”í•œ Python íŒ¨í‚¤ì§€ ì„¤ì¹˜**
    ```bash
    pip install -r requirements.txt
    ```

4.  **(Ollama ì‚¬ìš©ì) ëª¨ë¸ ë‹¤ìš´ë¡œë“œ**
    ì‹œì‘ì„ ìœ„í•´ ë²”ìš© ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤. ë” ë§ì€ ëª¨ë¸ì€ [Ollama ë¼ì´ë¸ŒëŸ¬ë¦¬](https://ollama.com/library)ì—ì„œ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    ```bash
    ollama pull llama3:8b
    ```
    - ì´ ëª…ë ¹ì„ ì‹¤í–‰í•˜ê¸° ì „ì— Ollama ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
    - `config.yml`ì˜ `default_ollama` ëª¨ë¸ ì´ë¦„ì´ ë‹¤ìš´ë¡œë“œí•œ ëª¨ë¸ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

5.  **Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰**
    ```bash
    streamlit run src/main.py
    ```

6.  ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8501`ë¡œ ì ‘ì†í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

## ğŸ“ íŒŒì¼ êµ¬ì¡°
```
.
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ readme.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ image/
â”‚   â””â”€â”€ image1.png
â””â”€â”€ src/
    â”œâ”€â”€ main.py
    â”œâ”€â”€ ui.py
    â”œâ”€â”€ session.py
    â”œâ”€â”€ rag_core.py
    â”œâ”€â”€ config.py
    â””â”€â”€ config.yml
```
- **`main.py`**: Streamlit ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì§„ì…ì ì…ë‹ˆë‹¤.
- **`ui.py`**: Streamlit ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ ë Œë”ë§ í•¨ìˆ˜ë“¤ì„ í¬í•¨í•©ë‹ˆë‹¤.
- **`session.py`**: ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„¸ì…˜ ìƒíƒœë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
- **`rag_core.py`**: RAG ì‹œìŠ¤í…œì˜ í•µì‹¬ ë¡œì§(ë°ì´í„° ì²˜ë¦¬, ì„ë² ë”©, ë¦¬íŠ¸ë¦¬ë²„, QA ì²´ì¸)ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
- **`config.py`**: ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„¤ì • ìƒìˆ˜ë¥¼ ë¡œë“œí•˜ê³  ì œê³µí•©ë‹ˆë‹¤.
- **`config.yml`**: ëª¨ë¸ ëª©ë¡, ë¦¬íŠ¸ë¦¬ë²„ ì„¤ì • ë“± ì£¼ìš” ì„¤ì •ì„ ì €ì¥í•˜ëŠ” YAML íŒŒì¼ì…ë‹ˆë‹¤.
- **`.env.example`**: í™˜ê²½ ë³€ìˆ˜ ì˜ˆì‹œ íŒŒì¼ì…ë‹ˆë‹¤. ì´ íŒŒì¼ì„ `.env`ë¡œ ë³µì‚¬í•˜ì—¬ API í‚¤ ë“±ì„ ì„¤ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## âœ¨ ì£¼ìš” êµ¬ì„± ìš”ì†Œ

- **PDF ë¡œë” (PyMuPDF)**: ì—…ë¡œë“œëœ PDF íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ë¡œë“œí•˜ê³  ì¶”ì¶œí•©ë‹ˆë‹¤.
- **í…ìŠ¤íŠ¸ ë¶„í• ê¸° (Langchain)**: ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê¸° ì‰¬ìš´ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
- **ì„ë² ë”© ëª¨ë¸ (Sentence Transformers)**: í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ìˆ«ì ë²¡í„° ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
- **ë²¡í„° ì €ì¥ì†Œ (FAISS)**: ë²¡í„° ì„ë² ë”©ì„ ì €ì¥í•˜ì—¬ íš¨ìœ¨ì ì¸ ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
- **ë¦¬íŠ¸ë¦¬ë²„ (Ensemble)**: í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰(**BM25**)ê³¼ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰(**FAISS**)ì„ ê²°í•©í•˜ì—¬ ì£¼ì–´ì§„ ì¿¼ë¦¬ì— ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
- **LLM (Ollama & Gemini)**: ì„ íƒëœ ì–¸ì–´ ëª¨ë¸ì´ ì‚¬ìš©ìì˜ ì¿¼ë¦¬ì™€ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
- **Streamlit UI**: ëª¨ë“  ì‚¬ìš©ì ìƒí˜¸ ì‘ìš©ì„ ìœ„í•œ ëŒ€í™”í˜• ì›¹ ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

## âš™ï¸ ì„¤ì •

- **API í‚¤**: í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ì„ ë§Œë“¤ê³  `GEMINI_API_KEY`ë¥¼ ì„¤ì •í•˜ì„¸ìš”.
- **ëª¨ë¸ ë° íŒŒë¼ë¯¸í„°**: `config.yml` íŒŒì¼ì—ì„œ ëª¨ë¸, ë¦¬íŠ¸ë¦¬ë²„ ê°€ì¤‘ì¹˜, í…ìŠ¤íŠ¸ ë¶„í• ê¸° ì„¤ì • ë“±ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸš‘ ë¬¸ì œ í•´ê²°

- **Ollama ì—°ê²° ë¬¸ì œ**: Ollama ì• í”Œë¦¬ì¼€ì´ì…˜/ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš” (`ollama list`).
- **Gemini API í‚¤ ë¬¸ì œ**: í‚¤ê°€ ì˜¬ë°”ë¥´ê³  `.env` íŒŒì¼ì— ì •í™•íˆ ì„¤ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. `429` ì˜¤ë¥˜ëŠ” API í• ë‹¹ëŸ‰ì„ ì´ˆê³¼í–ˆìŒì„ ì˜ë¯¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- **ëŠë¦° ì„±ëŠ¥**: ëŒ€ìš©ëŸ‰ PDFë¥¼ ì²˜ë¦¬í•˜ê±°ë‚˜ í° ë¡œì»¬ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë¦¬ì†ŒìŠ¤ë¥¼ ë§ì´ ì†Œëª¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì´ ê¶Œì¥ ì‚¬ì–‘ì„ ì¶©ì¡±í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

## ğŸ“„ ë¼ì´ì„ ìŠ¤
ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.
