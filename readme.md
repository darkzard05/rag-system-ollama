# RAG System with Ollama & LangGraph

> **A High-Performance, Local Retrieval-Augmented Generation (RAG) Solution.**  
> Optimized for speed and accuracy using `LangGraph` orchestration and local `Ollama` models.

[![Python 3.11+](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://www.python.org)
[![Model: qwen3:4b-instruct](https://img.shields.io/badge/Model-qwen3:4b--instruct-blueviolet.svg)](https://ollama.com/library/qwen3)
[![Backend: LangGraph](https://img.shields.io/badge/Orchestrator-LangGraph-informational.svg)]()
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“¸ Preview

![Application Interface](image/image1.png)

*The interface provides a clean chat experience with sidebar controls for document upload and model selection.*

---

## âš¡ Key Highlights

### ğŸš€ **Performance Optimized**
- **Zero Thinking Time:** Switch to `qwen3:4b-instruct` eliminates the 2-3 minute wait time of standard models, delivering answers in seconds.
- **Async & Parallel:** Uses `AsyncIO` for parallel document retrieval and processing.
- **Device-Aware:** Automatically optimizes embedding and reranking tasks based on available hardware (CPU/GPU).

### ğŸ§  **Intelligent RAG Pipeline**
- **LangGraph Orchestration:** Precise state management for complex reasoning flows.
- **Hybrid Search:** Combines semantic search (Dense) with keyword search (Sparse/BM25) for best-in-class retrieval.
- **Adaptive Reranking:** Filters irrelevant documents to ensure the LLM receives only high-quality context.

### ğŸ›¡ï¸ **Enterprise-Grade Security**
- **Cache Integrity:** Protects cached models and vectors with SHA256 checksums and HMAC verification.
- **Safe Loading:** Prevents unauthorized model loading via strict path validation.

---

## ğŸ› ï¸ Getting Started

### 1ï¸âƒ£ Prerequisites
- **Python 3.11+**
- **Ollama**: Download from [ollama.ai](https://ollama.ai)

### 2ï¸âƒ£ Model Setup (Crucial)
We highly recommend using the **instruct** version of Qwen3 for the best RAG experience (fast response, no long "thinking" loops).

```powershell
# Pull the recommended model
ollama pull qwen3:4b-instruct-2507-q4_K_M

# (Optional) Pull embedding models if not auto-downloaded
# The system will handle this automatically on first run.
```

### 3ï¸âƒ£ Installation
```bash
git clone https://github.com/darkzard05/rag-system-ollama.git
cd rag-system-ollama

# Create Virtual Environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install Dependencies
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configuration
The system is pre-configured in `config.yml`.
Ensure the default model is set correctly for optimal performance:

```yaml
# config.yml
models:
  default_ollama: "qwen3:4b-instruct-2507-q4_K_M"
```

---

## ğŸ–¥ï¸ Usage

### Run the Frontend (Streamlit UI)
The main interface for chatting with your documents.
```bash
streamlit run src/main.py
```

### Run the Backend (API Server)
For integrating RAG capabilities into other applications.
```bash
uvicorn src.api.api_server:app --host 0.0.0.0 --port 8000
```

---

## ğŸ—ï¸ Project Structure

```text
rag-system-ollama/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py             # ğŸ Streamlit Entry Point
â”‚   â”œâ”€â”€ core/               # ğŸ§  RAG Engine (Graph, Retrieval, Models)
â”‚   â”œâ”€â”€ api/                # ğŸ”Œ FastAPI Server
â”‚   â”œâ”€â”€ services/           # âš¡ Monitoring & Background Services
â”‚   â”œâ”€â”€ security/           # ğŸ›¡ï¸ Security & Cache Verification
â”‚   â””â”€â”€ common/             # ğŸ› ï¸ Config & Utils
â”œâ”€â”€ image/                  # ğŸ–¼ï¸ Assets & Screenshots
â”œâ”€â”€ logs/                   # ğŸ“ Application & Performance Logs
â”œâ”€â”€ reports/                # ğŸ“Š Benchmarks & Audit Reports
â””â”€â”€ tests/                  # ğŸ§ª Test Suite
```

---

## ğŸ“š Documentation & Reports

- **[Model Recommendation Report](./reports/MODEL_SELECTION_RECOMMENDATION.md)**: Why we chose `qwen3:4b-instruct`.
- **[Performance Audit](./reports/PERFORMANCE_AND_QUALITY_AUDIT.md)**: Detailed analysis of system latency and throughput.
- **[API Reference](./docs/API.md)**: Endpoints documentation.

---

## ğŸ“„ License
MIT License - Developed by **darkzard05**.

**Status:** Stable (v2.1.0) | **Last Updated:** 2026-01-27