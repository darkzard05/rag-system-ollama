user_input,retrieved_contexts,response,reference,faithfulness,answer_relevancy,context_precision,context_recall
CM3 모델은 어떤 종류의 모델을 사용하여 개발되었나요?,"['The third prompt, CM3, is incapable of drawing the face of a sheep while getting the general body and texture correct. We note that CM3 trains with an order of magnitude less unique images than DALL-E, and the subset of images available to CM3 are the images available in news and Wikipedia articles; therefore, CM3 does not generate ﬁctional images well.', '8 CONCLUSION In this paper, we present the CM3 model, a causally masked trained language model that is capable of non-trivial zero-shot performance on a wide range of zero-shot uni- and cross-modal tasks.', 'We show both qualitatively and quantitatively that CM3 can be prompted for non-trivial image generation, similar to that of DALL-E. We also show that CM3 models are ca- pable of improving over state-of-the-art zero-shot summarization, entity linking, entity disambigua- tion, highlighting the structure that comes from the hypertext during training. Finally, we show that by ﬁne-tuning CM3 we set the new state-of-the-art for entity linking and entity disambiguation in general.', 'We ﬁrst describe a new sequence modeling objective we call causally masked, enabling both full generative modeling with bidirectional context. Through extensive experimentation, we show that as a single model CM3 can be prompted to re- cover the functionality of many other models being able to do image generation, image captioning, unconditional image generation, and more.', 'We see that our CM3 are extremely competitive with entity-linking speciﬁc models and that our CM3-Large model sets a new state-of-the-art. Furthermore, although our zero-shot numbers are substantially worse, they are still non-trivial, implying that CM3 learns a signiﬁcant amount of implicit entity linking through our training setting.', 'arXiv:1904.01310, 2019. 18 A APPENDIX A.1 MODEL ARCHITECTURE For model architecture we use the same exact architecture for CM3-Medium and CM3-Large as the dense 2.7B and 13B models described in Artetxe et al.', '0 1 2 3 4 Number of Documents 1e8 100 Validation Perplexity 0 50000 100000 150000 200000 Number of Updates 100 0 1 2 3 Training Time (Seconds) 1e6 100 Model CM3-XSmall CM3-Small CM3-Medium CM3-Large Perplexity Based Scaling Laws for CM3 Figure 2: Basic perplexity based scaling laws for the proposed CM3 objective and training set-up.', 'We compare CM3 with a wide array of masked language model derived models such as T5 (Raffel et al., 2019), RoBERTa (Liu et al., 2019), HTLM (Aghajanyan et al., 2021) tested on the standard GLUE benchmark (Wang et al., 2018). For CM3 we look at three settings for ﬁne-tuning; standard ﬁne- tuning, better ﬁne-tuning using adversarial methods (Aghajanyan et al., 2020), and better ﬁne-tuning over prompts derived from Aghajanyan et al.', 'Given the generative nature of CM3 in both the language and visual modalities, we used GWEAT/GSEAT to probe our model. Overall, we evaluated six bias tests for gender and seven bias tests for race and found that our family of CM3 models show signiﬁcantly less bias than other models, speiciﬁcally VisualBERT (Li et al., 2019) and ViLBert (Lu et al., 2019).', 'The resulting CM3 models can generate rich structured, multi- modal outputs while conditioning on arbitrary masked document contexts, and thereby implicitly learn a wide range of text, image, and cross modal tasks.']",CM3 모델은 **causally masked trained language model**을 사용하여 개발되었습니다.[p.14],CM3는 구조화된 다모달 문서의 대규모 데이터 세트를 기반으로 학습된 인과적 마스킹 생성 모델입니다. 이 모델은 텍스트와 이미지 토큰을 모두 포함할 수 있는 문서에서 학습됩니다.,1.0,,,
CM3 모델이 생성하는 토큰은 어떻게 이루어지나요?,"['We show both qualitatively and quantitatively that CM3 can be prompted for non-trivial image generation, similar to that of DALL-E. We also show that CM3 models are ca- pable of improving over state-of-the-art zero-shot summarization, entity linking, entity disambigua- tion, highlighting the structure that comes from the hypertext during training. Finally, we show that by ﬁne-tuning CM3 we set the new state-of-the-art for entity linking and entity disambiguation in general.', 'The third prompt, CM3, is incapable of drawing the face of a sheep while getting the general body and texture correct. We note that CM3 trains with an order of magnitude less unique images than DALL-E, and the subset of images available to CM3 are the images available in news and Wikipedia articles; therefore, CM3 does not generate ﬁctional images well.', '8 CONCLUSION In this paper, we present the CM3 model, a causally masked trained language model that is capable of non-trivial zero-shot performance on a wide range of zero-shot uni- and cross-modal tasks.', 'We delegate the speciﬁcs hyper-parameters of the ﬁne-tuning experiments to § A.3 MNLI Acc-m/mm QQP Acc RTE Acc QNLI Acc MRPC Acc CoLA Mcc SST-2 Acc # Params T5-Base 87.1/86.2 89.4 80.1 93.7 87.5 51.1 95.2 220M RoBERTA 90.2/- 92.2 86.6 94.7 89.1 68.0 96.4 330M RoBERTa-R3F 91.1/91.3 92.4 88.5 95.3 91.6 71.2 97.0 330M BART-Large 89.9/90.1 92.5 87.0 94.9 90.4 62.8 96.6 400M HTLM 90.3/91.4 92.6 87.1 95.1 90.8 64.3 96.9 400M HTLM-R3F 91.4/92.1 92.8 89.1 95.4 91.5 69.4 97.1 400M HTLM-R3F-Prompt 91.6/91.2 92.9 89.4 95.7 91.7 69.8 97.3 400M T5-Large 89.9/89.6 89.9 87.2 94.8 89.9 61.2 96.3 770M T5-3B 91.4/91.2 89.7 91.1 96.3 90.0 67.1 97.4 3B T5-11B 92.2/91.9 90.6 92.8 96.9 90.4 71.6 97.5 11B CM3-Medium 89.9/89.7 89.6 89.1 93.1 86.5 63.1 94.9 2.7B CM3-Medium-Prompt 90.8/91.0 89.9 90.5 95.1 89.9 66.2 96.3 2.7B CM3-Medium-RXF-Prompt 90.9/91.1 90.0 90.7 95.3 90.0 67.1 96.9 2.7B CM3-Large 91.1/91.0 89.9 91.9 95.6 89.6 64.6 94.2 13B CM3-Large-Prompt 91.5/91.4 90.1 92.4 96.2 90.1 70.9 97.1 13B CM3-Large-RXF-Prompt 91.9/91.5 91.1 92.5 96.4 90.3 70.8 97.3 13B Table 7: Results on the GLUE development set for various ﬁne-tuning methods applied to CM3.', 'We see that our CM3 are extremely competitive with entity-linking speciﬁc models and that our CM3-Large model sets a new state-of-the-art. Furthermore, although our zero-shot numbers are substantially worse, they are still non-trivial, implying that CM3 learns a signiﬁcant amount of implicit entity linking through our training setting.', 'arXiv:1904.01310, 2019. 18 A APPENDIX A.1 MODEL ARCHITECTURE For model architecture we use the same exact architecture for CM3-Medium and CM3-Large as the dense 2.7B and 13B models described in Artetxe et al.', '0 1 2 3 4 Number of Documents 1e8 100 Validation Perplexity 0 50000 100000 150000 200000 Number of Updates 100 0 1 2 3 Training Time (Seconds) 1e6 100 Model CM3-XSmall CM3-Small CM3-Medium CM3-Large Perplexity Based Scaling Laws for CM3 Figure 2: Basic perplexity based scaling laws for the proposed CM3 objective and training set-up.', 'The resulting CM3 models can generate rich structured, multi- modal outputs while conditioning on arbitrary masked document contexts, and thereby implicitly learn a wide range of text, image, and cross modal tasks.', 'Given the generative nature of CM3 in both the language and visual modalities, we used GWEAT/GSEAT to probe our model. Overall, we evaluated six bias tests for gender and seven bias tests for race and found that our family of CM3 models show signiﬁcantly less bias than other models, speiciﬁcally VisualBERT (Li et al., 2019) and ViLBert (Lu et al., 2019).']",문서 내에서 CM3 모델이 생성하는 토큰에 대한 구체적인 설명은 제공되지 않았습니다. 따라서 CM3 모델이 생성하는 토큰의 구조나 메커니즘에 대한 근거를 찾을 수 없습니다.,"CM3 모델은 토큰을 왼쪽에서 오른쪽으로 생성하며, 문자열 끝부분에 생성되는 소수의 긴 토큰 스피언을 원래 위치에서 마스킹하는 방식으로 작동합니다.",,,,0.0
CM3 모델은 어떤 데이터를 기반으로 훈련되었나요?,"['We show both qualitatively and quantitatively that CM3 can be prompted for non-trivial image generation, similar to that of DALL-E. We also show that CM3 models are ca- pable of improving over state-of-the-art zero-shot summarization, entity linking, entity disambigua- tion, highlighting the structure that comes from the hypertext during training. Finally, we show that by ﬁne-tuning CM3 we set the new state-of-the-art for entity linking and entity disambiguation in general.', 'The third prompt, CM3, is incapable of drawing the face of a sheep while getting the general body and texture correct. We note that CM3 trains with an order of magnitude less unique images than DALL-E, and the subset of images available to CM3 are the images available in news and Wikipedia articles; therefore, CM3 does not generate ﬁctional images well.', '8 CONCLUSION In this paper, we present the CM3 model, a causally masked trained language model that is capable of non-trivial zero-shot performance on a wide range of zero-shot uni- and cross-modal tasks.', 'The resulting CM3 models can generate rich structured, multi- modal outputs while conditioning on arbitrary masked document contexts, and thereby implicitly learn a wide range of text, image, and cross modal tasks.', 'We see that our CM3 are extremely competitive with entity-linking speciﬁc models and that our CM3-Large model sets a new state-of-the-art. Furthermore, although our zero-shot numbers are substantially worse, they are still non-trivial, implying that CM3 learns a signiﬁcant amount of implicit entity linking through our training setting.', 'We delegate the speciﬁcs hyper-parameters of the ﬁne-tuning experiments to § A.3 MNLI Acc-m/mm QQP Acc RTE Acc QNLI Acc MRPC Acc CoLA Mcc SST-2 Acc # Params T5-Base 87.1/86.2 89.4 80.1 93.7 87.5 51.1 95.2 220M RoBERTA 90.2/- 92.2 86.6 94.7 89.1 68.0 96.4 330M RoBERTa-R3F 91.1/91.3 92.4 88.5 95.3 91.6 71.2 97.0 330M BART-Large 89.9/90.1 92.5 87.0 94.9 90.4 62.8 96.6 400M HTLM 90.3/91.4 92.6 87.1 95.1 90.8 64.3 96.9 400M HTLM-R3F 91.4/92.1 92.8 89.1 95.4 91.5 69.4 97.1 400M HTLM-R3F-Prompt 91.6/91.2 92.9 89.4 95.7 91.7 69.8 97.3 400M T5-Large 89.9/89.6 89.9 87.2 94.8 89.9 61.2 96.3 770M T5-3B 91.4/91.2 89.7 91.1 96.3 90.0 67.1 97.4 3B T5-11B 92.2/91.9 90.6 92.8 96.9 90.4 71.6 97.5 11B CM3-Medium 89.9/89.7 89.6 89.1 93.1 86.5 63.1 94.9 2.7B CM3-Medium-Prompt 90.8/91.0 89.9 90.5 95.1 89.9 66.2 96.3 2.7B CM3-Medium-RXF-Prompt 90.9/91.1 90.0 90.7 95.3 90.0 67.1 96.9 2.7B CM3-Large 91.1/91.0 89.9 91.9 95.6 89.6 64.6 94.2 13B CM3-Large-Prompt 91.5/91.4 90.1 92.4 96.2 90.1 70.9 97.1 13B CM3-Large-RXF-Prompt 91.9/91.5 91.1 92.5 96.4 90.3 70.8 97.3 13B Table 7: Results on the GLUE development set for various ﬁne-tuning methods applied to CM3.', '0 1 2 3 4 Number of Documents 1e8 100 Validation Perplexity 0 50000 100000 150000 200000 Number of Updates 100 0 1 2 3 Training Time (Seconds) 1e6 100 Model CM3-XSmall CM3-Small CM3-Medium CM3-Large Perplexity Based Scaling Laws for CM3 Figure 2: Basic perplexity based scaling laws for the proposed CM3 objective and training set-up.', 'Given the generative nature of CM3 in both the language and visual modalities, we used GWEAT/GSEAT to probe our model. Overall, we evaluated six bias tests for gender and seven bias tests for race and found that our family of CM3 models show signiﬁcantly less bias than other models, speiciﬁcally VisualBERT (Li et al., 2019) and ViLBert (Lu et al., 2019).', 'We compare CM3 with a wide array of masked language model derived models such as T5 (Raffel et al., 2019), RoBERTa (Liu et al., 2019), HTLM (Aghajanyan et al., 2021) tested on the standard GLUE benchmark (Wang et al., 2018). For CM3 we look at three settings for ﬁne-tuning; standard ﬁne- tuning, better ﬁne-tuning using adversarial methods (Aghajanyan et al., 2020), and better ﬁne-tuning over prompts derived from Aghajanyan et al.']",CM3 모델은 뉴스 및 위키백과사전에 포함된 이미지 집합을 기반으로 훈련되었습니다.[p.6],CM3 모델은 공통 크롤에서 수집한 거의 테라바이트의 다중 모드 간단한 HTML 데이터를 기반으로 훈련되었습니다.,0.6666666666666666,,,0.0
CM3 모델의 훈련에 사용된 주요 목적은 무엇인가요?,"['We show both qualitatively and quantitatively that CM3 can be prompted for non-trivial image generation, similar to that of DALL-E. We also show that CM3 models are ca- pable of improving over state-of-the-art zero-shot summarization, entity linking, entity disambigua- tion, highlighting the structure that comes from the hypertext during training. Finally, we show that by ﬁne-tuning CM3 we set the new state-of-the-art for entity linking and entity disambiguation in general.', 'The third prompt, CM3, is incapable of drawing the face of a sheep while getting the general body and texture correct. We note that CM3 trains with an order of magnitude less unique images than DALL-E, and the subset of images available to CM3 are the images available in news and Wikipedia articles; therefore, CM3 does not generate ﬁctional images well.', '8 CONCLUSION In this paper, we present the CM3 model, a causally masked trained language model that is capable of non-trivial zero-shot performance on a wide range of zero-shot uni- and cross-modal tasks.', 'The resulting CM3 models can generate rich structured, multi- modal outputs while conditioning on arbitrary masked document contexts, and thereby implicitly learn a wide range of text, image, and cross modal tasks.', 'We see that our CM3 are extremely competitive with entity-linking speciﬁc models and that our CM3-Large model sets a new state-of-the-art. Furthermore, although our zero-shot numbers are substantially worse, they are still non-trivial, implying that CM3 learns a signiﬁcant amount of implicit entity linking through our training setting.', 'We delegate the speciﬁcs hyper-parameters of the ﬁne-tuning experiments to § A.3 MNLI Acc-m/mm QQP Acc RTE Acc QNLI Acc MRPC Acc CoLA Mcc SST-2 Acc # Params T5-Base 87.1/86.2 89.4 80.1 93.7 87.5 51.1 95.2 220M RoBERTA 90.2/- 92.2 86.6 94.7 89.1 68.0 96.4 330M RoBERTa-R3F 91.1/91.3 92.4 88.5 95.3 91.6 71.2 97.0 330M BART-Large 89.9/90.1 92.5 87.0 94.9 90.4 62.8 96.6 400M HTLM 90.3/91.4 92.6 87.1 95.1 90.8 64.3 96.9 400M HTLM-R3F 91.4/92.1 92.8 89.1 95.4 91.5 69.4 97.1 400M HTLM-R3F-Prompt 91.6/91.2 92.9 89.4 95.7 91.7 69.8 97.3 400M T5-Large 89.9/89.6 89.9 87.2 94.8 89.9 61.2 96.3 770M T5-3B 91.4/91.2 89.7 91.1 96.3 90.0 67.1 97.4 3B T5-11B 92.2/91.9 90.6 92.8 96.9 90.4 71.6 97.5 11B CM3-Medium 89.9/89.7 89.6 89.1 93.1 86.5 63.1 94.9 2.7B CM3-Medium-Prompt 90.8/91.0 89.9 90.5 95.1 89.9 66.2 96.3 2.7B CM3-Medium-RXF-Prompt 90.9/91.1 90.0 90.7 95.3 90.0 67.1 96.9 2.7B CM3-Large 91.1/91.0 89.9 91.9 95.6 89.6 64.6 94.2 13B CM3-Large-Prompt 91.5/91.4 90.1 92.4 96.2 90.1 70.9 97.1 13B CM3-Large-RXF-Prompt 91.9/91.5 91.1 92.5 96.4 90.3 70.8 97.3 13B Table 7: Results on the GLUE development set for various ﬁne-tuning methods applied to CM3.', '0 1 2 3 4 Number of Documents 1e8 100 Validation Perplexity 0 50000 100000 150000 200000 Number of Updates 100 0 1 2 3 Training Time (Seconds) 1e6 100 Model CM3-XSmall CM3-Small CM3-Medium CM3-Large Perplexity Based Scaling Laws for CM3 Figure 2: Basic perplexity based scaling laws for the proposed CM3 objective and training set-up.', 'Given the generative nature of CM3 in both the language and visual modalities, we used GWEAT/GSEAT to probe our model. Overall, we evaluated six bias tests for gender and seven bias tests for race and found that our family of CM3 models show signiﬁcantly less bias than other models, speiciﬁcally VisualBERT (Li et al., 2019) and ViLBert (Lu et al., 2019).', '• We demonstrate consistently strong transfer from CM3 to a range of uni-modal and multi- modal tasks at differing supervision levels, including stating state-of-the-art on entity dis- ambiguation and zero-shot summarization.']","CM3 모델의 훈련에 사용된 주요 목적은 임의의 마스킹된 문서 컨텍스트를 조건으로 하여 풍부한 구조화된 다모달 출력을 생성할 수 있도록 하며, 이 과정을 통해 텍스트, 이미지, 그리고 다모달 작업에 대한 광범위한 임피디트 학습을 묵시적으로 수행하는 것입니다.[p.1]","CM3 모델의 훈련에 사용된 주요 목적은 사고적으로 마스킹된 목적(causally masked objective)이며, 이는 사고적 및 마스킹 언어 모델의 하이브리드로, 생성 마스킹 채우기 과정에서 양방향 컨텍스트 제어를 가능하게 합니다.",,,,1.0
Monte Melkonian의 정치적 성향과 정체성은 무엇인가요?,"['2 Monte Melkonian was left-wing a nationalist militant . Masked Language Model <a href= Armenian _nationalism > <mask> Monte Melkonian was <a left-wing a href= Armenian _nationalism > nationalist militant . Language Model Monte Melkonian was left-wing a nationalist militant .', 'Hyper Parameter MNLI QNLI QQP SST-2 RTE MRPC CoLA Learning Rate 5e-6 5e-6 5e-6 5e-6 1e-5 1e-5 1e-5 Max Updates 123873 33112 113272 20935 3120 2296 5336 Max Sentences 8 8 32 32 8 16 16 Table 11: Task speciﬁc hyper parameters for GLUE experiments 19 Hyper parameter Value Optimizer Adam Adam-betas (0.9, 0.98) Adam-eps 1e-6 LR Scheduler polynomial decay Dropout 0.1 Weight Decay 0.01 Warmup Updates 0.06 * max updates Hyper parameter Value λ [0.1, 0.5, 1.0, 5.0] Noise Types [U, N] σ 1e −5 Table 12: Hyper parameters for ﬁne-tuning experiments on GLUE 20', 'CM3: A CAUSAL MASKED MULTIMODAL MODEL OF THE INTERNET Armen Aghajanyan, Bernie Huang∗, Candace Ross∗, Vlad Karpukhin∗, Hu Xu∗, Naman Goyal, Dmytro Okhonko, Mandar Joshi, Gargi Ghosh, Mike Lewis, Luke Zettlemoyer Facebook AI Research {armenag,berniehuang,ccross,vladk,huxu,naman}@fb.com {oxo,mandarj,gghosh,mikelewis,lsz}@fb.com ABSTRACT We introduce CM3, a family of causally masked generative models trained over a large corpus of structured multi-modal documents that can contain both text and image tokens.', '0 1 2 3 4 Number of Documents 1e8 100 Validation Perplexity 0 50000 100000 150000 200000 Number of Updates 100 0 1 2 3 Training Time (Seconds) 1e6 100 Model CM3-XSmall CM3-Small CM3-Medium CM3-Large Perplexity Based Scaling Laws for CM3 Figure 2: Basic perplexity based scaling laws for the proposed CM3 objective and training set-up.', 'Luckily HTML based Wikipedia contains very rich annotations. Speciﬁcally below, we show an example of naturally occurring entity linking that would occur in our Wikipedia subset of CM3 training data. Original: Manetho writes that these kings ruled from <a title=""Memphis, Egypt"">Memphis</a> Prompt: Manetho writes that these kings ruled from <a title=""<mask:0>"">Memphis</a>...<mask:0> Target: Manetho writes that these kings ruled from <a title=""<mask:0>"">Memphis</a>...<mask:0> Memphis, Egypt Using our scoring approach we can simply score the Target while swapping out the postﬁx after <mask:0>.', 'the wooden park benches are painted dark purple. some bread is on a plate with jam, an apple, yogurt and orange juice. a nice looking hotel room with a neatly done bed, coffee table, and a chair. Source Image Masked/Tokenized Image CM3-Inﬁlling-U CM3-Inﬁlling-C Ground Truth Figure 4: We provide qualitative samples for zero-shot image-inﬁlling using the CM3-Large model using the aforementioned prompts.', 'Causally Masked Language Model <mask:0> <mask:0> <a href= Armenian _nationalism > Figure 1: A visual representation of various language modeling objectives as well as our proposed causal language modeling objective with a single mask (n = 1).', '4.2.3 CAPTIONING We next look at the dual-task to conditional image generation and image captioning. We can prompt CM3 to do zero-shot image captioning by asking the model to generate either the alt or title 6 group of people windsurfing over the beach and water in the ocean.', 'Science, 356:183 – 186, 2017. Nicola De Cao, Gautier Izacard, Sebastian Riedel, and Fabio Petroni. Autoregressive entity retrieval. arXiv preprint arXiv:2010.00904, 2020. Leon Derczynski, Diana Maynard, Giuseppe Rizzo, Marieke Van Erp, Genevieve Gorrell, Rapha¨el Troncy, Johann Petrak, and Kalina Bontcheva.']",Monte Melkonian은 좌파이자 민족주의 운동가입니다.[p.3],Monte Melkonian는 좌파이자 아르메니아 민족주의자이자 민중 운동가였습니다.,,,,0.0
