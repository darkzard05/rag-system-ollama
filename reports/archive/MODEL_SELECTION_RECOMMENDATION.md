# 📄 모델 선정 권장 사항: Instruct vs Thinking (Base)

**작성일:** 2026년 1월 27일
**작성자:** Gemini Agent
**대상 모델:** `qwen3:4b` vs `qwen3:4b-instruct`

## 1. 개요
본 문서는 로컬 RAG 시스템(`win32`, CPU/Low-VRAM 환경)에서의 LLM 모델 선정 기준과 테스트 결과를 기록합니다. 초기 설정이었던 Base(Thinking) 모델과 최적화된 Instruct 모델의 성능을 비교하여, 향후 배포 및 설정 시 참고 자료로 활용합니다.

## 2. 성능 비교 분석
2026년 1월 27일 수행된 벤치마크 로그를 기반으로 한 비교 데이터입니다.

| 비교 항목 | qwen3:4b (Base/Thinking) | qwen3:4b-instruct (Recommended) | 개선 효과 |
| :--- | :--- | :--- | :--- |
| **초당 토큰 수 (TPS)** | 평균 5.97 | **평균 8.06** | **약 35% 속도 향상** |
| **첫 응답 시간 (TTFT)** | 2.0 ~ 4.0초 | **1.8 ~ 6.4초** | 유사함 (즉각 반응) |
| **사고 시간 (Thinking)**| **100초 ~ 300초** (과도함) | **0초** (즉시 답변) | **대기 시간 제거** |
| **총 소요 시간** | 150초 ~ 220초 | **30초 ~ 60초** | **약 4~5배 단축** |

## 3. 상세 분석 결과

### 3.1 Base 모델 (`qwen3:4b`)의 문제점
*   **불필요한 사고 과정:** Base 모델은 사용자의 질문에 바로 답하기보다, 내부적인 사고(Thinking) 프로세스를 거치도록 설계되어 있습니다. RAG 시스템에서 문서를 바탕으로 명확한 답변을 요구할 때, 이 사고 과정이 오히려 장애물이 됩니다.
*   **긴 대기 시간:** "생각을 정리하는 중..." 단계에서만 최대 5분 가까이 소요되어 사용자 경험(UX)을 심각하게 저해합니다.

### 3.2 Instruct 모델 (`qwen3:4b-instruct`)의 강점
*   **지시 이행 최적화:** "주어진 문맥(Context)을 바탕으로 답변하라"는 시스템 프롬프트(System Prompt)를 즉각적으로 이해하고 수행합니다.
*   **효율성:** 불필요한 추론 루프 없이 바로 답변 생성(Generation) 단계로 진입하여 리소스를 답변 작성에만 집중합니다.

## 4. 결론 및 조치 사항

### ✅ 최종 권장 모델
**`qwen3:4b-instruct-2507-q4_K_M`**

### 🛠 적용 가이드
1.  **모델 다운로드:**
    ```powershell
    ollama pull qwen3:4b-instruct-2507-q4_K_M
    ```
2.  **설정 변경 (`config.yml`):**
    ```yaml
    models:
      default_ollama: "qwen3:4b-instruct-2507-q4_K_M"
    ```
3.  **기대 효과:**
    *   답변 속도 4배 이상 향상
    *   불필요한 "생각 중" 상태 제거로 쾌적한 채팅 경험 제공
