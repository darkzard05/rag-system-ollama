import os
import sys
import asyncio
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
ROOT_DIR = Path(__file__).parent.parent.absolute()
sys.path.append(str(ROOT_DIR / "src"))

from core.rag_core import RAGSystem
from core.model_loader import ModelManager
from common.config import DEFAULT_OLLAMA_MODEL
from common.logging_config import setup_logging

async def verify_system():
    # ë¡œê¹… ì„¤ì • (ê²€ì¦ìš©)
    setup_logging(log_level="INFO")
    
    print("\n" + "="*60)
    print("ğŸš€ RAG System Refactoring Verification")
    print("="*60)

    session_id = f"verify-{int(datetime.now().timestamp())}"
    rag = RAGSystem(session_id=session_id)
    
    # 1. ë¹„ë™ê¸° ëª¨ë¸ ë¡œë”© í…ŒìŠ¤íŠ¸
    print("\n[STEP 1] Testing Async Model Loading...")
    start = asyncio.get_event_loop().time()
    
    # ë³‘ë ¬ ë¡œë”© ì‹œë„ (ë½ ì‘ë™ í™•ì¸)
    embedder_task = ModelManager.get_embedder()
    llm_task = ModelManager.get_llm(DEFAULT_OLLAMA_MODEL)
    
    embedder, llm = await asyncio.gather(embedder_task, llm_task)
    
    elapsed = asyncio.get_event_loop().time() - start
    print(f"âœ… Models loaded successfully in {elapsed:.2f}s")

    # 2. ë¬¸ì„œ ì¸ë±ì‹± (Semantic Chunking & ResourcePool)
    test_pdf = str(ROOT_DIR / "tests" / "data" / "2201.07520v1.pdf")
    if not os.path.exists(test_pdf):
        print(f"âŒ Test PDF not found at {test_pdf}. Skipping indexing test.")
        # ëŒ€ì²´ìš© íŒŒì¼ ì°¾ê¸°
        pdf_files = list(ROOT_DIR.glob("**/*.pdf"))
        if pdf_files:
            test_pdf = str(pdf_files[0])
            print(f"ğŸ’¡ Using alternative PDF: {test_pdf}")
        else:
            return

    print(f"\n[STEP 2] Testing Document Indexing (Semantic & Page-Aware)...")
    start = asyncio.get_event_loop().time()
    
    msg, cache_used = await rag.load_document(test_pdf, os.path.basename(test_pdf), embedder)
    
    elapsed = asyncio.get_event_loop().time() - start
    print(f"âœ… {msg}")
    print(f"âœ… Indexing completed in {elapsed:.2f}s (Cache used: {cache_used})")

    # 3. ë¹„ë™ê¸° ì§ˆì˜ ì‘ë‹µ (Async Semaphore)
    print("\n[STEP 3] Testing Async Querying...")
    query = "What is this document about?"
    
    start = asyncio.get_event_loop().time()
    result = await rag.aquery(query, llm=llm)
    elapsed = asyncio.get_event_loop().time() - start
    
    response = result.get("response", "")
    thought = result.get("thought", "")
    
    print(f"âœ… Query finished in {elapsed:.2f}s")
    print(f"âœ… Response length: {len(response)} chars")
    if thought:
        print(f"âœ… Thought captured: {len(thought)} chars")

    # 4. ë©”íƒ€ë°ì´í„° ê²€ì¦ (Page-Aware Chunking ê²°ê³¼ í™•ì¸)
    print("\n[STEP 4] Verifying Metadata (Pages/Cross-page)...")
    from core.resource_pool import get_resource_pool
    from core.session import SessionManager
    
    file_hash = SessionManager.get("file_hash", session_id=session_id)
    vector_store, _ = await get_resource_pool().get(file_hash)
    
    if vector_store:
        # ë¬´ì‘ìœ„ ì²­í¬ í•˜ë‚˜ êº¼ë‚´ì„œ ë©”íƒ€ë°ì´í„° í™•ì¸
        # FAISS.similarity_search ëŒ€ì‹  ì§ì ‘ docstoreì—ì„œ ì¶”ì¶œ ì‹œë„
        sample_doc = vector_store.similarity_search("context", k=1)[0]
        meta = sample_doc.metadata
        print(f"âœ… Sample Chunk Metadata: {meta}")
        if "pages" in meta:
            print(f"ğŸ¯ SUCCESS: Page-aware metadata 'pages' found: {meta['pages']}")
        else:
            print("âš ï¸ WARNING: 'pages' key not found in metadata.")
    
    print("\n" + "="*60)
    print("ğŸ All Verification Steps Completed!")
    print("="*60 + "\n")

if __name__ == "__main__":
    try:
        asyncio.run(verify_system())
    except Exception as e:
        print(f"\nâŒ Verification failed with error: {e}")
        import traceback
        traceback.print_exc()
