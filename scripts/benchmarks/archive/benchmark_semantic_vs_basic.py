import asyncio
import os
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent / "src"))

import numpy as np
import torch
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

from common.config import SEMANTIC_CHUNKER_CONFIG
from core.rag_core import _load_pdf_docs, _split_documents


async def run_comparison():
    print("ğŸš€ [Benchmark] Semantic Chunking vs Basic Chunking ë¹„êµ í…ŒìŠ¤íŠ¸")

    pdf_path = "tests/data/2201.07520v1.pdf"
    if not os.path.exists(pdf_path):
        print(f"âŒ í…ŒìŠ¤íŠ¸ìš© PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    device = "cuda" if torch.cuda.is_available() else "cpu"
    embedder = HuggingFaceEmbeddings(
        model_name=model_name, model_kwargs={"device": device}
    )

    # ì›ë³¸ ë¬¸ì„œ ë¡œë“œ (ê³µí†µ)
    docs = _load_pdf_docs(pdf_path, "benchmark.pdf")

    results = {}

    # --- Case A: Basic Chunking ---
    print("\n[Case A] Basic Chunking (RecursiveCharacterTextSplitter) ì‹¤í–‰ ì¤‘...")
    # ì„ì‹œë¡œ ì„¤ì • ë³€ê²½
    SEMANTIC_CHUNKER_CONFIG["enabled"] = False

    start_time = time.time()
    split_docs_a, _ = _split_documents(docs, embedder)
    # Basicì€ ë²¡í„°ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œ ì„ë² ë”© ìˆ˜í–‰
    texts_a = [d.page_content for d in split_docs_a]
    vectors_a = embedder.embed_documents(texts_a)
    _ = FAISS.from_embeddings(
        zip(texts_a, vectors_a, strict=False),
        embedder,
        metadatas=[d.metadata for d in split_docs_a],
    )
    time_a = time.time() - start_time

    results["Basic"] = {
        "time": time_a,
        "chunk_count": len(split_docs_a),
        "avg_len": sum(len(d.page_content) for d in split_docs_a) / len(split_docs_a),
    }

    # --- Case B: Semantic Chunking ---
    print("\n[Case B] Semantic Chunking (Vector Reuse) ì‹¤í–‰ ì¤‘...")
    # ì„ì‹œë¡œ ì„¤ì • ë³€ê²½
    SEMANTIC_CHUNKER_CONFIG["enabled"] = True

    start_time = time.time()
    # ì˜ë¯¸ë¡ ì  ì²­í‚¹ì€ ë¶„í•  ê³¼ì •ì—ì„œ ë²¡í„°ë¥¼ ì´ë¯¸ ê³„ì‚°í•¨
    split_docs_b, vectors_b = _split_documents(docs, embedder)

    # ë²¡í„° ì¬ì‚¬ìš©í•˜ì—¬ FAISS ìƒì„± (ì¶”ê°€ ì„ë² ë”© í˜¸ì¶œ ì—†ìŒ)
    if vectors_b:
        vectors_np = [np.array(v) for v in vectors_b]
        _ = FAISS.from_embeddings(
            zip([d.page_content for d in split_docs_b], vectors_np, strict=False),
            embedder,
            metadatas=[d.metadata for d in split_docs_b],
        )
    time_b = time.time() - start_time

    results["Semantic"] = {
        "time": time_b,
        "chunk_count": len(split_docs_b),
        "avg_len": sum(len(d.page_content) for d in split_docs_b) / len(split_docs_b),
    }

    # --- ê²°ê³¼ ì¶œë ¥ ---
    print("\n" + "=" * 60)
    print(f"{'ì§€í‘œ':<20} | {'Basic (ê·œì¹™ ê¸°ë°˜)':<18} | {'Semantic (ì˜ë¯¸ë¡ ì )':<18}")
    print("-" * 60)
    print(
        f"{'ì†Œìš” ì‹œê°„(ì´ˆ)':<20} | {results['Basic']['time']:<18.2f} | {results['Semantic']['time']:<18.2f}"
    )
    print(
        f"{'ìƒì„±ëœ ì²­í¬ ìˆ˜':<20} | {results['Basic']['chunk_count']:<18} | {results['Semantic']['chunk_count']:<18}"
    )
    print(
        f"{'í‰ê·  ì²­í¬ ê¸¸ì´':<20} | {results['Basic']['avg_len']:<18.1f} | {results['Semantic']['avg_len']:<18.1f}"
    )
    print("=" * 60)

    # ë¶„ì„ ì˜ê²¬
    print("\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
    if results["Semantic"]["time"] > results["Basic"]["time"]:
        overhead = (
            (results["Semantic"]["time"] - results["Basic"]["time"])
            / results["Basic"]["time"]
            * 100
        )
        print(f"1. ì‹œê°„ ë¹„ìš©: ì˜ë¯¸ë¡ ì  ì²­í‚¹ì´ ì•½ {overhead:.1f}% ë” ì†Œìš”ë©ë‹ˆë‹¤.")
    else:
        print("1. ì‹œê°„ ë¹„ìš©: ë²¡í„° ì¬ì‚¬ìš© ë•ë¶„ì— ì˜ë¯¸ë¡ ì  ì²­í‚¹ì´ ì˜¤íˆë ¤ íš¨ìœ¨ì ì…ë‹ˆë‹¤.")

    print(
        f"2. êµ¬ì¡°ì  ì°¨ì´: Basicì€ ê³ ì • í¬ê¸°ë¡œ ìª¼ê°œì§€ë§Œ, Semanticì€ {results['Semantic']['chunk_count']}ê°œì˜ 'ì˜ë¯¸ ë‹¨ìœ„'ë¡œ ë¬¶ì—ˆìŠµë‹ˆë‹¤."
    )
    print(
        "3. íš¨ìš©ì„±: í˜„ì¬ êµ¬ì¡°(Vector Reuse)ëŠ” ì˜ë¯¸ë¡ ì  ì²­í‚¹ ì‹œ ë°œìƒí•˜ëŠ” ì„ë² ë”© ë¹„ìš©ì„ FAISS ì¸ë±ì‹± ë‹¨ê³„ì—ì„œ 100% íšŒìˆ˜í•˜ë¯€ë¡œ ë§¤ìš° íš¨ìœ¨ì ì…ë‹ˆë‹¤."
    )


if __name__ == "__main__":
    asyncio.run(run_comparison())
